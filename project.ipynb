{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f556ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ginza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73a52ce",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13d8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff229cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "nlp = spacy.load('ja_ginza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4429fad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "銀座 銀座 銀座 ['ギンザ'] PROPN [] 名詞-固有名詞-地名-一般 nmod 5\n",
      "で で で ['デ'] ADP [] 助詞-格助詞 case 0\n",
      "ランチ ランチ ランチ ['ランチ'] NOUN [] 名詞-普通名詞-一般 obj 5\n",
      "を を を ['ヲ'] ADP [] 助詞-格助詞 case 2\n",
      "ご ご 御 ['ゴ'] NOUN [] 接頭辞 compound 5\n",
      "一緒 一緒 一緒 ['イッショ'] NOUN [] 名詞-普通名詞-サ変可能 ROOT 5\n",
      "し する 為る ['シ'] AUX ['サ行変格;連用形-一般'] 動詞-非自立可能 aux 5\n",
      "ましょう ます ます ['マショウ'] AUX ['助動詞-マス;意志推量形'] 助動詞 aux 5\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 5\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# nlp = spacy.load('ja_ginza_electra')\n",
    "nlp = spacy.load('ja_ginza')\n",
    "\n",
    "doc = nlp('銀座でランチをご一緒しましょう。')\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        print(\n",
    "#             token.i,\n",
    "            token.orth_,\n",
    "            token.lemma_,\n",
    "            token.norm_,\n",
    "            token.morph.get(\"Reading\"),\n",
    "            token.pos_,\n",
    "            token.morph.get(\"Inflection\"),\n",
    "            token.tag_,\n",
    "            token.dep_,\n",
    "            token.head.i,\n",
    "        )\n",
    "#     print('EOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67fc8976",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 compound 1\n",
      "人 人 人 ['ヒト'] NOUN [] 名詞-普通名詞-一般 obj 4\n",
      "を を を ['ヲ'] ADP [] 助詞-格助詞 case 1\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 1\n",
      "信ずる 信ずる 信じる ['シンズル'] VERB ['サ行変格;連体形-一般'] 動詞-一般 ccomp 11\n",
      "事 事 事 ['コト'] NOUN [] 名詞-普通名詞-一般 compound 4\n",
      "が が が ['ガ'] ADP [] 助詞-格助詞 fixed 5\n",
      "出来 出来る 出来る ['デキ'] AUX ['上一段-カ行;未然形-一般'] 動詞-非自立可能 fixed 5\n",
      "ぬ ぬ ず ['ヌ'] AUX ['助動詞-ヌ;終止形-一般'] 助動詞 aux 4\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 4\n",
      "と と と ['ト'] ADP [] 助詞-格助詞 case 4\n",
      "いう いう 言う ['イウ'] VERB ['五段-ワア行;連体形-一般'] 動詞-一般 ROOT 11\n",
      "の の の ['ノ'] SCONJ [] 助詞-準体助詞 mark 11\n",
      "です です です ['デス'] AUX ['助動詞-デス;終止形-一般'] 助動詞 fixed 12\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 11\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 compound 17\n",
      "三 三 3 ['ミッ'] NUM [] 名詞-数詞 nummod 17\n",
      "日 日 日 ['カ'] NOUN [] 接尾辞-名詞的-助数詞 nmod 19\n",
      "の の の ['ノ'] ADP [] 助詞-格助詞 case 17\n",
      "うち うち うち ['ウチ'] NOUN [] 名詞-普通名詞-副詞可能 obl 28\n",
      "に に に ['ニ'] ADP [] 助詞-格助詞 case 19\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 19\n",
      "私 私 私 ['ワタクシ'] PRON [] 代名詞 nsubj 28\n",
      "は は は ['ハ'] ADP [] 助詞-係助詞 case 22\n",
      "村 村 村 ['ムラ'] NOUN [] 名詞-普通名詞-一般 obl 28\n",
      "で で で ['デ'] ADP [] 助詞-格助詞 case 24\n",
      "結婚式 結婚式 結婚式 ['ケッコンシキ'] NOUN [] 名詞-普通名詞-一般 obj 28\n",
      "を を を ['ヲ'] ADP [] 助詞-格助詞 case 26\n",
      "挙げ 挙げる 上げる ['アゲ'] VERB ['下一段-ガ行;未然形-一般'] 動詞-非自立可能 advcl 35\n",
      "させ させる させる ['サセ'] AUX ['下一段-サ行;連用形-一般'] 助動詞 aux 28\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 28\n",
      "必ず 必ず 必ず ['カナラズ'] ADV [] 副詞 advmod 35\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 31\n",
      "ここ ここ 此処 ['ココ'] PRON [] 代名詞 obl 35\n",
      "へ へ へ ['ヘ'] ADP [] 助詞-格助詞 case 33\n",
      "帰っ 帰る 帰る ['カエッ'] VERB ['五段-ラ行;連用形-促音便'] 動詞-一般 advcl 37\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 mark 35\n",
      "来 来る 来る ['キ'] VERB ['カ行変格;連用形-一般'] 動詞-非自立可能 ROOT 37\n",
      "ます ます ます ['マス'] AUX ['助動詞-マス;終止形-一般'] 助動詞 aux 37\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 37\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 dep 60\n",
      "そう そう そう ['ソウ'] ADV [] 副詞 aux 40\n",
      "し する 為る ['シ'] AUX ['サ行変格;連用形-一般'] 動詞-非自立可能 fixed 41\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 fixed 41\n",
      "身代り 身代り 身代わり ['ミガワリ'] NOUN [] 名詞-普通名詞-一般 nmod 46\n",
      "の の の ['ノ'] ADP [] 助詞-格助詞 case 44\n",
      "男 男 男 ['オトコ'] NOUN [] 名詞-普通名詞-一般 obj 53\n",
      "を を を ['ヲ'] ADP [] 助詞-格助詞 case 46\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 46\n",
      "三 三 3 ['ミッ'] NUM [] 名詞-数詞 compound 51\n",
      "日 日 日 ['カ'] NOUN [] 接尾辞-名詞的-助数詞 compound 51\n",
      "目 目 目 ['メ'] NOUN [] 接尾辞-名詞的-一般 obl 53\n",
      "に に に ['ニ'] ADP [] 助詞-格助詞 case 51\n",
      "殺し 殺す 殺す ['コロシ'] VERB ['五段-サ行;連用形-一般'] 動詞-一般 advcl 60\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 mark 53\n",
      "やる やる 遣る ['ヤル'] VERB ['五段-ラ行;連体形-一般'] 動詞-非自立可能 fixed 54\n",
      "の の の ['ノ'] SCONJ [] 助詞-準体助詞 mark 53\n",
      "も も も ['モ'] ADP [] 助詞-係助詞 case 53\n",
      "気味 気味 気味 ['キミ'] NOUN [] 名詞-普通名詞-一般 nsubj 60\n",
      "が が が ['ガ'] ADP [] 助詞-格助詞 case 58\n",
      "いい いい 良い ['イイ'] ADJ ['形容詞;終止形-一般'] 形容詞-非自立可能 ROOT 60\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 60\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 compound 63\n",
      "もの もの 物 ['モノ'] NOUN [] 名詞-普通名詞-サ変可能 nsubj 65\n",
      "も も も ['モ'] ADP [] 助詞-係助詞 case 63\n",
      "言い 言う 言う ['イイ'] VERB ['五段-ワア行;連用形-一般'] 動詞-一般 advcl 67\n",
      "たく たい たい ['タク'] AUX ['助動詞-タイ;連用形-一般'] 助動詞 aux 65\n",
      "なく ない 無い ['ナク'] ADJ ['形容詞;連用形-一般'] 形容詞-非自立可能 advcl 68\n",
      "なっ なる 成る ['ナッ'] VERB ['五段-ラ行;連用形-促音便'] 動詞-非自立可能 ROOT 68\n",
      "た た た ['タ'] AUX ['助動詞-タ;終止形-一般'] 助動詞 aux 68\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 68\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 advcl 91\n",
      "そう そう そう ['ソウ'] ADV [] 副詞 aux 71\n",
      "し する 為る ['シ'] AUX ['サ行変格;連用形-一般'] 動詞-非自立可能 fixed 72\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 fixed 72\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 71\n",
      "少し 少し 少し ['スコシ'] ADV [] 副詞 advmod 79\n",
      "事情 事情 事情 ['ジジョウ'] NOUN [] 名詞-普通名詞-一般 nsubj 79\n",
      "が が が ['ガ'] ADP [] 助詞-格助詞 case 77\n",
      "ある ある 有る ['アル'] VERB ['五段-ラ行;終止形-一般'] 動詞-非自立可能 advcl 86\n",
      "から から から ['カラ'] SCONJ [] 助詞-接続助詞 mark 79\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 79\n",
      "結婚式 結婚式 結婚式 ['ケッコンシキ'] NOUN [] 名詞-普通名詞-一般 obj 86\n",
      "を を を ['ヲ'] ADP [] 助詞-格助詞 case 82\n",
      "明日 明日 明日 ['アス'] NOUN [] 名詞-普通名詞-副詞可能 obl 86\n",
      "に に に ['ニ'] ADP [] 助詞-格助詞 case 84\n",
      "し する 為る ['シ'] VERB ['サ行変格;連用形-一般'] 動詞-非自立可能 ccomp 91\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 mark 86\n",
      "くれ くれる 呉れる ['クレ'] VERB ['下一段-ラ行;命令形'] 動詞-非自立可能 fixed 87\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 86\n",
      "と と と ['ト'] ADP [] 助詞-格助詞 case 86\n",
      "頼ん 頼む 頼む ['タノン'] VERB ['五段-マ行;連用形-撥音便'] 動詞-一般 ROOT 91\n",
      "だ だ た ['ダ'] AUX ['助動詞-タ;終止形-一般'] 助動詞 aux 91\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 91\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 ROOT 94\n",
      "あれ あれ 彼れ ['アレ'] PRON [] 代名詞 nsubj 97\n",
      "が が が ['ガ'] ADP [] 助詞-格助詞 case 95\n",
      "沈ん 沈む 沈む ['シズン'] VERB ['五段-マ行;連用形-撥音便'] 動詞-一般 acl 101\n",
      "で で で ['デ'] SCONJ [] 助詞-接続助詞 mark 97\n",
      "しまわ しまう 仕舞う ['シマワ'] VERB ['五段-ワア行;未然形-一般'] 動詞-非自立可能 fixed 98\n",
      "ぬ ぬ ず ['ヌ'] AUX ['助動詞-ヌ;連体形-一般'] 助動詞 aux 97\n",
      "うち うち うち ['ウチ'] NOUN [] 名詞-普通名詞-副詞可能 obl 106\n",
      "に に に ['ニ'] ADP [] 助詞-格助詞 case 101\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 101\n",
      "王城 王城 王城 ['オウジョウ'] NOUN [] 名詞-普通名詞-一般 obl 106\n",
      "に に に ['ニ'] ADP [] 助詞-格助詞 case 104\n",
      "行き着く 行き着く 行き着く ['イキツク'] VERB ['五段-カ行;連体形-一般'] 動詞-一般 advcl 122\n",
      "こと こと こと ['コト'] NOUN [] 名詞-普通名詞-一般 compound 106\n",
      "が が が ['ガ'] ADP [] 助詞-格助詞 fixed 107\n",
      "出来 出来る 出来る ['デキ'] AUX ['上一段-カ行;未然形-一般'] 動詞-非自立可能 fixed 107\n",
      "なかっ ない ない ['ナカッ'] AUX ['助動詞-ナイ;連用形-促音便'] 助動詞 aux 106\n",
      "たら た た ['タラ'] AUX ['助動詞-タ;仮定形-一般'] 助動詞 aux 106\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 106\n",
      "あの あの 彼の ['アノ'] DET [] 連体詞 det 115\n",
      "佳い 佳い 良い ['ヨイ'] VERB ['形容詞;連体形-一般'] 形容詞-非自立可能 compound 115\n",
      "友達 友達 友達 ['トモダチ'] NOUN [] 名詞-普通名詞-一般 nsubj 122\n",
      "が が が ['ガ'] ADP [] 助詞-格助詞 case 115\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 115\n",
      "私 私 私 ['ワタクシ'] PRON [] 代名詞 nmod 120\n",
      "の の の ['ノ'] ADP [] 助詞-格助詞 case 118\n",
      "ため ため 為 ['タメ'] NOUN [] 名詞-普通名詞-副詞可能 obl 122\n",
      "に に に ['ニ'] ADP [] 助詞-格助詞 case 120\n",
      "死ぬ 死ぬ 死ぬ ['シヌ'] VERB ['五段-ナ行;連体形-一般'] 動詞-一般 ROOT 122\n",
      "の の の ['ノ'] SCONJ [] 助詞-準体助詞 mark 122\n",
      "です です です ['デス'] AUX ['助動詞-デス;終止形-一般'] 助動詞 fixed 123\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 122\n",
      "\n",
      " \n",
      " \n",
      " [] ADV [] 空白 advmod 129\n",
      "何 何 何 ['ナン'] PRON [] 代名詞 obj 129\n",
      "を を を ['ヲ'] ADP [] 助詞-格助詞 case 127\n",
      "する する 為る ['スル'] VERB ['サ行変格;連体形-一般'] 動詞-非自立可能 ROOT 129\n",
      "の の の ['ノ'] SCONJ [] 助詞-準体助詞 mark 129\n",
      "だ だ だ ['ダ'] AUX ['助動詞-ダ;終止形-一般'] 助動詞 fixed 130\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 129\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 ROOT 133\n",
      "けれど けれど けれど ['ケレド'] CCONJ [] 接続詞 ROOT 134\n",
      "も も も ['モ'] ADP [] 助詞-係助詞 ROOT 135\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 ROOT 136\n",
      "今 今 今 ['イマ'] NOUN [] 名詞-普通名詞-副詞可能 obl 139\n",
      "に に に ['ニ'] ADP [] 助詞-格助詞 case 137\n",
      "なっ なる 成る ['ナッ'] VERB ['五段-ラ行;連用形-促音便'] 動詞-非自立可能 advcl 151\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 mark 139\n",
      "みる みる 見る ['ミル'] VERB ['上一段-マ行;終止形-一般'] 動詞-非自立可能 fixed 140\n",
      "と と と ['ト'] SCONJ [] 助詞-接続助詞 mark 139\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 139\n",
      "私 私 私 ['ワタクシ'] PRON [] 代名詞 nsubj 151\n",
      "は は は ['ハ'] ADP [] 助詞-係助詞 case 144\n",
      "王 王 王 ['オウ'] NOUN [] 名詞-普通名詞-一般 nmod 148\n",
      "の の の ['ノ'] ADP [] 助詞-格助詞 case 146\n",
      "言う 言う 言う ['イウ'] VERB ['五段-ワア行;連体形-一般'] 動詞-一般 acl 149\n",
      "まま まま 侭 ['ママ'] NOUN [] 名詞-普通名詞-副詞可能 obl 151\n",
      "に に に ['ニ'] ADP [] 助詞-格助詞 case 149\n",
      "なっ なる 成る ['ナッ'] VERB ['五段-ラ行;連用形-促音便'] 動詞-非自立可能 ROOT 151\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 mark 151\n",
      "いる いる 居る ['イル'] VERB ['上一段-ア行;終止形-一般'] 動詞-非自立可能 fixed 152\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 151\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 compound 156\n",
      "王 王 王 ['オウ'] NOUN [] 名詞-普通名詞-一般 nsubj 164\n",
      "は は は ['ハ'] ADP [] 助詞-係助詞 case 156\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 156\n",
      "ひとり合点 ひとり合点 独り合点 ['ヒトリガテン'] VERB [] 名詞-普通名詞-サ変可能 advcl 164\n",
      "し する 為る ['シ'] AUX ['サ行変格;連用形-一般'] 動詞-非自立可能 aux 159\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 mark 159\n",
      "私 私 私 ['ワタクシ'] PRON [] 代名詞 obj 164\n",
      "を を を ['ヲ'] ADP [] 助詞-格助詞 case 162\n",
      "笑い 笑う 笑う ['ワライ'] VERB ['五段-ワア行;連用形-一般'] 動詞-一般 advcl 167\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 164\n",
      "そう そう そう ['ソウ'] ADV [] 副詞 advmod 167\n",
      "し する 為る ['シ'] VERB ['サ行変格;連用形-一般'] 動詞-非自立可能 advcl 174\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 mark 167\n",
      "事 事 事 ['コト'] NOUN [] 名詞-普通名詞-一般 nsubj 171\n",
      "も も も ['モ'] ADP [] 助詞-係助詞 case 169\n",
      "無く 無い 無い ['ナク'] ADJ ['形容詞;連用形-一般'] 形容詞-非自立可能 advcl 174\n",
      "私 私 私 ['ワタクシ'] PRON [] 代名詞 obj 174\n",
      "を を を ['ヲ'] ADP [] 助詞-格助詞 case 172\n",
      "放免 放免 放免 ['ホウメン'] VERB [] 名詞-普通名詞-サ変可能 ROOT 174\n",
      "する する 為る ['スル'] AUX ['サ行変格;終止形-一般'] 動詞-非自立可能 aux 174\n",
      "だろう だ だ ['ダロウ'] AUX ['助動詞-ダ;意志推量形'] 助動詞 aux 174\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 174\n",
      "\n",
      " \n",
      " \n",
      " [] ADV [] 空白 ROOT 178\n",
      "私 私 私 ['ワタクシ'] PRON [] 代名詞 obj 182\n",
      "を を を ['ヲ'] ADP [] 助詞-格助詞 case 179\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 179\n",
      "待っ 待つ 待つ ['マッ'] VERB ['五段-タ行;連用形-促音便'] 動詞-一般 acl 185\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 mark 182\n",
      "いる いる 居る ['イル'] VERB ['上一段-ア行;連体形-一般'] 動詞-非自立可能 fixed 183\n",
      "人 人 人 ['ヒト'] NOUN [] 名詞-普通名詞-一般 nsubj 187\n",
      "が が が ['ガ'] ADP [] 助詞-格助詞 case 185\n",
      "ある ある 有る ['アル'] VERB ['五段-ラ行;連体形-一般'] 動詞-非自立可能 ROOT 187\n",
      "の の の ['ノ'] SCONJ [] 助詞-準体助詞 mark 187\n",
      "だ だ だ ['ダ'] AUX ['助動詞-ダ;終止形-一般'] 助動詞 fixed 188\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 187\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 compound 192\n",
      "死ん 死ぬ 死ぬ ['シン'] VERB ['五段-ナ行;連用形-撥音便'] 動詞-一般 advcl 195\n",
      "で で で ['デ'] SCONJ [] 助詞-接続助詞 mark 192\n",
      "お お 御 ['オ'] NOUN [] 接頭辞 compound 195\n",
      "詫び 詫びる 詫びる ['ワビ'] NOUN ['上一段-バ行;連用形-一般'] 動詞-一般 obl 204\n",
      "、 、 、 ['、'] PUNCT [] 補助記号-読点 punct 195\n",
      "など など など ['ナド'] PART [] 助詞-副助詞 mark 195\n",
      "と と と ['ト'] ADP [] 助詞-格助詞 case 195\n",
      "気 気 気 ['キ'] NOUN [] 名詞-普通名詞-一般 nmod 201\n",
      "の の の ['ノ'] ADP [] 助詞-格助詞 case 199\n",
      "いい いい 良い ['イイ'] ADJ ['形容詞;連体形-一般'] 形容詞-非自立可能 acl 202\n",
      "事 事 事 ['コト'] NOUN [] 名詞-普通名詞-一般 nsubj 204\n",
      "は は は ['ハ'] ADP [] 助詞-係助詞 case 202\n",
      "言っ 言う 言う ['イッ'] VERB ['五段-ワア行;連用形-促音便'] 動詞-一般 advcl 206\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 mark 204\n",
      "居 居る 居る ['イ'] VERB ['上一段-ア行;未然形-一般'] 動詞-非自立可能 ROOT 206\n",
      "られ られる られる ['ラレ'] AUX ['助動詞-レル;未然形-一般'] 助動詞 aux 206\n",
      "ぬ ぬ ず ['ヌ'] AUX ['助動詞-ヌ;終止形-一般'] 助動詞 aux 206\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 206\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 compound 211\n",
      "メロス メロス メロス ['メロス'] PROPN [] 名詞-普通名詞-一般 ROOT 211\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 211\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 ROOT 213\n",
      "その その 其の ['ソノ'] DET [] 連体詞 det 215\n",
      "人 人 人 ['ヒト'] NOUN [] 名詞-普通名詞-一般 obj 217\n",
      "を を を ['ヲ'] ADP [] 助詞-格助詞 case 215\n",
      "殺し 殺す 殺す ['コロシ'] VERB ['五段-サ行;連用形-一般'] 動詞-一般 ROOT 217\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 mark 217\n",
      "は は は ['ハ'] ADP [] 助詞-係助詞 fixed 218\n",
      "なら なる 成る ['ナラ'] VERB ['五段-ラ行;未然形-一般'] 動詞-非自立可能 fixed 218\n",
      "ぬ ぬ ず ['ヌ'] AUX ['助動詞-ヌ;終止形-一般'] 助動詞 fixed 218\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 217\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 compound 224\n",
      "メロス メロス メロス ['メロス'] PROPN [] 名詞-普通名詞-一般 nsubj 226\n",
      "が が が ['ガ'] ADP [] 助詞-格助詞 case 224\n",
      "帰っ 帰る 帰る ['カエッ'] VERB ['五段-ラ行;連用形-促音便'] 動詞-一般 ROOT 226\n",
      "て て て ['テ'] SCONJ [] 助詞-接続助詞 mark 226\n",
      "来 来る 来る ['キ'] VERB ['カ行変格;連用形-一般'] 動詞-非自立可能 advcl 226\n",
      "た た た ['タ'] AUX ['助動詞-タ;終止形-一般'] 助動詞 aux 228\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 228\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 compound 232\n",
      "メロス メロス メロス ['メロス'] PROPN [] 名詞-普通名詞-一般 ROOT 232\n",
      "だ だ だ ['ダ'] AUX ['助動詞-ダ;終止形-一般'] 助動詞 cop 232\n",
      "。 。 。 ['。'] PUNCT [] 補助記号-句点 punct 232\n",
      "\n",
      " \n",
      " \n",
      " [] NUM [] 空白 ROOT 235\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "人を、信ずる事が出来ぬ、というのです。\n",
    "三日のうちに、私は村で結婚式を挙げさせ、必ず、ここへ帰って来ます。\n",
    "そうして身代りの男を、三日目に殺してやるのも気味がいい。\n",
    "ものも言いたくなくなった。\n",
    "そうして、少し事情があるから、結婚式を明日にしてくれ、と頼んだ。\n",
    "あれが沈んでしまわぬうちに、王城に行き着くことが出来なかったら、あの佳い友達が、私のために死ぬのです。\n",
    "何をするのだ。\n",
    "けれども、今になってみると、私は王の言うままになっている。\n",
    "王は、ひとり合点して私を笑い、そうして事も無く私を放免するだろう。\n",
    "私を、待っている人があるのだ。\n",
    "死んでお詫び、などと気のいい事は言って居られぬ。\n",
    "メロス。\n",
    "その人を殺してはならぬ。\n",
    "メロスが帰って来た。\n",
    "メロスだ。\n",
    "\"\"\"\n",
    "texts = nlp(text)\n",
    "# print(texts)\n",
    "for sent in texts.sents:\n",
    "    for token in sent:\n",
    "        print(\n",
    "#             token.i,\n",
    "            token.orth_,\n",
    "            token.lemma_,\n",
    "            token.norm_,\n",
    "            token.morph.get(\"Reading\"),\n",
    "            token.pos_,\n",
    "            token.morph.get(\"Inflection\"),\n",
    "            token.tag_,\n",
    "            token.dep_,\n",
    "            token.head.i,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29f9068-35ac-46f8-9370-e8ffc8d8015c",
   "metadata": {},
   "source": [
    "## Text Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00f1ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67505b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "887f7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ca415bf-29f8-45c3-bd69-69165a2cb164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学習者のID</th>\n",
       "      <th>学習者の性別</th>\n",
       "      <th>学習環境</th>\n",
       "      <th>作文テーマ</th>\n",
       "      <th>学習者の母語</th>\n",
       "      <th>日本語学習履歴</th>\n",
       "      <th>日本語レベル</th>\n",
       "      <th>テスト成績（文字語彙）</th>\n",
       "      <th>テスト成績（文法）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CG009</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CG011</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CG013</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CG015</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CG017</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>KN303</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>KN307</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>KN312</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>KN313</td>\n",
       "      <td>男</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>KN316</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    学習者のID 学習者の性別 学習環境            作文テーマ 学習者の母語   日本語学習履歴 日本語レベル テスト成績（文字語彙）  \\\n",
       "0    CG009      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "1    CG011      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "2    CG013      男   国外  外国語がうまくなる方法について    中国語      2年未満     上級           A   \n",
       "3    CG015      男   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "4    CG017      女   国外  外国語がうまくなる方法について    中国語      2年未満     中級           B   \n",
       "..     ...    ...  ...              ...    ...       ...    ...         ...   \n",
       "299  KN303      女   国内  外国語がうまくなる方法について    韓国語      2年未満     中級           X   \n",
       "300  KN307      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "301  KN312      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "302  KN313      男   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "303  KN316      女   国内  外国語がうまくなる方法について    韓国語      5年以上     上級           X   \n",
       "\n",
       "    テスト成績（文法）  \n",
       "0           C  \n",
       "1           B  \n",
       "2           A  \n",
       "3           B  \n",
       "4           A  \n",
       "..        ...  \n",
       "299         X  \n",
       "300         X  \n",
       "301         X  \n",
       "302         X  \n",
       "303         X  \n",
       "\n",
       "[304 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/register.xls\"\n",
    "labels = pd.read_excel(path)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0c5fc55-ef23-4b84-89bc-2169246e450b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'外国語がうまくなる方法について': 192, 'インターネット時代に新聞や雑誌は必要か': 112})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(labels.作文テーマ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4ccb70d-8c0d-4f03-94ad-b5a8939d5b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学習者のID</th>\n",
       "      <th>学習者の性別</th>\n",
       "      <th>学習環境</th>\n",
       "      <th>作文テーマ</th>\n",
       "      <th>学習者の母語</th>\n",
       "      <th>日本語学習履歴</th>\n",
       "      <th>日本語レベル</th>\n",
       "      <th>テスト成績（文字語彙）</th>\n",
       "      <th>テスト成績（文法）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CG009</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CG011</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CG013</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CG015</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CG017</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>KN303</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>KN307</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>KN312</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>KN313</td>\n",
       "      <td>男</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>KN316</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    学習者のID 学習者の性別 学習環境            作文テーマ 学習者の母語   日本語学習履歴 日本語レベル テスト成績（文字語彙）  \\\n",
       "0    CG009      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "1    CG011      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "2    CG013      男   国外  外国語がうまくなる方法について    中国語      2年未満     上級           A   \n",
       "3    CG015      男   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "4    CG017      女   国外  外国語がうまくなる方法について    中国語      2年未満     中級           B   \n",
       "..     ...    ...  ...              ...    ...       ...    ...         ...   \n",
       "299  KN303      女   国内  外国語がうまくなる方法について    韓国語      2年未満     中級           X   \n",
       "300  KN307      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "301  KN312      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "302  KN313      男   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "303  KN316      女   国内  外国語がうまくなる方法について    韓国語      5年以上     上級           X   \n",
       "\n",
       "    テスト成績（文法）  \n",
       "0           C  \n",
       "1           B  \n",
       "2           A  \n",
       "3           B  \n",
       "4           A  \n",
       "..        ...  \n",
       "299         X  \n",
       "300         X  \n",
       "301         X  \n",
       "302         X  \n",
       "303         X  \n",
       "\n",
       "[192 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "label1 = labels.loc[labels.作文テーマ == \"外国語がうまくなる方法について\",:]\n",
    "label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ef9c545-ca9e-4ec3-be21-44a3d6109551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学習者のID</th>\n",
       "      <th>学習者の性別</th>\n",
       "      <th>学習環境</th>\n",
       "      <th>作文テーマ</th>\n",
       "      <th>学習者の母語</th>\n",
       "      <th>日本語学習履歴</th>\n",
       "      <th>日本語レベル</th>\n",
       "      <th>テスト成績（文字語彙）</th>\n",
       "      <th>テスト成績（文法）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>CG101</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>CG102</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>CG103</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CG104</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>CG105</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>KG151</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>KG152</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>KG153</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>KG154</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>KG155</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    学習者のID 学習者の性別 学習環境                作文テーマ 学習者の母語   日本語学習履歴 日本語レベル  \\\n",
       "76   CG101      男   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "77   CG102      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "78   CG103      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "79   CG104      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "80   CG105      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     上級   \n",
       "..     ...    ...  ...                  ...    ...       ...    ...   \n",
       "292  KG151      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語      5年以上     上級   \n",
       "293  KG152      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語  2年以上5年未満     上級   \n",
       "294  KG153      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語  2年以上5年未満     上級   \n",
       "295  KG154      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語      2年未満     中級   \n",
       "296  KG155      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語      5年以上     上級   \n",
       "\n",
       "    テスト成績（文字語彙） テスト成績（文法）  \n",
       "76            X         X  \n",
       "77            X         X  \n",
       "78            X         X  \n",
       "79            X         X  \n",
       "80            X         X  \n",
       "..          ...       ...  \n",
       "292           X         X  \n",
       "293           X         X  \n",
       "294           X         X  \n",
       "295           X         X  \n",
       "296           X         X  \n",
       "\n",
       "[112 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2 = labels.loc[labels.作文テーマ == \"インターネット時代に新聞や雑誌は必要か\",:]\n",
    "label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf6b1924-31fb-4042-923e-12973315f894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['初級', '初級', '上級', '初級', '中級', '中級', '中級', '上級', '中級', '中級', '中級',\n",
       "        '上級', '中級', '中級', '中級', '初級', '中級', '上級', '初級', '初級', '中級', '中級',\n",
       "        '初級', '中級', '中級', '上級', '中級', '中級', '初級', '上級', '上級', '初級', '中級',\n",
       "        '中級', '上級', '中級', '中級', '初級', '初級', '中級', '上級', '中級', '上級', '中級',\n",
       "        '上級', '中級', '初級', '中級', '中級', '初級', '上級', '初級', '中級', '中級', '上級',\n",
       "        '初級', '初級', '上級', '上級', '中級', '中級', '中級', '上級', '中級', '中級', '上級',\n",
       "        '中級', '中級', '中級', '初級', '中級', '初級', '中級', '中級', '上級', '上級', '初級',\n",
       "        '上級', '中級', '中級', '上級', '中級', '中級', '中級', '中級', '中級', '中級', '中級',\n",
       "        '中級', '中級', '上級', '中級', '中級', '初級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '中級', '中級', '中級', '中級', '初級', '中級', '中級', '初級', '中級', '中級', '中級',\n",
       "        '上級', '中級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '中級', '中級',\n",
       "        '上級', '中級', '上級', '上級', '中級', '上級', '上級', '中級', '中級', '初級', '中級',\n",
       "        '中級', '上級', '中級', '上級', '上級', '上級', '中級', '上級', '中級', '上級', '上級',\n",
       "        '上級', '中級', '初級', '中級', '中級', '上級', '上級', '中級', '中級', '上級', '上級',\n",
       "        '上級', '中級', '初級', '中級', '中級', '中級', '上級', '中級', '初級', '中級', '中級',\n",
       "        '中級', '上級', '初級', '上級', '中級', '中級', '中級', '初級', '中級', '中級', '中級',\n",
       "        '中級', '初級', '中級', '初級', '初級', '中級', '中級', '中級', '中級', '上級', '中級',\n",
       "        '中級', '上級', '上級', '上級', '上級'], dtype=object),\n",
       " 192)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level1 = np.array(label1.日本語レベル)\n",
    "level1, len(level1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4efca524-db6c-4c83-8b40-769f9894fcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中級', '中級', '中級', '中級', '上級', '中級', '中級', '中級', '上級', '中級', '中級',\n",
       "        '中級', '中級', '上級', '上級', '中級', '中級', '中級', '上級', '中級', '中級', '中級',\n",
       "        '中級', '上級', '中級', '中級', '中級', '中級', '中級', '上級', '中級', '中級', '中級',\n",
       "        '上級', '中級', '中級', '中級', '中級', '中級', '中級', '中級', '上級', '中級', '中級',\n",
       "        '中級', '中級', '上級', '中級', '中級', '上級', '中級', '中級', '中級', '上級', '中級',\n",
       "        '上級', '上級', '上級', '上級', '中級', '上級', '上級', '上級', '中級', '上級', '上級',\n",
       "        '中級', '上級', '上級', '上級', '中級', '上級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '上級', '上級', '上級', '上級', '上級', '上級', '中級', '上級', '上級', '上級', '上級',\n",
       "        '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '中級', '上級'], dtype=object),\n",
       " 112)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level2 = np.array(label2.日本語レベル)\n",
    "level2, len(level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38ce16f8-f876-4b4f-ae39-be73cdab30c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'中級': 49, '上級': 63})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "level2_dist = Counter(level2)\n",
    "level2_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abe45e2f-8f54-49a2-a30a-072d2698b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = \"data/txt/\"\n",
    "# txt = pd.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c628447-9e5b-4298-adf1-6e12c7165e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gaigo_txt', 'internet_txt']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "txt_path = \"data/txt/\"\n",
    "txt_topics = listdir(txt_path)\n",
    "txt_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8bedc23-8edf-4fca-97c8-046549018ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_gaigo_path = txt_path + txt_topics[0]\n",
    "txt_internet_path = txt_path + txt_topics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bd0f916-cb66-4af5-8fd8-a9ee3cd18eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_gaigo_files = listdir(txt_gaigo_path)\n",
    "txt_internet_files = listdir(txt_internet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a68c5243-0fd2-4769-a2d6-b0b0dd08d0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CG009.txt', 'CG011.txt', 'CG013.txt', 'CG015.txt', 'CG017.txt']\n",
      "['CG101.txt', 'CG102.txt', 'CG103.txt', 'CG104.txt', 'CG105.txt']\n"
     ]
    }
   ],
   "source": [
    "print(txt_gaigo_files[:5])\n",
    "print(txt_internet_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5df6c89-51f1-40f5-be51-2c87b6edd222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import re\n",
    "gaigo_files = [f for f in listdir(osp.join(txt_path, txt_topics[0])) if f.endswith('.txt')]\n",
    "gaigo = []\n",
    "for gaigo_file in gaigo_files:\n",
    "    # print(gaigo_file)\n",
    "    with open(osp.join(txt_path, txt_topics[0], gaigo_file), \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read()\n",
    "        # type(lines)\n",
    "        lines = re.sub('\\n', '', lines)\n",
    "        lines = re.sub('\\u3000', '', lines)\n",
    "    gaigo.append(lines)\n",
    "# type(gaigo[0])\n",
    "# gaigo[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59848c76-9602-4f9c-95e9-a0d43259f80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'私は大学日本語科の一年生です。最初、日本語が難しいと思いました。それから先生が日本語がうまくなる方法を聞きました。先生は「毎日単語を覚えるとか、日本語の文章を読むとか、ドラマをみます。」と言いました。私は先生が教えたとおりにしていました。毎朝、単語を読んでいました。よる、ドラマを見ていました。難しい内容をあった。先生に聞きました。重要な内容を整理しました。日本語の口頭試験がよいためにたくさん練習しました。たくさんの日本の歌を聞きました。歌を聞きながら、歌の内容を書きました。いま、私は日本語がやさしいと思います。'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaigo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5a61094-35a3-4cd3-9dbb-05a920dc7bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'この数十年の間に、テレビや携*帯電話などの便利なものは世界的に使われていて、私たち現代人の生活に大きな役に立っているのだ。その何種類の産品の中に、一番の便利さが持っていて、生活を影響するのはコンピューターだと思う。今は、何でもコンピューターでできるんでしょう。例えば、ネットを使って、どの国にどんなことがあったかのがすぐ分かることとか、ネットで買い物したり、ホテルを予約したりすることとか、いろいろなことがただ指で完成できる。その一方で、コンピューターの発達によって、たくさん問題も次から次へと、生じる。ずっと、コンピューターで宿題やレポートをすると、今の子たちはほとんど、字がきたなくなったり、書けない漢字も昔より増えてきたらしい。だから、うまくコンピューターを利用できるかどうかは私たちにとって重要な課題になる。さっき言ったように、ネットでどんなことでもできる。もちろん、毎日のニュースや雑誌の内容もほとんどネットにある。そのため、コンビニに行って、新聞と雑誌を買う必要がなくなり、コンピューターの電源のボタンを押すと、何でも見られる。新聞代や雑誌代を使って、他方面のことで使うことができるようになったから、コンピューターがあれば、他のものはもういらないと思っている人が多いかも知れないけれども、私はそのようには思わない。コンピューターの利点はたくさんあるのは確かだけれど、その利点や便利さを頼りすぎると、悪い結果も出て来る。漢字が正しく書けなくなったり、何でもネットからコピーして、自分がどんどん考えられなくなったりするのは一番見られる現象である。ですから、いくらコンピューターが便利でも、他のところから知識とか生活能力を学習するのは昔より重要だと思っている。もちろん、新聞や雑誌はそれらの方法の中に、一番簡単に使える方法である。これからも、必要なものとして私たちの生活に存在しているのも違えない。要するに、これから、きっとたくさん生活に役に立つものが創造されるんだ。だけど、いくら生活がどんなに快適、便利になっても、自分の目で見て、手を使って、自分らしく考えておいて、そして、やることをするのが依然として、もっとも人間にとって大切なことであると、私はそうだと思っているL。※「携」は右側の部分の上に「山」'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "internet_files = [f for f in listdir(osp.join(txt_path, txt_topics[1])) if f.endswith('.txt')]\n",
    "internet = []\n",
    "for internet_file in internet_files:\n",
    "    with open(osp.join(txt_path, txt_topics[1], internet_file), \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read()\n",
    "        # print(lines)\n",
    "        lines = lines.strip('\\ufeff□')\n",
    "        lines = re.sub('■', '', lines)\n",
    "        lines = re.sub('\\n', '', lines)\n",
    "        lines = re.sub('□', '', lines)\n",
    "        lines = re.sub('\\u3000', '', lines)\n",
    "        \n",
    "    internet.append(lines)\n",
    "\n",
    "internet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c429f50-6d4c-497c-a644-34f0fb47e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# text = 'この数十年の間に、テレビや携*帯電話などの便利なものは世界的に使われていて、私たち現代人の生活に大きな役に立っているのだ。その何種類の産品の中に、一番の便利さが持っていて、生活を影響するのはコンピューターだと思う。今は、何でもコンピューターでできるんでしょう。例えば、ネットを使って、どの国にどんなことがあったかのがすぐ分かることとか、ネットで買い物したり、ホテルを予約したりすることとか、いろいろなことがただ指で完成できる。その一方で、コンピューターの発達によって、たくさん問題も次から次へと、生じる。ずっと、コンピューターで宿題やレポートをすると、今の子たちはほとんど、字がきたなくなったり、書けない漢字も昔より増えてきたらしい。だから、うまくコンピューターを利用できるかどうかは私たちにとって重要な課題になる■。\\n'\n",
    "\n",
    "# text2 = re.sub('■', '', text)\n",
    "# text3 = re.sub('\\n', '', text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "339fb041-5e37-4b6a-a4eb-9e215f5a0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817f517-8a58-44cb-ab2a-62d261db22e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535fd1b-3cfc-421e-af21-a4adcebd487f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict as dd\n",
    "internet_tagged = dd(list)\n",
    "for level, txt in zip(level1, internet):\n",
    "    internet_tagged[level].append(txt)\n",
    "\n",
    "# print(internet_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97689fb7-8a37-483e-8973-6aae5e152e96",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "gaigo_tagged = dd(list)\n",
    "for level, txt in zip(level2, gaigo):\n",
    "    gaigo_tagged[level].append(txt)\n",
    "\n",
    "# print(gaigo_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30ce04-8843-4847-a8fd-81093025e940",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict as dd\n",
    "text_tagged = dd(list)\n",
    "for level, txt in zip(level1, internet):\n",
    "    text_tagged[level].append(txt)\n",
    "\n",
    "for level, txt in zip(level2, gaigo):\n",
    "    text_tagged[level].append(txt)\n",
    "\n",
    "# text_tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9053f837-70a5-4d71-8382-f98713b3b0d5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_tagged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text_tagged_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[43mtext_tagged\u001b[49m)\n\u001b[0;32m      2\u001b[0m text_tagged_dict\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_tagged' is not defined"
     ]
    }
   ],
   "source": [
    "text_tagged_dict = dict(text_tagged)\n",
    "text_tagged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7321e33-eac3-4362-acd8-ca13439097f0",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "002cb5d6-7b9a-4611-b4d6-901586ad8f59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_tagged_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm_notebook \u001b[38;5;28;01mas\u001b[39;00m tqdm\n\u001b[0;32m      8\u001b[0m category_vectors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cat, text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtext_tagged_dict\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sents \u001b[38;5;129;01min\u001b[39;00m tqdm(text):\n\u001b[0;32m     12\u001b[0m         sent_vecs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_tagged_dict' is not defined"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# nlp = spacy.load('ja_ginza_electra')\n",
    "nlp = spacy.load('ja_ginza')\n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "category_vectors = []\n",
    "\n",
    "for cat, text in text_tagged_dict.items():\n",
    "    for sents in tqdm(text):\n",
    "        sent_vecs = []\n",
    "        for sent in sents:\n",
    "            sent = nlp(sent)\n",
    "            word_sum = np.sum([tok.vector for tok in sent], axis=0)\n",
    "            sent_vecs.append(word_sum)\n",
    "        category_vectors.append((cat, np.sum(sent_vecs, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f0ef68-2d03-4dde-8602-fc1a74a76b25",
   "metadata": {},
   "source": [
    "## Save & load Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81638d93-72d4-4668-bb01-4c8de184925d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "# with open('category_vectors.pickle', 'wb') as f:\n",
    "#     pickle.dump(category_vectors, f)\n",
    "    \n",
    "category_vectors2 = pickle.load(open('category_vectors.pickle', 'rb'))\n",
    "\n",
    "category_vectors2[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a367a2b-46fe-4d49-abc9-a815427884f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# with open('text_tagged_dict.pickle', 'wb') as f:\n",
    "#     pickle.dump(text_tagged_dict, f)\n",
    "import pickle \n",
    "    \n",
    "text_tagged_dict2 = pickle.load(open('text_tagged_dict.pickle', 'rb'))\n",
    "# text_tagged_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49205bfb-dcc7-4695-ab22-e5e9b126c28f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68726b56-66b0-4512-9ba8-ba66b45d897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('ja_ginza')\n",
    "\n",
    "for text in text_tagged_dict2[\"初級\"]:\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.is_stop:\n",
    "            print(token)\n",
    "#     for sents in tqdm(text):\n",
    "#         sent_vecs = []\n",
    "#         for sent in sents:\n",
    "#             sent = nlp(sent)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf62dd4-a9d1-42fb-a408-342f9479edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('ja_ginza')\n",
    "\n",
    "doc = \"\"\" 私は大学日本語科の一年生です。いま、外国語がたくさんひとが学習しました。でも私は日本語より英語のほうが難しいと思いました。外国語がうまくなる、いろいろ方法が習っています。単語を覚えています。会話を読みます。聴解を聞きます。以上はすべて外国語がうまくなる方法です。日本語聴解が私にとってにくいと思います。先生は日本語聴解よくを私に言います。私は聴解教材を聞きてみました。やはり、聴解教材をよく聞きば聴解ほどよいてします。いま、私は私の日本語能力ことができるどてもいいたいと思います。 \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c4bb40-91f2-4b77-bfbf-2d9460f9ceff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a1be6dc-f853-4098-bb62-6620f5311826",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d18d240-4590-4c03-9c42-a885d0ece278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'初級': 22, '上級': 91, '中級': 111})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "keys, values = zip(*category_vectors2)\n",
    "\n",
    "data = pd.DataFrame({'cat': keys, 'vectors': values})\n",
    "data2 = Counter(data.cat)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba06b079-00f2-43db-8a5d-37baaac5ad9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(data)\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0586cc-d7b5-414c-9b71-320845d10c77",
   "metadata": {},
   "source": [
    "## Compute the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b5c77d-3250-4c84-92ab-da7b3daf5ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random baseline 0.3333333333333333\n",
      "\n",
      "most common baseline?\n",
      "初級: 0.09821428571428571\n",
      "上級: 0.40625\n",
      "中級: 0.4955357142857143\n"
     ]
    }
   ],
   "source": [
    "print('random baseline {}\\n'.format(1.0/len(set(data.cat))))\n",
    "\n",
    "print('most common baseline?')\n",
    "for cat in data2.keys():\n",
    "    print('{}: {}'.format(cat, len(data[data.cat == cat])/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60b653-b0b4-454a-8ab1-1fc79b9e0ae4",
   "metadata": {},
   "source": [
    "Thus we assume that the baseline for the target texts is 0.496 and we attempt to surpass it using several neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f97c9c3-43ab-4763-9371-c44dc3f209c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 2), (179, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.sample(frac=0.2, random_state=200)\n",
    "train = data.drop(test.index)\n",
    "\n",
    "test.shape, train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da9450-0b32-4a9d-a1e1-754437423f5e",
   "metadata": {},
   "source": [
    "## Train by Using Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfd40244-8f4f-4d68-8283-a58594468217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12f57046-65bd-4558-a1e5-651957e69f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data.cat)\n",
    "X = [x for x in train.vectors]\n",
    "y = le.transform(train.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef98e87c-0878-45fc-bafc-9b10d75ef245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b7560c8-776b-46e1-9773-f04b4cdd0443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "clfr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98ddcc8-02f9-4b5e-9096-11f7aff6213e",
   "metadata": {},
   "source": [
    "### Evaluate the Accuracy for Logistic Regressiong Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0951810e-4c28-45dc-8395-cfd8340798f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30446314-9338-4ade-a734-a59c4f4136a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37777777777777777"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = le.transform(test.cat)\n",
    "test_X = [x for x in test.vectors]\n",
    "pred_y = clfr.predict(test_X)\n",
    "\n",
    "# test_y.shape, pred_y.shape\n",
    "accuracy = accuracy_score(pred_y, test_y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "383a0a1c-8ae8-49bb-8315-e8d156ab405f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9, 14,  3],\n",
       "       [ 6,  8,  1],\n",
       "       [ 1,  3,  0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(pred_y, test_y)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(cm, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.xticks(np.arange(3), [\"Beginner\", \"Intermediate\", \"Advanced\"])\n",
    "plt.yticks(np.arange(3), [\"Beginner\", \"Intermediate\", \"Advanced\"])\n",
    "\n",
    "plt.show()\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1d058-afb0-422c-b432-dcf10d47b59b",
   "metadata": {},
   "source": [
    "## Feedforward Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b3d9986-1757-4fd7-b110-cb4814673c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((179, 300), (179, 3))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "le.fit(data.cat)\n",
    "y = le.transform(train.cat).reshape(-1, 1)\n",
    "ohe.fit(y)\n",
    "y = ohe.transform(y).todense()\n",
    "\n",
    "X = np.array([x for x in train.vectors])\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b7ebe1e-b338-43bf-b131-4f779805e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cd2637b-c696-49af-9b02-877c577bc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=300, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "000c4948-2a40-43bd-9d29-91b4b84cab20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 128)               38528     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,139\n",
      "Trainable params: 51,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cad71c20-6951-40dd-a5ec-b3e02e2a096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 7ms/step - loss: 10.9179 - accuracy: 0.3017\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.3220 - accuracy: 0.5196\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.5349 - accuracy: 0.4637\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6859 - accuracy: 0.4302\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.4610 - accuracy: 0.4358\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1568 - accuracy: 0.4581\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0942 - accuracy: 0.5307\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.9851 - accuracy: 0.5084\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.9152 - accuracy: 0.5698\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.9430 - accuracy: 0.5922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1377b093f10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d7f46ff-4d2e-4ee0-bb30-9f4f71f5bd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 300), (45, 3))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "le.fit(data.cat)\n",
    "test_y = le.transform(test.cat).reshape(-1, 1)\n",
    "ohe.fit(test_y)\n",
    "test_y = ohe.transform(test_y).todense()\n",
    "\n",
    "test_X = np.array([x for x in test.vectors])\n",
    "\n",
    "test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4f9e89c-80ea-435c-b731-4e61c3cd2b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.27284557e-01, 7.99998224e-01, 7.27172270e-02],\n",
       "       [1.58635765e-01, 6.42919838e-01, 1.98444352e-01],\n",
       "       [2.30315790e-01, 7.54898489e-01, 1.47856781e-02],\n",
       "       [4.40872312e-02, 9.55893278e-01, 1.94785371e-05],\n",
       "       [8.88422355e-02, 9.09154236e-01, 2.00347998e-03],\n",
       "       [7.86220491e-01, 2.13706166e-01, 7.33169363e-05],\n",
       "       [7.83255231e-03, 9.55856502e-01, 3.63109410e-02],\n",
       "       [3.79981250e-01, 3.32507610e-01, 2.87511200e-01],\n",
       "       [8.74345839e-01, 1.25105247e-01, 5.48925193e-04],\n",
       "       [8.76006186e-01, 1.22479424e-01, 1.51444750e-03],\n",
       "       [3.46303493e-01, 6.35249496e-01, 1.84470434e-02],\n",
       "       [2.85680115e-01, 7.04360247e-01, 9.95954499e-03],\n",
       "       [8.83650035e-02, 4.53815311e-01, 4.57819730e-01],\n",
       "       [5.06330609e-01, 4.92734283e-01, 9.35068063e-04],\n",
       "       [6.52937829e-01, 3.45547736e-01, 1.51443691e-03],\n",
       "       [4.76984162e-04, 6.13246500e-01, 3.86276513e-01],\n",
       "       [1.55114532e-01, 8.36451828e-01, 8.43365211e-03],\n",
       "       [1.76592320e-01, 6.67706311e-01, 1.55701324e-01],\n",
       "       [6.70522690e-01, 3.27151030e-01, 2.32627499e-03],\n",
       "       [6.26582205e-01, 3.72947365e-01, 4.70448256e-04],\n",
       "       [1.01649150e-01, 7.30792165e-01, 1.67558685e-01],\n",
       "       [2.40649153e-02, 8.35626841e-01, 1.40308321e-01],\n",
       "       [2.52700210e-01, 6.06495202e-01, 1.40804648e-01],\n",
       "       [1.05724014e-01, 5.53891063e-01, 3.40384960e-01],\n",
       "       [2.03192189e-01, 5.67108929e-01, 2.29698837e-01],\n",
       "       [3.62867653e-01, 6.36365056e-01, 7.67366670e-04],\n",
       "       [1.28663078e-01, 8.31014335e-01, 4.03226018e-02],\n",
       "       [2.42498487e-01, 7.52630413e-01, 4.87112999e-03],\n",
       "       [2.20171630e-01, 7.63508141e-01, 1.63202100e-02],\n",
       "       [9.64259133e-02, 3.35369557e-01, 5.68204522e-01],\n",
       "       [2.14790225e-01, 4.03492481e-01, 3.81717265e-01],\n",
       "       [8.75380695e-01, 1.23166583e-01, 1.45267358e-03],\n",
       "       [7.71105766e-01, 2.22284198e-01, 6.61004288e-03],\n",
       "       [1.43450454e-01, 6.82270646e-01, 1.74278989e-01],\n",
       "       [7.26601660e-01, 2.57892579e-01, 1.55057721e-02],\n",
       "       [8.78606200e-01, 1.20390281e-01, 1.00345141e-03],\n",
       "       [1.26217291e-01, 7.58212805e-01, 1.15569934e-01],\n",
       "       [6.06526732e-02, 8.06797326e-01, 1.32550046e-01],\n",
       "       [3.39875221e-01, 6.59724832e-01, 3.99904704e-04],\n",
       "       [7.97006130e-01, 1.91760361e-01, 1.12335924e-02],\n",
       "       [8.92131865e-01, 1.07780643e-01, 8.74983161e-05],\n",
       "       [9.27673280e-02, 5.80302000e-01, 3.26930642e-01],\n",
       "       [4.47291285e-02, 6.83204412e-01, 2.72066444e-01],\n",
       "       [7.17237651e-01, 2.80599356e-01, 2.16301112e-03],\n",
       "       [4.66802835e-01, 5.32081604e-01, 1.11557113e-03]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b6459ec-a5ce-49cc-85a0-98e0adb35559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4666666666666667"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(model.predict(test_X), axis=1), np.argmax(test_y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65430c-c4b1-4012-9ccc-ef7eee56e87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcb8ba87-fb09-407f-8953-ba03d0bbf724",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=300, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22317d69-e9ba-4e44-b80b-61f18116d51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "GridSearchCV(estimator=SVC(),\n",
    "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
    "#sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba3429e1-f201-46fb-8fdb-cc3732e8ecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0006001 , 0.00061111, 0.00020065, 0.00079961]),\n",
       " 'std_fit_time': array([0.00048998, 0.00049977, 0.00040131, 0.00039983]),\n",
       " 'mean_score_time': array([0.        , 0.00058985, 0.00040054, 0.        ]),\n",
       " 'std_score_time': array([0.        , 0.00048308, 0.00049056, 0.        ]),\n",
       " 'param_C': masked_array(data=[1, 1, 10, 10],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.96666667, 0.96666667, 1.        , 0.96666667]),\n",
       " 'split1_test_score': array([1.        , 0.96666667, 1.        , 1.        ]),\n",
       " 'split2_test_score': array([0.96666667, 0.96666667, 0.9       , 0.96666667]),\n",
       " 'split3_test_score': array([0.96666667, 0.93333333, 0.96666667, 0.96666667]),\n",
       " 'split4_test_score': array([1., 1., 1., 1.]),\n",
       " 'mean_test_score': array([0.98      , 0.96666667, 0.97333333, 0.98      ]),\n",
       " 'std_test_score': array([0.01632993, 0.02108185, 0.03887301, 0.01632993]),\n",
       " 'rank_test_score': array([1, 4, 3, 1])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9808553-8043-4179-bb13-15a2efa10ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4597ab-e5f5-457e-9f32-40cdefc54d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e034a23-255f-4db5-97a5-150c6a6138c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "957c1790-f269-4698-b7fe-7fe104512d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from keras.optimizers import Adam, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54fa2eef-8acd-477a-b9c3-4cd3a75c2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 300\n",
    "output_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66a52ad9-f300-47f4-9688-fccfdd20f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_model(activation=\"relu\", optimizer=\"adam\", hidden_layer_sizes=(100, 100)): #, out_dim=100, ):\n",
    "    model = Sequential()\n",
    "    firstflag = True\n",
    "    for dim in hidden_layer_sizes:\n",
    "        if firstflag:\n",
    "            model.add(Dense(dim, input_dim=input_dim, activation=activation))\n",
    "            firstflag = False\n",
    "        else:\n",
    "            model.add(Dense(dim, activation=activation))\n",
    "    #model.add(Dense(out_dim, input_dim=300, activation=activation))\n",
    "    #model.add(Dense(out_dim, activation=activation))\n",
    "\n",
    "    model.add(Dense(output_dim, activation=\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "422fd6fa-573b-45c5-ab29-a5de5ad0952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = [\"relu\", \"sigmoid\"]\n",
    "optimizer = [\"adam\", \"adagrad\", \"sgd\", \"RMSprop\", \"Adamax\"]\n",
    "#out_dim = [100, 200]\n",
    "hidden_layer_sizes = [(50, 50, 50, 50), (50, 50, 50), (100, 100), (50, ) ]\n",
    "nb_epoch = [10, 25]\n",
    "batch_size = [5, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d58ed8f-6a48-4905-a1a5-e10ed3f4506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fic2023150.FIC.001\\AppData\\Local\\Temp\\ipykernel_5032\\303135173.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=language_model, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=language_model, verbose=0)\n",
    "param_grid = dict(activation=activation, \n",
    "                  optimizer=optimizer, \n",
    "                  hidden_layer_sizes=hidden_layer_sizes, \n",
    "                  nb_epoch=nb_epoch, \n",
    "                  batch_size=batch_size,)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e85490ea-625b-465d-a974-8d4356a6cabc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=relu, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.8s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.8s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.8s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.8s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=5, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.8s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.9s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.8s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.9s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=10, optimizer=Adamax; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.8s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=10, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(100, 100), nb_epoch=25, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.7s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=10, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adam; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=adagrad; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.5s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=RMSprop; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.4s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.6s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.3s\n",
      "[CV] END activation=sigmoid, batch_size=10, hidden_layer_sizes=(50,), nb_epoch=25, optimizer=Adamax; total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "99370522-815d-4ac4-a83e-15b605638f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4804469347000122"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5d2e3003-0aa6-44b0-816e-f6c6e90393de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000002A2524DB040>,\n",
       "             param_grid={'activation': ['relu', 'sigmoid'],\n",
       "                         'batch_size': [5, 10],\n",
       "                         'hidden_layer_sizes': [(50, 50, 50, 50), (50, 50, 50),\n",
       "                                                (100, 100), (50,)],\n",
       "                         'nb_epoch': [10, 25],\n",
       "                         'optimizer': ['adam', 'adagrad', 'sgd', 'RMSprop',\n",
       "                                       'Adamax']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08cb5001-7850-46ef-90ab-6766bc50cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "# with open('gridcv_result.pickle', 'wb') as f:\n",
    "#     pickle.dump(grid.cv_results_, f)\n",
    "\n",
    "# with open('gridcv_best_params.pickle', 'wb') as f:\n",
    "#     pickle.dump(grid.best_params_, f)\n",
    "    \n",
    "gridcv_result = pickle.load(open('gridcv_result.pickle', 'rb'))\n",
    "\n",
    "gridcv_best_params = pickle.load(open('gridcv_best_params.pickle', 'rb'))\n",
    "\n",
    "# gridcv_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a063eea5-6723-4f5d-a5ce-df9e6ae3d1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'sigmoid',\n",
       " 'batch_size': 10,\n",
       " 'hidden_layer_sizes': (50, 50, 50),\n",
       " 'nb_epoch': 25,\n",
       " 'optimizer': 'adagrad'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridcv_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80d576a2-2bc1-48d0-80f8-3768e4772d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f7746-c7d0-4275-b11d-80f8d6dac947",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5efa7c41-8cf3-46d5-9f8d-9387c3cfa46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'sigmoid',\n",
       " 'batch_size': 10,\n",
       " 'hidden_layer_sizes': (50, 50, 50),\n",
       " 'nb_epoch': 25,\n",
       " 'optimizer': 'adagrad'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7226b542-9a7b-4885-867e-b2b1f625fc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6166666626930237"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "41c53d3e-1ab9-4576-a184-7b5666560d7f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9759 - accuracy: 0.4302\n",
      "Epoch 2/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9682 - accuracy: 0.4804\n",
      "Epoch 3/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9639 - accuracy: 0.4804\n",
      "Epoch 4/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9607 - accuracy: 0.4804\n",
      "Epoch 5/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9585 - accuracy: 0.4804\n",
      "Epoch 6/25\n",
      "18/18 [==============================] - 0s 957us/step - loss: 0.9567 - accuracy: 0.4804\n",
      "Epoch 7/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9554 - accuracy: 0.4804\n",
      "Epoch 8/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9544 - accuracy: 0.4804\n",
      "Epoch 9/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9534 - accuracy: 0.4804\n",
      "Epoch 10/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9527 - accuracy: 0.4804\n",
      "Epoch 11/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9521 - accuracy: 0.4804\n",
      "Epoch 12/25\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.9516 - accuracy: 0.4804\n",
      "Epoch 13/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9514 - accuracy: 0.4804\n",
      "Epoch 14/25\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9509 - accuracy: 0.4804\n",
      "Epoch 15/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9505 - accuracy: 0.4804\n",
      "Epoch 16/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9502 - accuracy: 0.4804\n",
      "Epoch 17/25\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.9500 - accuracy: 0.4804\n",
      "Epoch 18/25\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.9497 - accuracy: 0.4804\n",
      "Epoch 19/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9496 - accuracy: 0.4804\n",
      "Epoch 20/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9496 - accuracy: 0.4804\n",
      "Epoch 21/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9492 - accuracy: 0.4804\n",
      "Epoch 22/25\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.9491 - accuracy: 0.4804\n",
      "Epoch 23/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9490 - accuracy: 0.4804\n",
      "Epoch 24/25\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9488 - accuracy: 0.4804\n",
      "Epoch 25/25\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9488 - accuracy: 0.4804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a254cc2760>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = language_model(activation=gridcv_best_params['activation'], \n",
    "                   optimizer=gridcv_best_params['optimizer'], \n",
    "                   hidden_layer_sizes=gridcv_best_params['hidden_layer_sizes'])\n",
    "\n",
    "model2.fit(X, y, epochs=gridcv_best_params['nb_epoch'], batch_size=gridcv_best_params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "41006c83-f713-4743-ab66-6b4e068f5f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# accuracy_score(model2.predict(test_X), test_y)\n",
    "accuracy_score(np.argmax(model2.predict(test_X), axis=1), np.argmax(test_y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b5e3d521-0c66-45f7-8ea7-c89cd4cb2af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.41423059, 0.47225347, 0.11351594],\n",
       "       [0.41422632, 0.4722535 , 0.11352018],\n",
       "       [0.41420543, 0.47228828, 0.11350624],\n",
       "       [0.41422457, 0.47225925, 0.11351618],\n",
       "       [0.41190252, 0.4767209 , 0.11137651],\n",
       "       [0.4142279 , 0.47225347, 0.11351866],\n",
       "       [0.41457272, 0.47251788, 0.11290936],\n",
       "       [0.4145866 , 0.47248918, 0.11292418],\n",
       "       [0.41380697, 0.4729741 , 0.1132189 ],\n",
       "       [0.41449392, 0.47239387, 0.11311228],\n",
       "       [0.41418064, 0.47232622, 0.11349319],\n",
       "       [0.4132563 , 0.47401205, 0.11273165],\n",
       "       [0.41423264, 0.4722564 , 0.11351098],\n",
       "       [0.41299728, 0.47453085, 0.11247186],\n",
       "       [0.4122939 , 0.47599617, 0.11170992],\n",
       "       [0.41458058, 0.4724811 , 0.11293835],\n",
       "       [0.41451716, 0.47241405, 0.11306875],\n",
       "       [0.41453126, 0.47242686, 0.11304185],\n",
       "       [0.41242033, 0.4754671 , 0.11211257],\n",
       "       [0.41422707, 0.47225457, 0.11351834],\n",
       "       [0.41427034, 0.47226706, 0.11346257],\n",
       "       [0.41446677, 0.47237185, 0.11316138],\n",
       "       [0.41455635, 0.4724528 , 0.11299085],\n",
       "       [0.41440204, 0.47248536, 0.11311267],\n",
       "       [0.41447562, 0.47243723, 0.11308715],\n",
       "       [0.41428563, 0.47227296, 0.11344139],\n",
       "       [0.41422826, 0.47225267, 0.11351911],\n",
       "       [0.41422752, 0.4722543 , 0.11351813],\n",
       "       [0.41422263, 0.47226483, 0.11351248],\n",
       "       [0.41299868, 0.4742905 , 0.11271079],\n",
       "       [0.4140445 , 0.47226414, 0.11369136],\n",
       "       [0.41422847, 0.47225273, 0.11351879],\n",
       "       [0.4145784 , 0.47249058, 0.11293108],\n",
       "       [0.4142322 , 0.4722705 , 0.11349743],\n",
       "       [0.41423178, 0.47225377, 0.11351439],\n",
       "       [0.4144235 , 0.47244224, 0.11313424],\n",
       "       [0.4142283 , 0.4722526 , 0.11351909],\n",
       "       [0.41422862, 0.47225398, 0.11351743],\n",
       "       [0.41422728, 0.47225276, 0.11351989],\n",
       "       [0.41423514, 0.4722316 , 0.11353327],\n",
       "       [0.41422692, 0.4722631 , 0.11351001],\n",
       "       [0.41450056, 0.4724034 , 0.11309598],\n",
       "       [0.41458812, 0.47249085, 0.11292113],\n",
       "       [0.41408783, 0.4724967 , 0.11341545],\n",
       "       [0.41400397, 0.4726558 , 0.11334028]], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e83e2159-cfe1-43f5-b200-cc7cea217ad0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'matrix' object has no attribute 'tonumpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Counter(np.argmax(test_y, axis=1))\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtonumpy\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'matrix' object has no attribute 'tonumpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Counter(np.argmax(test_y, axis=1))\n",
    "# np.argmax(test_y, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6c09f6a9-2c0e-458e-a4a4-5af29c83c61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model2.predict(test_X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e2cad920-6b3d-406f-af01-f9d8701d1072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.41423059, 0.47225347, 0.11351594],\n",
       "       [0.41422632, 0.4722535 , 0.11352018],\n",
       "       [0.41420543, 0.47228828, 0.11350624],\n",
       "       [0.41422457, 0.47225925, 0.11351618],\n",
       "       [0.41190252, 0.4767209 , 0.11137651],\n",
       "       [0.4142279 , 0.47225347, 0.11351866],\n",
       "       [0.41457272, 0.47251788, 0.11290936],\n",
       "       [0.4145866 , 0.47248918, 0.11292418],\n",
       "       [0.41380697, 0.4729741 , 0.1132189 ],\n",
       "       [0.41449392, 0.47239387, 0.11311228],\n",
       "       [0.41418064, 0.47232622, 0.11349319],\n",
       "       [0.4132563 , 0.47401205, 0.11273165],\n",
       "       [0.41423264, 0.4722564 , 0.11351098],\n",
       "       [0.41299728, 0.47453085, 0.11247186],\n",
       "       [0.4122939 , 0.47599617, 0.11170992],\n",
       "       [0.41458058, 0.4724811 , 0.11293835],\n",
       "       [0.41451716, 0.47241405, 0.11306875],\n",
       "       [0.41453126, 0.47242686, 0.11304185],\n",
       "       [0.41242033, 0.4754671 , 0.11211257],\n",
       "       [0.41422707, 0.47225457, 0.11351834],\n",
       "       [0.41427034, 0.47226706, 0.11346257],\n",
       "       [0.41446677, 0.47237185, 0.11316138],\n",
       "       [0.41455635, 0.4724528 , 0.11299085],\n",
       "       [0.41440204, 0.47248536, 0.11311267],\n",
       "       [0.41447562, 0.47243723, 0.11308715],\n",
       "       [0.41428563, 0.47227296, 0.11344139],\n",
       "       [0.41422826, 0.47225267, 0.11351911],\n",
       "       [0.41422752, 0.4722543 , 0.11351813],\n",
       "       [0.41422263, 0.47226483, 0.11351248],\n",
       "       [0.41299868, 0.4742905 , 0.11271079],\n",
       "       [0.4140445 , 0.47226414, 0.11369136],\n",
       "       [0.41422847, 0.47225273, 0.11351879],\n",
       "       [0.4145784 , 0.47249058, 0.11293108],\n",
       "       [0.4142322 , 0.4722705 , 0.11349743],\n",
       "       [0.41423178, 0.47225377, 0.11351439],\n",
       "       [0.4144235 , 0.47244224, 0.11313424],\n",
       "       [0.4142283 , 0.4722526 , 0.11351909],\n",
       "       [0.41422862, 0.47225398, 0.11351743],\n",
       "       [0.41422728, 0.47225276, 0.11351989],\n",
       "       [0.41423514, 0.4722316 , 0.11353327],\n",
       "       [0.41422692, 0.4722631 , 0.11351001],\n",
       "       [0.41450056, 0.4724034 , 0.11309598],\n",
       "       [0.41458812, 0.47249085, 0.11292113],\n",
       "       [0.41408783, 0.4724967 , 0.11341545],\n",
       "       [0.41400397, 0.4726558 , 0.11334028]], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e8221711-1286-4fc0-8ce6-c71a14960b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 1, 2, 0, 1, 0, 0, 2, 1, 1, 0, 0,\n",
       "         1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(test_y, axis=1).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c42d9b41-ed2a-4d80-b312-596f383d275c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(grid.predict(test_X), np.argmax(test_y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e70c9c-789e-4ffd-a048-03afe57e9419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = language_model(activation=grid_result.best_params_['activation'], \n",
    "#                    optimizer=grid_result.best_params_['optimizer'], \n",
    "#                    out_dim=grid_result.best_params_['out_dim'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "58a5a4dc-db1a-4b96-a483-196ba1501e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://marupeke296.com/IKDADV_DL_No7_dense.html\n",
    "# https://analyticsindiamag.com/a-complete-understanding-of-dense-layers-in-neural-networks/\n",
    "# https://www.tutorialspoint.com/keras/keras_dense_layer.htm#:~:text=Dense%20layer%20is%20the%20regular%20deeply%20connected%20neural,used%20in%20machine%20learning%20to%20optimize%20the%20model\n",
    "# dense layer multi dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339184f-2969-4dc2-8e93-24d5eb2cb96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c5a404-4c51-43ac-bba9-44294bbc0564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c14fd1ec-e806-4d3f-ac55-eabf1ca19de8",
   "metadata": {},
   "source": [
    "## LSTM(an RNN algorithm that considers sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316798e3-cd61-436a-b53d-89cbfdc0aaea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a114cd9-8283-44bc-853c-9f282a11de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(128, input_dim=300, activation='relu'))\n",
    "# model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ab1d1d8-74dd-4042-8256-578a3bfd277d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'units'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model3 \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m----> 6\u001b[0m model3\u001b[38;5;241m.\u001b[39madd(\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m model3\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Add an Embedding layer expecting input vocab of size 1000, and\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# output embedding dimension of size 64.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# model3.add(layers.Dense(3, activation = 'sigmoid'))\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# model3.add(layers.Dense(3))\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'units'"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "model3 = keras.Sequential()\n",
    "\n",
    "# model3.add(layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model3.add(layers.LSTM(256))\n",
    "\n",
    "model3.add(layers.Dense(3, activation=\"softmax\"))\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "\n",
    "# model3.add(layers.Embedding(17781, 64, mask_zero = True))\n",
    "# model3.add(layers.Embedding(input_dim=10000, output_dim=3))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "# model3.add(layers.LSTM(128))\n",
    "\n",
    "#LSTM層\n",
    "# model3.add(layers.LSTM(1000, batch_input_shape=(None, 300, 3), return_sequences=False))\n",
    "# model3.add(layers.LSTM(32))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "\n",
    "# model3.add(layers.Dense(3, activation = 'sigmoid'))\n",
    "# model3.add(layers.Dense(3))\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4c37ad9e-e6df-494d-82e7-a3fa38fa7b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_18 (Embedding)    (None, None, 128)         6400000   \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, None, 128)        98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,598,019\n",
      "Trainable params: 6,598,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Bidirectional, Dense, LSTM\n",
    "import keras\n",
    "\n",
    "model4 = keras.Sequential()\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "model4.add(inputs)\n",
    "model4.add(Embedding(50000, 128))\n",
    "# Add 2 bidirectional LSTMs\n",
    "model4.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model4.add(Bidirectional(LSTM(64)))\n",
    "# Add a classifier\n",
    "model4.add(Dense(3, activation=\"sigmoid\"))\n",
    "#model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "83ab0347-fc3b-4a1d-9434-0a86d162da39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_21/embedding_18/embedding_lookup' defined at (most recent call last):\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Local\\Temp\\ipykernel_9632\\3516443451.py\", line 4, in <cell line: 4>\n      model4.fit(X, y, epochs=10)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_21/embedding_18/embedding_lookup'\nindices[19,150] = -17 is not in [0, 50000)\n\t [[{{node sequential_21/embedding_18/embedding_lookup}}]] [Op:__inference_train_function_54178]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model4\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_val, y_val))\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel4\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_21/embedding_18/embedding_lookup' defined at (most recent call last):\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Local\\Temp\\ipykernel_9632\\3516443451.py\", line 4, in <cell line: 4>\n      model4.fit(X, y, epochs=10)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_21/embedding_18/embedding_lookup'\nindices[19,150] = -17 is not in [0, 50000)\n\t [[{{node sequential_21/embedding_18/embedding_lookup}}]] [Op:__inference_train_function_54178]"
     ]
    }
   ],
   "source": [
    "model4.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_val, y_val))\n",
    "\n",
    "model4.fit(X, y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2aa684c4-27d9-4448-b36c-1e810ddba754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((179, 300), (179, 3))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, #test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8b7220c-c96c-4984-b6c8-a79bc07a6413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 300, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 300, 3), dtype=tf.float32, name='lstm_17_input'), name='lstm_17_input', description=\"created by layer 'lstm_17_input'\"), but it was called on an input with incompatible shape (None, 300).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_16\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"lstm_17\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 300)\n    \n    Call arguments received by layer \"sequential_16\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 300), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\FIC202~1.003\\AppData\\Local\\Temp\\__autograph_generated_filexu578j5e.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fic2023150.FIC.003\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_16\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"lstm_17\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 300)\n    \n    Call arguments received by layer \"sequential_16\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 300), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model3.fit(X, y, epochs=10)\n",
    "# model3.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c5d51ab9-84f9-42c2-9897-ecd42ac65243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "フランスは美しい"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('ja_ginza')\n",
    "a = nlp(\"フランスは美しい\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b6efc08c-d272-4d7e-a194-0c8043237e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20541845,  0.06981254, -0.15181574, -0.19650103,  0.12664604,\n",
       "        0.13070539, -0.03076594, -0.26199836, -0.05935141,  0.08857816,\n",
       "        0.4077132 , -0.15560386, -0.4968115 ,  0.03130277, -0.4050716 ,\n",
       "       -1.1823422 , -0.52030545, -0.10984713, -0.2841841 ,  0.14389984,\n",
       "       -0.44435605,  0.72251076, -0.11566293, -0.0088225 , -0.11648972,\n",
       "       -0.23559886, -0.7332463 ,  0.39784816,  0.06261075,  0.33612818,\n",
       "       -0.28057522, -0.13994169,  0.32622817,  0.39167586,  0.20236656,\n",
       "        0.11419073, -0.22155693,  0.17834456, -0.21881005,  0.4253017 ,\n",
       "        0.12522538,  0.35306895, -0.25317585, -0.23793213, -0.11059578,\n",
       "       -0.17612958,  0.19178101,  0.42768013, -0.1962043 ,  0.01052836,\n",
       "        0.05601807, -0.29415464, -0.09432504,  0.34828192,  0.19634306,\n",
       "        0.19625708,  0.37396502, -0.32176477,  0.03398779,  0.16432036,\n",
       "        0.65104103,  0.23178801, -0.09538021,  0.10966959, -0.15087128,\n",
       "       -0.57314724,  0.1339181 ,  0.8827145 , -0.1836529 ,  0.1319705 ,\n",
       "        0.08433514,  0.4586126 ,  0.2032657 ,  0.8240324 ,  0.1218456 ,\n",
       "       -0.20018063,  0.11143362, -0.6270975 ,  0.6283263 ,  0.29286876,\n",
       "       -0.41577888, -0.20075506, -0.44462776, -0.1857904 ,  0.24923645,\n",
       "       -0.4743192 , -0.15817618, -0.5806153 , -0.06703201,  0.15818098,\n",
       "       -0.51470214,  0.7383777 , -0.37759137,  0.13141178,  0.10689086,\n",
       "        0.35307518, -0.01616598, -0.26360968,  0.01052089,  0.128831  ,\n",
       "        0.5754892 ,  0.00407861,  0.75608706, -0.45393735, -0.07035445,\n",
       "       -0.2134443 ,  0.34915933,  0.36055714, -0.17184214, -0.02114434,\n",
       "        0.4309727 , -0.22934571,  0.05241555, -0.2234714 ,  0.06088756,\n",
       "       -0.70610106,  0.2426825 , -0.0190919 ,  0.28526634, -0.0339921 ,\n",
       "       -0.46141878, -0.09704905,  0.09118422, -0.09015457,  0.19718406,\n",
       "       -0.2106655 , -0.3786124 ,  0.30974054,  0.16351998,  0.44445586,\n",
       "       -0.02917722, -0.6104162 , -0.5723843 , -0.30431107, -0.8359078 ,\n",
       "       -0.58194065,  0.08506744,  0.04281084,  0.13394603,  0.19175336,\n",
       "       -0.5983993 ,  0.4058845 , -0.0883664 ,  0.8698133 ,  0.10120742,\n",
       "        0.18838444, -0.47576696, -0.1534574 ,  0.17047003,  0.2188423 ,\n",
       "        0.01685311, -0.18421897,  0.26747704, -0.11993828, -0.91306734,\n",
       "        0.64947337, -0.7410563 , -0.10080376,  0.22526655,  0.18692216,\n",
       "       -0.36043164, -0.09110308, -0.3994145 ,  0.45416132, -0.00969236,\n",
       "       -0.09333991, -0.3014148 ,  0.5472517 ,  0.31426555, -0.90162885,\n",
       "       -0.16782683,  0.18766017, -0.23694608, -0.38686585, -0.111312  ,\n",
       "       -0.0054246 ,  0.37413853,  0.12490209,  0.08435526,  0.10301586,\n",
       "       -0.72816217,  0.23746476,  0.05013841,  0.5897914 , -0.41633305,\n",
       "        0.18547095,  0.09270769, -0.00296172,  0.16896398,  0.16536514,\n",
       "       -0.04768697, -0.1817843 , -0.23277481,  0.17364207, -0.09183274,\n",
       "        0.04182599,  0.30223635, -0.22760531,  0.23835027, -0.01673065,\n",
       "        0.4549189 , -0.16585629, -0.35400277,  0.15092996, -0.6513532 ,\n",
       "        0.00371678, -0.46376935, -0.16959183,  0.7989911 ,  0.02593151,\n",
       "       -0.42265755,  0.19370234,  0.4820017 , -0.17812917,  0.001715  ,\n",
       "        0.6336426 ,  0.36899042,  0.3462213 ,  0.06339736, -0.46114165,\n",
       "        0.22318317, -0.22144318,  0.35585663,  0.5287366 , -0.07251083,\n",
       "       -0.71381295, -0.8248421 ,  0.01596955, -0.13686767, -0.06921599,\n",
       "        0.40812296,  0.19561598, -0.82078516,  0.5211354 ,  0.25097978,\n",
       "        0.31135052, -0.28797865,  0.7245188 , -0.08686855,  0.53790605,\n",
       "        0.7913469 , -0.33426523, -0.50247234, -0.59662104,  0.06794044,\n",
       "       -0.10680965,  0.04344479, -0.56477475, -0.6546848 ,  0.0714702 ,\n",
       "        0.45469415, -0.64117616,  0.46200287,  0.6280636 , -0.2669358 ,\n",
       "        0.66250205,  0.43129537, -0.590854  , -0.02151808, -0.35038817,\n",
       "        0.09052702, -0.04907464, -0.31467807,  0.3047696 , -0.06343833,\n",
       "       -0.48527762, -0.35846913,  0.1028186 ,  0.32362998, -0.5561601 ,\n",
       "        0.4005589 ,  0.8807483 , -0.31066602, -0.00130638, -0.072743  ,\n",
       "        0.12502888, -0.02071061,  0.13106143,  0.72368836,  0.07703772,\n",
       "        0.31772774, -0.12685004, -0.0025726 , -0.08280589, -0.44577944,\n",
       "       -0.5149301 ,  0.3602599 , -0.06438424,  0.1464114 , -0.28391382,\n",
       "       -0.6331084 ,  0.97712183,  0.46991086, -0.34211516, -0.10651591,\n",
       "        0.35076895, -0.6273181 ,  0.5327946 , -0.1654709 ,  0.17281444],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = nlp(\"フランスは美しい\")\n",
    "word_sum = np.sum([tok.vector for tok in sent], axis=0)\n",
    "word_sum        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7534e088-c706-476e-a8ad-a6469e0f54f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20541844,  0.06981254, -0.15181574, -0.19650102,  0.12664604,\n",
       "        0.13070539, -0.03076594, -0.26199836, -0.05935141,  0.08857816,\n",
       "        0.4077132 , -0.15560386, -0.4968115 ,  0.03130277, -0.4050716 ,\n",
       "       -1.182342  , -0.52030545, -0.10984713, -0.2841841 ,  0.14389984,\n",
       "       -0.44435602,  0.72251076, -0.11566292, -0.0088225 , -0.11648972,\n",
       "       -0.23559886, -0.73324627,  0.39784816,  0.06261075,  0.33612818,\n",
       "       -0.28057522, -0.13994168,  0.32622817,  0.39167586,  0.20236656,\n",
       "        0.11419073, -0.22155693,  0.17834458, -0.21881005,  0.42530173,\n",
       "        0.1252254 ,  0.35306895, -0.25317585, -0.23793212, -0.11059578,\n",
       "       -0.17612958,  0.19178103,  0.42768013, -0.19620429,  0.01052836,\n",
       "        0.05601807, -0.29415467, -0.09432504,  0.3482819 ,  0.19634306,\n",
       "        0.19625708,  0.37396502, -0.32176477,  0.03398779,  0.16432035,\n",
       "        0.65104103,  0.23178801, -0.09538022,  0.10966959, -0.15087128,\n",
       "       -0.5731473 ,  0.1339181 ,  0.8827145 , -0.1836529 ,  0.1319705 ,\n",
       "        0.08433514,  0.4586126 ,  0.2032657 ,  0.8240324 ,  0.1218456 ,\n",
       "       -0.20018062,  0.11143362, -0.6270975 ,  0.6283263 ,  0.29286876,\n",
       "       -0.41577888, -0.20075506, -0.44462776, -0.1857904 ,  0.24923646,\n",
       "       -0.4743192 , -0.1581762 , -0.5806153 , -0.06703201,  0.15818098,\n",
       "       -0.51470214,  0.7383777 , -0.3775914 ,  0.13141176,  0.10689086,\n",
       "        0.35307515, -0.01616597, -0.26360968,  0.01052089,  0.128831  ,\n",
       "        0.5754892 ,  0.0040786 ,  0.75608706, -0.45393735, -0.07035445,\n",
       "       -0.21344432,  0.34915933,  0.36055717, -0.17184214, -0.02114434,\n",
       "        0.4309727 , -0.2293457 ,  0.05241555, -0.2234714 ,  0.06088756,\n",
       "       -0.70610106,  0.24268249, -0.0190919 ,  0.28526634, -0.0339921 ,\n",
       "       -0.4614188 , -0.09704906,  0.09118422, -0.09015458,  0.19718406,\n",
       "       -0.2106655 , -0.37861237,  0.3097405 ,  0.16351998,  0.44445586,\n",
       "       -0.0291772 , -0.6104162 , -0.5723843 , -0.30431107, -0.83590776,\n",
       "       -0.58194065,  0.08506744,  0.04281084,  0.13394603,  0.19175336,\n",
       "       -0.5983993 ,  0.4058845 , -0.08836639,  0.8698133 ,  0.10120741,\n",
       "        0.18838444, -0.47576693, -0.1534574 ,  0.17047003,  0.2188423 ,\n",
       "        0.0168531 , -0.18421897,  0.26747704, -0.11993828, -0.9130674 ,\n",
       "        0.64947337, -0.7410563 , -0.10080377,  0.22526655,  0.18692218,\n",
       "       -0.36043164, -0.09110308, -0.3994145 ,  0.45416135, -0.00969236,\n",
       "       -0.09333991, -0.3014148 ,  0.5472517 ,  0.31426555, -0.90162885,\n",
       "       -0.16782683,  0.18766019, -0.23694609, -0.38686585, -0.111312  ,\n",
       "       -0.0054246 ,  0.37413853,  0.12490209,  0.08435526,  0.10301585,\n",
       "       -0.72816217,  0.23746476,  0.05013841,  0.5897914 , -0.41633308,\n",
       "        0.18547097,  0.09270769, -0.00296172,  0.168964  ,  0.16536514,\n",
       "       -0.04768697, -0.18178432, -0.23277481,  0.17364207, -0.09183274,\n",
       "        0.04182599,  0.30223635, -0.22760531,  0.23835027, -0.01673064,\n",
       "        0.4549189 , -0.16585627, -0.35400277,  0.15092996, -0.65135324,\n",
       "        0.0037168 , -0.46376932, -0.16959183,  0.7989911 ,  0.02593151,\n",
       "       -0.42265755,  0.19370234,  0.4820017 , -0.17812918,  0.001715  ,\n",
       "        0.6336426 ,  0.36899042,  0.3462213 ,  0.06339736, -0.46114165,\n",
       "        0.22318317, -0.22144318,  0.35585666,  0.5287366 , -0.07251084,\n",
       "       -0.71381295, -0.8248421 ,  0.01596955, -0.13686767, -0.06921598,\n",
       "        0.40812296,  0.19561598, -0.82078516,  0.5211354 ,  0.25097978,\n",
       "        0.31135052, -0.28797865,  0.7245188 , -0.08686855,  0.53790605,\n",
       "        0.7913469 , -0.33426523, -0.50247234, -0.59662104,  0.06794044,\n",
       "       -0.10680964,  0.04344479, -0.56477475, -0.6546848 ,  0.0714702 ,\n",
       "        0.45469415, -0.64117616,  0.46200287,  0.6280637 , -0.2669358 ,\n",
       "        0.66250205,  0.43129537, -0.5908539 , -0.02151808, -0.35038817,\n",
       "        0.09052702, -0.04907465, -0.31467807,  0.3047696 , -0.06343833,\n",
       "       -0.48527762, -0.35846913,  0.1028186 ,  0.32362998, -0.55616003,\n",
       "        0.4005589 ,  0.88074833, -0.31066605, -0.00130638, -0.072743  ,\n",
       "        0.12502888, -0.02071061,  0.13106143,  0.7236884 ,  0.07703772,\n",
       "        0.31772774, -0.12685004, -0.0025726 , -0.08280589, -0.44577944,\n",
       "       -0.5149301 ,  0.3602599 , -0.06438425,  0.1464114 , -0.2839138 ,\n",
       "       -0.6331084 ,  0.97712183,  0.46991086, -0.34211516, -0.10651592,\n",
       "        0.35076895, -0.6273181 ,  0.5327946 , -0.1654709 ,  0.17281443],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = nlp(\"美しいはフランス\")\n",
    "word_sum2 = np.sum([tok.vector for tok in sent], axis=0)\n",
    "word_sum2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aa947664-d1d3-40a8-b9c3-c0a4bbfd3343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True, False,  True, False,  True,  True,  True, False,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True, False,  True, False, False,  True,  True, False,  True,\n",
       "        True, False,  True, False,  True,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True, False, False,  True, False, False,  True,  True,\n",
       "        True,  True, False,  True,  True,  True, False,  True, False,\n",
       "        True, False,  True, False,  True,  True,  True,  True, False,\n",
       "        True,  True,  True, False, False,  True, False,  True,  True,\n",
       "       False, False,  True,  True, False,  True,  True,  True, False,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True, False,  True,  True,  True, False,  True,  True,\n",
       "        True, False,  True,  True, False,  True, False,  True,  True,\n",
       "        True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True, False, False,  True, False, False,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True, False,  True,  True, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True, False, False,  True,  True,\n",
       "       False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "        True, False, False,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "        True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True, False])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sum == word_sum2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c7753ff4-6cfc-441b-9e3e-8b747e5a846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.376008\n",
      "-0.05035316\n",
      "-0.1202364\n",
      "0.205418448895216\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for tok in sent:\n",
    "    print(tok.vector[0])\n",
    "    t += tok.vector[0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23dc452e-3461-4b39-aba9-5b14da2e0779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4)\n",
      "(32, 10, 4)\n",
      "(32, 4)\n",
      "(32, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.random.normal([32, 10, 8])\n",
    "lstm = tf.keras.layers.LSTM(4)\n",
    "output = lstm(inputs)\n",
    "print(output.shape)\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(4, return_sequences=True, return_state=True)\n",
    "whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n",
    "print(whole_seq_output.shape)\n",
    "\n",
    "print(final_memory_state.shape)\n",
    "\n",
    "print(final_carry_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d80ac7f-83d8-4aa9-a815-e1b2ea3b25ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
