{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b60299-c959-479a-8d50-c3cb97e49d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学習者のID</th>\n",
       "      <th>学習者の性別</th>\n",
       "      <th>学習環境</th>\n",
       "      <th>作文テーマ</th>\n",
       "      <th>学習者の母語</th>\n",
       "      <th>日本語学習履歴</th>\n",
       "      <th>日本語レベル</th>\n",
       "      <th>テスト成績（文字語彙）</th>\n",
       "      <th>テスト成績（文法）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CG009</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CG011</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CG013</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CG015</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CG017</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>KN303</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>KN307</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>KN312</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>KN313</td>\n",
       "      <td>男</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>KN316</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    学習者のID 学習者の性別 学習環境            作文テーマ 学習者の母語   日本語学習履歴 日本語レベル テスト成績（文字語彙）  \\\n",
       "0    CG009      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "1    CG011      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "2    CG013      男   国外  外国語がうまくなる方法について    中国語      2年未満     上級           A   \n",
       "3    CG015      男   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "4    CG017      女   国外  外国語がうまくなる方法について    中国語      2年未満     中級           B   \n",
       "..     ...    ...  ...              ...    ...       ...    ...         ...   \n",
       "299  KN303      女   国内  外国語がうまくなる方法について    韓国語      2年未満     中級           X   \n",
       "300  KN307      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "301  KN312      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "302  KN313      男   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "303  KN316      女   国内  外国語がうまくなる方法について    韓国語      5年以上     上級           X   \n",
       "\n",
       "    テスト成績（文法）  \n",
       "0           C  \n",
       "1           B  \n",
       "2           A  \n",
       "3           B  \n",
       "4           A  \n",
       "..        ...  \n",
       "299         X  \n",
       "300         X  \n",
       "301         X  \n",
       "302         X  \n",
       "303         X  \n",
       "\n",
       "[304 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "path = \"data/register.xls\"\n",
    "labels = pd.read_excel(path)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5a45fc-5165-4705-a4ab-b9cd5bbd5da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'初級': 31, '上級': 124, '中級': 149})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "a = Counter(labels.日本語レベル)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98583a0b-403d-4212-8f28-f019e4a13f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学習者のID</th>\n",
       "      <th>学習者の性別</th>\n",
       "      <th>学習環境</th>\n",
       "      <th>作文テーマ</th>\n",
       "      <th>学習者の母語</th>\n",
       "      <th>日本語学習履歴</th>\n",
       "      <th>日本語レベル</th>\n",
       "      <th>テスト成績（文字語彙）</th>\n",
       "      <th>テスト成績（文法）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CG009</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CG011</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CG013</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CG015</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CG017</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>KN303</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>KN307</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>KN312</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>KN313</td>\n",
       "      <td>男</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>KN316</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    学習者のID 学習者の性別 学習環境            作文テーマ 学習者の母語   日本語学習履歴 日本語レベル テスト成績（文字語彙）  \\\n",
       "0    CG009      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "1    CG011      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "2    CG013      男   国外  外国語がうまくなる方法について    中国語      2年未満     上級           A   \n",
       "3    CG015      男   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "4    CG017      女   国外  外国語がうまくなる方法について    中国語      2年未満     中級           B   \n",
       "..     ...    ...  ...              ...    ...       ...    ...         ...   \n",
       "299  KN303      女   国内  外国語がうまくなる方法について    韓国語      2年未満     中級           X   \n",
       "300  KN307      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "301  KN312      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "302  KN313      男   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "303  KN316      女   国内  外国語がうまくなる方法について    韓国語      5年以上     上級           X   \n",
       "\n",
       "    テスト成績（文法）  \n",
       "0           C  \n",
       "1           B  \n",
       "2           A  \n",
       "3           B  \n",
       "4           A  \n",
       "..        ...  \n",
       "299         X  \n",
       "300         X  \n",
       "301         X  \n",
       "302         X  \n",
       "303         X  \n",
       "\n",
       "[192 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "label1 = labels.loc[labels.作文テーマ == \"外国語がうまくなる方法について\",:]\n",
    "label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae02239-03db-4330-b29d-d68fc8164afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'初級': 31, '上級': 61, '中級': 100})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Counter(label1.日本語レベル)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834e01d4-9aac-47c2-97bb-142ca7a152b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学習者のID</th>\n",
       "      <th>学習者の性別</th>\n",
       "      <th>学習環境</th>\n",
       "      <th>作文テーマ</th>\n",
       "      <th>学習者の母語</th>\n",
       "      <th>日本語学習履歴</th>\n",
       "      <th>日本語レベル</th>\n",
       "      <th>テスト成績（文字語彙）</th>\n",
       "      <th>テスト成績（文法）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>CG101</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>CG102</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>CG103</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CG104</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>CG105</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>KG151</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>KG152</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>KG153</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>KG154</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>KG155</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    学習者のID 学習者の性別 学習環境                作文テーマ 学習者の母語   日本語学習履歴 日本語レベル  \\\n",
       "76   CG101      男   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "77   CG102      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "78   CG103      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "79   CG104      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "80   CG105      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     上級   \n",
       "..     ...    ...  ...                  ...    ...       ...    ...   \n",
       "292  KG151      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語      5年以上     上級   \n",
       "293  KG152      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語  2年以上5年未満     上級   \n",
       "294  KG153      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語  2年以上5年未満     上級   \n",
       "295  KG154      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語      2年未満     中級   \n",
       "296  KG155      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語      5年以上     上級   \n",
       "\n",
       "    テスト成績（文字語彙） テスト成績（文法）  \n",
       "76            X         X  \n",
       "77            X         X  \n",
       "78            X         X  \n",
       "79            X         X  \n",
       "80            X         X  \n",
       "..          ...       ...  \n",
       "292           X         X  \n",
       "293           X         X  \n",
       "294           X         X  \n",
       "295           X         X  \n",
       "296           X         X  \n",
       "\n",
       "[112 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2 = labels.loc[labels.作文テーマ == \"インターネット時代に新聞や雑誌は必要か\",:]\n",
    "label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2be1bc8-8312-4010-b717-64244a03c21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'中級': 49, '上級': 63})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(label2.日本語レベル)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ec06dd-dcd9-4ff8-be26-c2eb5e3feef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['初級', '初級', '上級', '初級', '中級', '中級', '中級', '上級', '中級', '中級', '中級',\n",
       "        '上級', '中級', '中級', '中級', '初級', '中級', '上級', '初級', '初級', '中級', '中級',\n",
       "        '初級', '中級', '中級', '上級', '中級', '中級', '初級', '上級', '上級', '初級', '中級',\n",
       "        '中級', '上級', '中級', '中級', '初級', '初級', '中級', '上級', '中級', '上級', '中級',\n",
       "        '上級', '中級', '初級', '中級', '中級', '初級', '上級', '初級', '中級', '中級', '上級',\n",
       "        '初級', '初級', '上級', '上級', '中級', '中級', '中級', '上級', '中級', '中級', '上級',\n",
       "        '中級', '中級', '中級', '初級', '中級', '初級', '中級', '中級', '上級', '上級', '初級',\n",
       "        '上級', '中級', '中級', '上級', '中級', '中級', '中級', '中級', '中級', '中級', '中級',\n",
       "        '中級', '中級', '上級', '中級', '中級', '初級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '中級', '中級', '中級', '中級', '初級', '中級', '中級', '初級', '中級', '中級', '中級',\n",
       "        '上級', '中級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '中級', '中級',\n",
       "        '上級', '中級', '上級', '上級', '中級', '上級', '上級', '中級', '中級', '初級', '中級',\n",
       "        '中級', '上級', '中級', '上級', '上級', '上級', '中級', '上級', '中級', '上級', '上級',\n",
       "        '上級', '中級', '初級', '中級', '中級', '上級', '上級', '中級', '中級', '上級', '上級',\n",
       "        '上級', '中級', '初級', '中級', '中級', '中級', '上級', '中級', '初級', '中級', '中級',\n",
       "        '中級', '上級', '初級', '上級', '中級', '中級', '中級', '初級', '中級', '中級', '中級',\n",
       "        '中級', '初級', '中級', '初級', '初級', '中級', '中級', '中級', '中級', '上級', '中級',\n",
       "        '中級', '上級', '上級', '上級', '上級'], dtype=object),\n",
       " 192)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level1 = np.array(label1.日本語レベル)\n",
    "level1, len(level1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c847ac2a-1c01-4872-b656-12ebc25ad33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中級', '中級', '中級', '中級', '上級', '中級', '中級', '中級', '上級', '中級', '中級',\n",
       "        '中級', '中級', '上級', '上級', '中級', '中級', '中級', '上級', '中級', '中級', '中級',\n",
       "        '中級', '上級', '中級', '中級', '中級', '中級', '中級', '上級', '中級', '中級', '中級',\n",
       "        '上級', '中級', '中級', '中級', '中級', '中級', '中級', '中級', '上級', '中級', '中級',\n",
       "        '中級', '中級', '上級', '中級', '中級', '上級', '中級', '中級', '中級', '上級', '中級',\n",
       "        '上級', '上級', '上級', '上級', '中級', '上級', '上級', '上級', '中級', '上級', '上級',\n",
       "        '中級', '上級', '上級', '上級', '中級', '上級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '上級', '上級', '上級', '上級', '上級', '上級', '中級', '上級', '上級', '上級', '上級',\n",
       "        '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '中級', '上級'], dtype=object),\n",
       " 112)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level2 = np.array(label2.日本語レベル)\n",
    "level2, len(level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c86efb-bf58-4252-be6f-ca08ba4da7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "txt_path = \"data/txt/\"\n",
    "txt_topics = listdir(txt_path)\n",
    "\n",
    "txt_gaigo_path = txt_path + txt_topics[0]\n",
    "txt_internet_path = txt_path + txt_topics[1]\n",
    "\n",
    "txt_gaigo_files = listdir(txt_gaigo_path)\n",
    "txt_internet_files = listdir(txt_internet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5889ef08-8537-4546-a485-ddfdd2aa65b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os.path as osp\n",
    "# import re\n",
    "# gaigo_files = [f for f in listdir(osp.join(txt_path, txt_topics[0])) if f.endswith('.txt')]\n",
    "# gaigo = []\n",
    "# for gaigo_file in gaigo_files:\n",
    "#     # print(gaigo_file)\n",
    "#     with open(osp.join(txt_path, txt_topics[0], gaigo_file), \"r\", encoding=\"utf-8\") as f:\n",
    "#         lines = f.read()\n",
    "#         # type(lines)\n",
    "#         lines = re.sub('\\n', '', lines)\n",
    "#         lines = re.sub('\\u3000', '', lines)\n",
    "#     gaigo.append(lines)\n",
    "# # type(gaigo[0])\n",
    "# # gaigo[0][0]\n",
    "\n",
    "import os.path as osp\n",
    "import re\n",
    "gaigo_files = [f for f in listdir(osp.join(txt_path, txt_topics[0])) if f.endswith('.txt')]\n",
    "gaigo = []\n",
    "for gaigo_file in gaigo_files:\n",
    "    # print(gaigo_file)\n",
    "    with open(osp.join(txt_path, txt_topics[0], gaigo_file), \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read()\n",
    "        # type(lines)\n",
    "        lines = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", lines)\n",
    "        lines = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}・［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", lines)\n",
    "        lines = lines.replace(\" \", \"\")\n",
    "\n",
    "\n",
    "    gaigo.append(lines)\n",
    "# type(gaigo[0])\n",
    "len(gaigo)\n",
    "\n",
    "# 注意。注釈は削除していない。記号のみ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec8cc9c2-1357-4ff9-90ce-b5585ec755b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import re\n",
    "# internet_files = [f for f in listdir(osp.join(txt_path, txt_topics[1])) if f.endswith('.txt')]\n",
    "# internet = []\n",
    "# for internet_file in internet_files:\n",
    "#     with open(osp.join(txt_path, txt_topics[1], internet_file), \"r\", encoding=\"utf-8\") as f:\n",
    "#         lines = f.read()\n",
    "#         # print(lines)\n",
    "#         lines = lines.strip('\\ufeff□')\n",
    "#         lines = re.sub('■', '', lines)\n",
    "#         lines = re.sub('\\n', '', lines)\n",
    "#         lines = re.sub('□', '', lines)\n",
    "#         lines = re.sub('\\u3000', '', lines)\n",
    "        \n",
    "#     internet.append(lines)\n",
    "\n",
    "# internet[0]\n",
    "\n",
    "import re\n",
    "internet_files = [f for f in listdir(osp.join(txt_path, txt_topics[1])) if f.endswith('.txt')]\n",
    "internet = []\n",
    "for internet_file in internet_files:\n",
    "    with open(osp.join(txt_path, txt_topics[1], internet_file), \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read()\n",
    "        # print(lines)\n",
    "        lines = lines.strip('\\ufeff□')\n",
    "        lines = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", lines)\n",
    "        lines = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}・［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", lines)\n",
    "        lines = lines.replace(\" \", \"\")\n",
    "        \n",
    "    internet.append(lines)\n",
    "\n",
    "len(internet)\n",
    "# + delete ・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6080253b-8225-4834-b212-f6da98da0835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "124\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict as dd\n",
    "text_tagged = dd(list)\n",
    "for level, txt in zip(level1, gaigo):\n",
    "    text_tagged[level].append(txt)\n",
    "\n",
    "for level, txt in zip(level2, internet):\n",
    "    text_tagged[level].append(txt)\n",
    "\n",
    "text_tagged_dict = dict(text_tagged)\n",
    "# text_tagged_dict\n",
    "for level in text_tagged_dict.keys():\n",
    "    print(len(text_tagged_dict[level]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc35f04-43f2-49e7-929c-e29f49948bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in text_tagged_dict.keys():\n",
    "    text_tagged_dict[level] = \"\".join(text_tagged_dict[level])\n",
    "        \n",
    "# text_tagged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec0de867-5c50-4c98-b8d6-43dd0b155c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "# with open('text_tagged_dict2_joined.pickle', 'wb') as f:\n",
    "#     pickle.dump(text_tagged_dict, f)\n",
    "    \n",
    "text_tagged_dict2_joined = pickle.load(open('text_tagged_dict2_joined.pickle', 'rb'))\n",
    "# text_tagged_dict2_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cd19413-0a78-491a-a043-5725826708be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# text_length_dist = [len(text) for level in text_tagged_dict2.keys() for text in text_tagged_dict2[level]]\n",
    "# # [len(text) for text in text_tagged_dict2[\"初級\"]]\n",
    "# # text_length_dist\n",
    "\n",
    "# # np.max(text_length_dist) = 914\n",
    "# # to determine how many paddings we should add \n",
    "# plt.hist(text_length_dist, bins = np.arange(0, 1000, 10))\n",
    "# plt.show()\n",
    "# # we can determine the max length of texts as 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7df0bec8-4824-42bf-bc32-0adffa428ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'私は大学日本語科の一'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tagged_dict2_joined[\"初級\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1354c976-0341-4a4d-96d5-57a866b755ff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_tagged_joined2 = {\"初級\": list(), \"上級\": list(), \"中級\": list()}\n",
    "text_tagged_joined2[\"初級\"].append(text_tagged_dict2_joined[\"初級\"])\n",
    "text_len_advanced = len(text_tagged_dict2_joined[\"上級\"])\n",
    "text_len_intermediate = len(text_tagged_dict2_joined[\"中級\"])\n",
    "\n",
    "for i in range(5):\n",
    "    text_tagged_joined2[\"上級\"].append(text_tagged_dict2_joined[\"上級\"][int(i * text_len_advanced / 5) : int((i + 1) * text_len_advanced / 5)])\n",
    "\n",
    "for i in range(6):\n",
    "    text_tagged_joined2[\"中級\"].append(text_tagged_dict2_joined[\"中級\"][int(i * text_len_intermediate / 6) : int((i + 1) * text_len_intermediate / 6)])\n",
    "\n",
    "# text_tagged_joined2[\"中級\"][5]\n",
    "# text_tagged_dict2_joined[\"中級\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6bd5880-8a56-437d-9d98-1b45a7244c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72690"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_len_advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5650580b-c46f-4f42-956f-103d996a6ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84307"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_len_intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ff682c6-ce89-44ad-a2e1-38eb842e4883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13407\n",
      "14538\n",
      "14051\n"
     ]
    }
   ],
   "source": [
    "for text in text_tagged_joined2.values():\n",
    "    print(len(text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68d1c9a7-b298-42ed-9bde-70d575e3d680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:30<00:00, 10.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('ja_ginza')\n",
    "\n",
    "text_vectorized = {}\n",
    "for level in tqdm(text_tagged_joined2.keys()):\n",
    "    text_vectorized[level] = []\n",
    "    for text in text_tagged_joined2[level]:\n",
    "        tokenized = nlp(text)\n",
    "        for token in tokenized:\n",
    "            text_vectorized[level].append(token.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfc63193-6fab-4181-92dd-3d0452c35c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7655\n",
      "41449\n",
      "48524\n"
     ]
    }
   ],
   "source": [
    "# for i in text_vectorized.values():\n",
    "#     print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a2682a-7ded-4e4e-840e-64046523a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "# with open('text_vectorized_joined.pickle', 'wb') as f:\n",
    "#     pickle.dump(text_vectorized, f)\n",
    "    \n",
    "text_vectorized2 = pickle.load(open('text_vectorized_joined.pickle', 'rb'))\n",
    "# text_vectorized2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dd96490-8457-4531-83a1-fbfa68c1e4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "window_size = 15\n",
    "n_sample = 1000 # less than or equal to (len(text_vectorized2[\"初級\"]) - window_size)\n",
    "\n",
    "\n",
    "text_transformed = {}\n",
    "for level, vector in text_vectorized2.items():\n",
    "    text_transformed[level] = []\n",
    "    start_index_list = np.random.permutation(list(range(len(text_vectorized2[level]) - window_size)))\n",
    "    for i in range(n_sample):\n",
    "        start_index = start_index_list[i]\n",
    "        # print(start_index)\n",
    "        chunks = []\n",
    "        for index in range(start_index, start_index + window_size):\n",
    "            chunks.append(text_vectorized2[level][index])\n",
    "        text_transformed[level].append(chunks)\n",
    "    text_transformed[level] = np.array(text_transformed[level])\n",
    "    \n",
    "# print(text_transformed)\n",
    "# text_transformed[\"初級\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93216d7f-f969-4d44-ab58-64c423366e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初級 (1000, 15, 300)\n",
      "上級 (1000, 15, 300)\n",
      "中級 (1000, 15, 300)\n"
     ]
    }
   ],
   "source": [
    "for level, value in text_transformed.items():\n",
    "    print(level, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5468d86-f1de-477c-be4c-758fa8981c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "# with open('text_transformed_window_size15_sample_size1000.pickle', 'wb') as f:\n",
    "#     pickle.dump(text_transformed, f)\n",
    "    \n",
    "text_transformed2 = pickle.load(open('text_transformed_window_size15_sample_size1000.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "751d8c39-6f9d-4150-8ac9-2c152a81d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_vectors = []\n",
    "for level, vectors in text_transformed2.items():\n",
    "    for vector in vectors:\n",
    "        category_vectors.append((level, vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24dc7fa5-a9b2-4559-9d34-bf2279a54528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[0.47779918, -0.290014, 0.35474735, -0.094679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[-0.11235832, -0.04813227, -0.2808526, 0.0092...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[-0.084042855, -0.03873583, 0.013529049, -0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat                                              value\n",
       "0  初級  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "1  初級  [[0.47779918, -0.290014, 0.35474735, -0.094679...\n",
       "2  初級  [[-0.11235832, -0.04813227, -0.2808526, 0.0092...\n",
       "3  初級  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "4  初級  [[-0.084042855, -0.03873583, 0.013529049, -0.1..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "key, value = zip(*category_vectors)\n",
    "data2 = pd.DataFrame({'cat': key, 'value': value})\n",
    "\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9d0590-7607-4165-8ab9-7254250d7d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in data2.value:\n",
    "#     print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e631c80f-2b73-4a17-a3a1-94d696166343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600, 2), (2400, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data2.sample(frac=0.2, random_state=200)\n",
    "train = data2.drop(test.index)\n",
    "\n",
    "test.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8a5af5-616a-4893-831b-aaeb36cb07ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 15, 300), (2400, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "le.fit(data2.cat)\n",
    "y_train = le.transform(train.cat).reshape(-1, 1)\n",
    "ohe.fit(y_train)\n",
    "y_train = ohe.transform(y_train).todense()\n",
    "\n",
    "X_train = np.array([x for x in train.value])\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ef04c3-43f6-4792-9ae1-ebe94318b5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 256)               570368    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               77100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 648,371\n",
      "Trainable params: 648,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "n_rnn = window_size = 15 # 時系列の数\n",
    "batch_size = 128\n",
    "epochs = 20  #epochsは、多いほど、精密に学習するが、重くなるため今回は小さくしている\n",
    "n_mid = 256  # 中間層のニューロン数\n",
    "data_dim = 300\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, data_dim)))\n",
    "model_lstm.add(Dense(data_dim, activation=\"relu\"))\n",
    "model_lstm.add(Dense(3, activation=\"softmax\"))\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13267e31-ab0e-4cac-83fd-49d99eccb2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "75/75 [==============================] - 5s 30ms/step - loss: 1.0410 - accuracy: 0.4146\n",
      "Epoch 2/20\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.9746 - accuracy: 0.4900\n",
      "Epoch 3/20\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.9483 - accuracy: 0.5171\n",
      "Epoch 4/20\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.9178 - accuracy: 0.5379\n",
      "Epoch 5/20\n",
      "75/75 [==============================] - 2s 30ms/step - loss: 0.8623 - accuracy: 0.5750\n",
      "Epoch 6/20\n",
      "75/75 [==============================] - 2s 30ms/step - loss: 0.8410 - accuracy: 0.5792\n",
      "Epoch 7/20\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.7817 - accuracy: 0.6300\n",
      "Epoch 8/20\n",
      "75/75 [==============================] - 2s 30ms/step - loss: 0.7290 - accuracy: 0.6650\n",
      "Epoch 9/20\n",
      "75/75 [==============================] - 2s 30ms/step - loss: 0.6839 - accuracy: 0.6837\n",
      "Epoch 10/20\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.6105 - accuracy: 0.7267\n",
      "Epoch 11/20\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.5453 - accuracy: 0.7513\n",
      "Epoch 12/20\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.4519 - accuracy: 0.8075\n",
      "Epoch 13/20\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.3865 - accuracy: 0.8363\n",
      "Epoch 14/20\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.3041 - accuracy: 0.8763\n",
      "Epoch 15/20\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.2547 - accuracy: 0.8975\n",
      "Epoch 16/20\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1863 - accuracy: 0.9292\n",
      "Epoch 17/20\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.1458 - accuracy: 0.9483\n",
      "Epoch 18/20\n",
      "75/75 [==============================] - 2s 30ms/step - loss: 0.1095 - accuracy: 0.9575\n",
      "Epoch 19/20\n",
      "75/75 [==============================] - 2s 31ms/step - loss: 0.0930 - accuracy: 0.9654\n",
      "Epoch 20/20\n",
      "75/75 [==============================] - 2s 32ms/step - loss: 0.0624 - accuracy: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204cff9a0d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model_lstm.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8060b53-2c09-4e0d-a201-b22ffff3ca61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600, 15, 300), (600, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "le.fit(data2.cat)\n",
    "y_test = le.transform(test.cat).reshape(-1, 1)\n",
    "ohe.fit(y_test)\n",
    "y_test = ohe.transform(y_test).todense()\n",
    "\n",
    "X_test = np.array([x for x in test.value])\n",
    "\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f229a42-0179-479b-afd1-d0f07718eb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5066666666666667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(np.argmax(model_lstm.predict(X_test), axis=1), np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0684f0ce-434c-42bf-b956-95e385e56f95",
   "metadata": {},
   "source": [
    "The accuracy was 50.7%. This needs fine-tuning. Possible suggestions for fine-tuning are grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daec05e5-f8d7-4983-b186-ba4f1b6dff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 2, 2, 2, 0, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 0, 1, 2, 0,\n",
       "       0, 0, 0, 1, 1, 2, 1, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 2, 1, 1, 2, 2,\n",
       "       0, 2, 2, 0, 0, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 0, 1, 1, 0, 0,\n",
       "       2, 1, 0, 0, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 0, 0, 1, 2, 0, 2, 2, 2,\n",
       "       0, 2, 2, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 0, 1, 1, 1, 0, 2, 1, 2,\n",
       "       1, 1, 1, 0, 0, 0, 2, 2, 1, 2, 0, 2, 1, 0, 1, 2, 2, 2, 1, 2, 2, 2,\n",
       "       0, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 0, 2, 0, 1, 0,\n",
       "       0, 2, 0, 1, 0, 0, 0, 0, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 2,\n",
       "       0, 1, 2, 0, 2, 1, 0, 1, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 1, 2, 0, 0,\n",
       "       0, 2, 1, 0, 1, 0, 1, 0, 2, 1, 0, 0, 1, 2, 1, 0, 2, 2, 1, 1, 0, 0,\n",
       "       0, 0, 2, 1, 0, 0, 1, 2, 2, 2, 2, 1, 0, 2, 0, 2, 2, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 2, 0, 0, 1, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 1, 1, 2, 0, 2,\n",
       "       1, 2, 1, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 2, 2, 1, 0, 0,\n",
       "       1, 2, 2, 1, 1, 0, 1, 0, 1, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 1, 1, 1,\n",
       "       1, 0, 2, 2, 0, 0, 1, 0, 2, 0, 0, 2, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1,\n",
       "       2, 1, 1, 2, 0, 1, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 0, 1, 1, 2,\n",
       "       1, 0, 2, 1, 2, 1, 1, 1, 2, 1, 0, 0, 2, 1, 0, 2, 1, 0, 1, 0, 1, 0,\n",
       "       2, 2, 1, 2, 2, 0, 0, 1, 2, 1, 1, 0, 2, 2, 1, 0, 1, 0, 0, 2, 1, 1,\n",
       "       2, 2, 1, 2, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 0, 2, 1, 0, 0, 0, 1, 1,\n",
       "       2, 0, 1, 0, 0, 2, 1, 2, 0, 1, 0, 1, 1, 2, 0, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2, 2, 1, 2, 2, 0, 1, 1, 1, 2, 0, 2, 0, 2, 2, 0, 1, 2, 2, 1, 1, 1,\n",
       "       1, 0, 2, 1, 0, 1, 1, 2, 0, 2, 2, 2, 2, 0, 0, 1, 1, 0, 2, 2, 2, 2,\n",
       "       2, 0, 1, 2, 0, 1, 1, 2, 0, 2, 2, 0, 0, 1, 1, 2, 1, 1, 1, 2, 2, 0,\n",
       "       0, 1, 1, 2, 1, 0, 0, 1, 0, 0, 1, 2, 1, 2, 2, 1, 2, 0, 2, 0, 1, 0,\n",
       "       1, 0, 1, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 1, 2, 0, 1, 2, 2, 2, 1,\n",
       "       2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2,\n",
       "       1, 0, 1, 0, 2, 1, 1, 1, 2, 1, 1, 2, 0, 1, 2, 1, 1, 0, 0, 2, 2, 0,\n",
       "       1, 2, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model_lstm.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eec2547b-32ce-4d9a-871d-80c38b53aa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 2, 1, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 1, 2, 1, 0, 1, 2, 2,\n",
       "         0, 1, 1, 0, 1, 1, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 0, 2, 2, 0, 2,\n",
       "         0, 1, 0, 1, 2, 2, 1, 2, 2, 0, 0, 2, 2, 0, 2, 0, 1, 2, 2, 0, 2,\n",
       "         0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 1, 0, 0, 2, 1,\n",
       "         0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1,\n",
       "         1, 1, 2, 0, 2, 0, 1, 0, 0, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "         2, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 0, 0, 2, 1, 1, 1, 0, 2, 2, 2,\n",
       "         1, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 2, 0,\n",
       "         2, 1, 1, 0, 1, 1, 0, 0, 0, 1, 2, 1, 2, 2, 1, 2, 0, 2, 0, 1, 0,\n",
       "         2, 0, 0, 2, 2, 1, 0, 0, 1, 0, 2, 1, 0, 2, 1, 1, 0, 1, 0, 2, 2,\n",
       "         0, 2, 0, 1, 0, 2, 1, 1, 1, 0, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 2,\n",
       "         1, 0, 2, 1, 2, 2, 2, 0, 1, 2, 0, 0, 1, 1, 2, 1, 0, 0, 2, 2, 2,\n",
       "         2, 0, 1, 0, 2, 2, 1, 1, 0, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2,\n",
       "         1, 0, 1, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 0, 0, 2, 1, 0, 0, 0, 1,\n",
       "         0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 2, 2, 0, 1, 1, 0, 2, 2, 0, 1, 1,\n",
       "         0, 1, 0, 1, 0, 0, 2, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 1, 1,\n",
       "         1, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 1, 2, 1, 1, 2, 0, 0, 1, 2, 1,\n",
       "         0, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 2,\n",
       "         2, 0, 0, 2, 2, 1, 0, 1, 2, 2, 2, 1, 0, 0, 0, 2, 1, 1, 1, 0, 1,\n",
       "         2, 1, 1, 2, 2, 2, 2, 1, 1, 0, 2, 2, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 2, 0, 2, 0, 0, 2, 2,\n",
       "         0, 2, 2, 0, 0, 1, 0, 2, 1, 0, 0, 1, 2, 2, 0, 2, 2, 2, 2, 1, 1,\n",
       "         2, 0, 0, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 0, 1, 2, 0, 0, 1, 2, 2,\n",
       "         2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 2, 1, 0, 1, 0, 2, 0, 1, 2, 0,\n",
       "         0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 1, 1, 0, 2, 1, 2, 0, 2, 2, 0, 2,\n",
       "         1, 0, 2, 2, 0, 1, 0, 2, 2, 1, 0, 1, 0, 2, 0, 0, 2, 2, 0, 0, 1,\n",
       "         2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0,\n",
       "         1, 2, 1, 1, 2, 1, 2, 0, 1, 2, 0, 0, 2, 1, 0, 1, 2, 0, 2, 2, 2,\n",
       "         1, 0, 0, 2, 2, 0, 1, 1, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test, axis=1).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e587ef6d-a7fa-4464-b8fb-5af9921fbb8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "188b9a25-9234-4569-a440-03b0b59439b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "# from keras.optimizers import Adam, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09d1519d-ab7c-48f1-b0d1-9b58d6628412",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 15\n",
    "n_sample = 1000 # less than or equal to (len(text_vectorized2[\"初級\"]) - window_size)\n",
    "\n",
    "n_rnn = window_size  # 時系列の数\n",
    "batch_size = 128\n",
    "epochs = 20  #epochsは、多いほど、精密に学習するが、重くなるため今回は小さくしている\n",
    "n_mid = 256  # 中間層のニューロン数\n",
    "data_dim = 300\n",
    "\n",
    "input_dim = (n_rnn, data_dim)\n",
    "output_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb800270-72b4-45d2-9528-96c6bf6c8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_model(activation=\"relu\", optimizer=\"adam\", hidden_layer_sizes=(100, 100)):\n",
    "    model = Sequential()\n",
    "    firstflag = True\n",
    "    for dim in hidden_layer_sizes:\n",
    "        if firstflag:\n",
    "            model.add(LSTM(n_mid, input_shape=(n_rnn, data_dim), return_sequences=True, activation=activation))\n",
    "            model.add(Dropout(0.2))\n",
    "            firstflag = False\n",
    "        else:\n",
    "            model.add(LSTM(n_mid, return_sequences=True, activation=activation))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(n_mid, activation=activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(output_dim, activation=\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d75a5336-7e0b-4aac-8835-c2fb553779d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = [\"relu\", \"tanh\"]\n",
    "optimizer = [\"adam\", \"adagrad\", \"sgd\", \"RMSprop\", \"Adamax\"]\n",
    "hidden_layer_sizes = [(50, 50, 50, 50), (50, 50, 50), (50, 50), (50, ) ]\n",
    "nb_epoch = [20, 25]\n",
    "batch_size = [128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b9751e1-4c58-4acd-9068-f7ca0ab799a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fic2023150.FIC.009\\AppData\\Local\\Temp\\ipykernel_2724\\2440950011.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model2 = KerasClassifier(build_fn=language_model, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model2 = KerasClassifier(build_fn=language_model, verbose=0)\n",
    "param_grid = dict(activation=activation, \n",
    "                  optimizer=optimizer, \n",
    "                  hidden_layer_sizes=hidden_layer_sizes, \n",
    "                  nb_epoch=nb_epoch, \n",
    "                  batch_size=batch_size,)\n",
    "grid = GridSearchCV(estimator=model2, param_grid=param_grid, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7763d3e-26f0-4cf9-8298-bf378664feb3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adam; total time=   8.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adam; total time=  13.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adam; total time=  16.3s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adam; total time=  18.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adam; total time=  22.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adagrad; total time=  23.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adagrad; total time=  25.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adagrad; total time=  27.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adagrad; total time=  25.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adagrad; total time=  27.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=sgd; total time=  28.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=sgd; total time=  28.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=sgd; total time=  22.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=sgd; total time=  24.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=sgd; total time=  24.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  25.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  28.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  25.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  28.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  27.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=Adamax; total time=  29.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=Adamax; total time=  20.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=Adamax; total time=  21.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=Adamax; total time=  21.9s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=Adamax; total time=  22.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=  23.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=  23.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=  22.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=  22.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adam; total time=  23.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=  23.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=  24.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=  24.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=  25.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=  24.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=  26.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=  26.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=  24.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=  26.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=sgd; total time=  26.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=  26.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=  27.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=  26.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=  27.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=  27.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=  27.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=  27.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=  27.9s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=  25.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=  26.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adam; total time=  19.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adam; total time=  20.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adam; total time=  19.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adam; total time=  20.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adam; total time=  20.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adagrad; total time=  20.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adagrad; total time=  20.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adagrad; total time=  20.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adagrad; total time=  20.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adagrad; total time=  21.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=sgd; total time=  21.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=sgd; total time=  20.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=sgd; total time=  20.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=sgd; total time=  20.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=sgd; total time=  20.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  21.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  21.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  22.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  21.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  21.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=Adamax; total time=  20.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=Adamax; total time=  19.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=Adamax; total time=  19.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=Adamax; total time=  19.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=Adamax; total time=  20.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=  19.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=  20.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=  21.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=  21.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adam; total time=  21.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=  21.3s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=  21.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=  21.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=  21.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=adagrad; total time=  22.3s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=  21.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=  22.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=  22.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=  21.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=sgd; total time=  21.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=  23.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=  22.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=  22.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=  22.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=RMSprop; total time=  22.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=  22.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=  22.3s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=  21.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=  21.3s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=25, optimizer=Adamax; total time=  21.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adam; total time=  15.3s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adam; total time=  15.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adam; total time=  15.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adam; total time=  16.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adam; total time=  15.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adagrad; total time=  15.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adagrad; total time=  15.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adagrad; total time=  15.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adagrad; total time=  16.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adagrad; total time=  15.9s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=sgd; total time=  16.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=sgd; total time=  16.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=sgd; total time=  16.3s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=sgd; total time=  16.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=sgd; total time=  16.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=RMSprop; total time=  16.9s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=RMSprop; total time=  17.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=RMSprop; total time=  17.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=RMSprop; total time=  17.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=RMSprop; total time=  17.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=Adamax; total time=  16.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=Adamax; total time=  17.4s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=Adamax; total time=  17.9s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=Adamax; total time=  17.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=Adamax; total time=  17.9s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=adam; total time=  18.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=adam; total time=  18.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=adam; total time=  17.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=adam; total time=  16.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=adam; total time=  16.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=adagrad; total time=  16.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=adagrad; total time=  17.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=adagrad; total time=  16.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=adagrad; total time=  17.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=adagrad; total time=  17.3s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=sgd; total time=  16.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=sgd; total time=  15.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=sgd; total time=  15.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=sgd; total time=  16.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=sgd; total time=  15.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=RMSprop; total time=  16.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=RMSprop; total time=  16.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=RMSprop; total time=  16.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=RMSprop; total time=  15.8s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=RMSprop; total time=  16.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=Adamax; total time=  16.3s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=Adamax; total time=  15.9s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=Adamax; total time=  16.5s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=Adamax; total time=  16.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=25, optimizer=Adamax; total time=  16.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adam; total time=   9.9s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adam; total time=  10.2s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adam; total time=  10.0s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adam; total time=   9.9s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adam; total time=   9.7s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adagrad; total time=  10.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adagrad; total time=   9.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adagrad; total time=  10.3s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adagrad; total time=   9.6s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adagrad; total time=   9.9s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=sgd; total time=  10.1s\n",
      "[CV] END activation=relu, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=sgd; total time=   9.6s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\wrappers\\scikit_learn.py:248\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape for y: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\wrappers\\scikit_learn.py:175\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m fit_args \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_sk_params(Sequential\u001b[38;5;241m.\u001b[39mfit))\n\u001b[0;32m    173\u001b[0m fit_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 175\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d46d01e3-41a5-4369-84e2-6dc3f5b1976e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000001B692177970>,\n",
       "             param_grid={'activation': ['relu', 'sigmoid'],\n",
       "                         'batch_size': [5, 10],\n",
       "                         'hidden_layer_sizes': [(50, 50, 50, 50), (50, 50, 50),\n",
       "                                                (100, 100), (50,)],\n",
       "                         'nb_epoch': [10, 25],\n",
       "                         'optimizer': ['adam', 'adagrad', 'sgd', 'RMSprop',\n",
       "                                       'Adamax']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "218e1f12-84e4-46fa-a483-7b7052858bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 5,\n",
       " 'hidden_layer_sizes': (50,),\n",
       " 'nb_epoch': 25,\n",
       " 'optimizer': 'RMSprop'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03f0a4b8-17e1-4569-bb6e-f3578e83f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = [\"tanh\"]\n",
    "optimizer = [\"adam\", \"RMSprop\"]\n",
    "hidden_layer_sizes = [(50, 50, 50, 50), (50, 50, 50), (50, 50), (50, ) ]\n",
    "nb_epoch = [20]\n",
    "batch_size = [128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "befa9be4-3b79-4fe2-8723-5378f6404c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fic2023150.FIC.009\\AppData\\Local\\Temp\\ipykernel_2724\\4269649812.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model3 = KerasClassifier(build_fn=language_model, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model3 = KerasClassifier(build_fn=language_model, verbose=0)\n",
    "param_grid = dict(activation=activation, \n",
    "                  optimizer=optimizer, \n",
    "                  hidden_layer_sizes=hidden_layer_sizes, \n",
    "                  nb_epoch=nb_epoch, \n",
    "                  batch_size=batch_size,)\n",
    "grid2 = GridSearchCV(estimator=model3, param_grid=param_grid, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03cdd4bf-dae6-4ae9-9421-c6cddb54bd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adam; total time=  29.8s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adam; total time=  33.0s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adam; total time=  32.4s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adam; total time=  34.1s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=adam; total time=  32.6s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  33.9s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  35.5s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  37.3s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  36.2s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  36.2s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adam; total time=  27.9s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adam; total time=  26.4s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adam; total time=  27.0s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adam; total time=  26.5s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=adam; total time=  26.5s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  28.1s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  27.4s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  28.0s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  27.2s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50, 50), nb_epoch=20, optimizer=RMSprop; total time=  27.4s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adam; total time=  19.9s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adam; total time=  20.6s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adam; total time=  20.3s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adam; total time=  20.2s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=adam; total time=  20.0s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=RMSprop; total time=  20.1s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=RMSprop; total time=  20.5s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=RMSprop; total time=  22.1s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=RMSprop; total time=  22.6s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50, 50), nb_epoch=20, optimizer=RMSprop; total time=  22.9s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adam; total time=  15.2s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adam; total time=  15.7s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adam; total time=  15.2s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adam; total time=  15.3s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=adam; total time=  15.9s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=RMSprop; total time=  15.4s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=RMSprop; total time=  15.7s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=RMSprop; total time=  15.2s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=RMSprop; total time=  15.2s\n",
      "[CV] END activation=tanh, batch_size=128, hidden_layer_sizes=(50,), nb_epoch=20, optimizer=RMSprop; total time=  15.3s\n"
     ]
    }
   ],
   "source": [
    "grid_result2 = grid2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09bea497-e7a3-4056-a92d-8eb76570da7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x00000204DE286F70>,\n",
       "             param_grid={'activation': ['tanh'], 'batch_size': [128],\n",
       "                         'hidden_layer_sizes': [(50, 50, 50, 50), (50, 50, 50),\n",
       "                                                (50, 50), (50,)],\n",
       "                         'nb_epoch': [20], 'optimizer': ['adam', 'RMSprop']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b86c741-65e2-42c9-8a0b-b8a5941f7a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'batch_size': 128,\n",
       " 'hidden_layer_sizes': (50, 50),\n",
       " 'nb_epoch': 20,\n",
       " 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc33a126-9bba-418e-b9cf-79992f40cbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tanh'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result2.best_params_['activation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca40a6a2-bfde-4a25-a8f2-3e0350709107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 [==============================] - 25s 1s/step - loss: 1.0656 - accuracy: 0.4283\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 1.0143 - accuracy: 0.4812\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.9789 - accuracy: 0.4883\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.9697 - accuracy: 0.4888\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.9405 - accuracy: 0.5225\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.9164 - accuracy: 0.5379\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.8936 - accuracy: 0.5412\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.8651 - accuracy: 0.5750\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.8640 - accuracy: 0.5633\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.8880 - accuracy: 0.5554\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.8761 - accuracy: 0.5638\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.8234 - accuracy: 0.5962\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.8124 - accuracy: 0.6083\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.7573 - accuracy: 0.6346\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.7080 - accuracy: 0.6671\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.6693 - accuracy: 0.6862\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.6586 - accuracy: 0.6938\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.6106 - accuracy: 0.7262\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.5704 - accuracy: 0.7471\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.5548 - accuracy: 0.7592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20486c91940>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = language_model(activation=grid_result2.best_params_['activation'], \n",
    "                   optimizer=grid_result2.best_params_['optimizer'], \n",
    "                   hidden_layer_sizes=grid_result2.best_params_['hidden_layer_sizes'])\n",
    "\n",
    "model4.fit(X_train, y_train, epochs=grid_result2.best_params_['nb_epoch'], batch_size=grid_result2.best_params_['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19430dd2-c51e-42a5-becb-3395cd66e0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 3s 106ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.53"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# accuracy_score(model2.predict(test_X), test_y)\n",
    "accuracy_score(np.argmax(model4.predict(X_test), axis=1), np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffb180da-9697-49c9-a2e4-d1d67b31c74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 2s 104ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 1, 2, 1,\n",
       "        0, 0, 0, 2, 0, 2, 0, 1, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2,\n",
       "        0, 2, 2, 0, 1, 2, 2, 2, 0, 2, 1, 0, 2, 0, 0, 2, 1, 0, 2, 0, 0, 0,\n",
       "        2, 0, 0, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 1, 0, 0, 1, 0, 2, 2, 2, 2,\n",
       "        0, 2, 2, 2, 1, 2, 0, 0, 1, 2, 2, 0, 2, 0, 2, 0, 2, 1, 0, 2, 1, 2,\n",
       "        0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "        1, 2, 1, 0, 1, 1, 2, 2, 2, 0, 0, 1, 1, 2, 2, 2, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 0, 1, 2, 1, 2, 2, 1, 2, 0, 0, 0, 1, 0, 1, 1,\n",
       "        0, 2, 2, 0, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0,\n",
       "        2, 2, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 2, 2, 1, 1, 0, 0,\n",
       "        2, 0, 2, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 1, 2, 0,\n",
       "        0, 2, 1, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 1, 2, 2, 1, 1, 1, 2, 2, 2,\n",
       "        0, 2, 2, 2, 2, 1, 2, 1, 0, 0, 0, 0, 2, 2, 2, 0, 1, 1, 2, 2, 0, 1,\n",
       "        0, 2, 2, 1, 2, 0, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0,\n",
       "        2, 1, 2, 2, 2, 0, 2, 0, 1, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 0, 0, 2, 0, 0, 2, 1, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 1, 1, 2, 2,\n",
       "        1, 1, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2, 2,\n",
       "        2, 2, 1, 2, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0,\n",
       "        2, 0, 2, 2, 2, 0, 2, 2, 2, 1, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 2, 2,\n",
       "        2, 1, 0, 0, 0, 1, 2, 2, 0, 1, 0, 2, 0, 2, 0, 2, 2, 0, 2, 1, 0, 2,\n",
       "        2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0, 2, 0, 1, 0, 0, 2, 2, 2, 2, 2, 1,\n",
       "        2, 0, 2, 1, 0, 2, 0, 2, 1, 0, 0, 2, 2, 0, 2, 2, 1, 0, 2, 2, 2, 0,\n",
       "        0, 0, 2, 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 1, 2, 0, 0,\n",
       "        0, 1, 1, 2, 1, 2, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0, 2, 0, 2, 0, 1, 2,\n",
       "        2, 0, 2, 0, 0, 2, 2, 2, 0, 1, 2, 2, 0, 2, 2, 1, 0, 1, 0, 2, 2, 2,\n",
       "        0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 1, 2, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2,\n",
       "        1, 0, 0, 0, 2, 1, 0, 1, 2, 0, 1, 2, 2, 1, 2, 1, 2, 2, 0, 2, 2, 1,\n",
       "        1, 2, 0, 1, 0, 1], dtype=int64),\n",
       " matrix([[1, 1, 2, 1, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 1, 2, 1, 0, 1, 2, 2,\n",
       "          0, 1, 1, 0, 1, 1, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 0, 2, 2, 0, 2,\n",
       "          0, 1, 0, 1, 2, 2, 1, 2, 2, 0, 0, 2, 2, 0, 2, 0, 1, 2, 2, 0, 2,\n",
       "          0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 1, 0, 0, 2, 1,\n",
       "          0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1,\n",
       "          1, 1, 2, 0, 2, 0, 1, 0, 0, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "          2, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 0, 0, 2, 1, 1, 1, 0, 2, 2, 2,\n",
       "          1, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 2, 0,\n",
       "          2, 1, 1, 0, 1, 1, 0, 0, 0, 1, 2, 1, 2, 2, 1, 2, 0, 2, 0, 1, 0,\n",
       "          2, 0, 0, 2, 2, 1, 0, 0, 1, 0, 2, 1, 0, 2, 1, 1, 0, 1, 0, 2, 2,\n",
       "          0, 2, 0, 1, 0, 2, 1, 1, 1, 0, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 2,\n",
       "          1, 0, 2, 1, 2, 2, 2, 0, 1, 2, 0, 0, 1, 1, 2, 1, 0, 0, 2, 2, 2,\n",
       "          2, 0, 1, 0, 2, 2, 1, 1, 0, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2,\n",
       "          1, 0, 1, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 0, 0, 2, 1, 0, 0, 0, 1,\n",
       "          0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 2, 2, 0, 1, 1, 0, 2, 2, 0, 1, 1,\n",
       "          0, 1, 0, 1, 0, 0, 2, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 1, 1,\n",
       "          1, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 1, 2, 1, 1, 2, 0, 0, 1, 2, 1,\n",
       "          0, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 2,\n",
       "          2, 0, 0, 2, 2, 1, 0, 1, 2, 2, 2, 1, 0, 0, 0, 2, 1, 1, 1, 0, 1,\n",
       "          2, 1, 1, 2, 2, 2, 2, 1, 1, 0, 2, 2, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "          0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 2, 0, 2, 0, 0, 2, 2,\n",
       "          0, 2, 2, 0, 0, 1, 0, 2, 1, 0, 0, 1, 2, 2, 0, 2, 2, 2, 2, 1, 1,\n",
       "          2, 0, 0, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 0, 1, 2, 0, 0, 1, 2, 2,\n",
       "          2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 2, 1, 0, 1, 0, 2, 0, 1, 2, 0,\n",
       "          0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 1, 1, 0, 2, 1, 2, 0, 2, 2, 0, 2,\n",
       "          1, 0, 2, 2, 0, 1, 0, 2, 2, 1, 0, 1, 0, 2, 0, 0, 2, 2, 0, 0, 1,\n",
       "          2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0,\n",
       "          1, 2, 1, 1, 2, 1, 2, 0, 1, 2, 0, 0, 2, 1, 0, 1, 2, 0, 2, 2, 2,\n",
       "          1, 0, 0, 2, 2, 0, 1, 1, 1, 0, 1, 1]], dtype=int64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model4.predict(X_test), axis=1), np.argmax(y_test, axis=1).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5c1a5-8eb0-4bf4-befa-9c1d383cc028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for early stopping\n",
    "# https://qiita.com/sasayabaku/items/b7872a3b8acc7d6261bf\n",
    "\n",
    "# stacked lstm model example\n",
    "# https://machinelearningknowledge.ai/keras-lstm-layer-explained-for-beginners-with-example/\n",
    "\n",
    "# lstm layer documentation\n",
    "# https://keras.io/api/layers/recurrent_layers/lstm/\n",
    "\n",
    "# Should you use relu for activation in lstm\n",
    "# https://stats.stackexchange.com/questions/444923/activation-function-between-lstm-layers\n",
    "\n",
    "# lstm explained\n",
    "# https://qiita.com/t_Signull/items/21b82be280b46f467d1b\n",
    "\n",
    "# stacked lstm explained\n",
    "# https://machinelearningmastery.com/stacked-long-short-term-memory-networks/\n",
    "\n",
    "# error solved\n",
    "# https://stackoverflow.com/questions/58119320/valueerror-input-0-of-layer-lstm-is-incompatible-with-the-layer-expected-ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f21014f0-96c6-4124-898f-228bc07ef250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.1014 - accuracy: 0.3075\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.1005 - accuracy: 0.3171\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.1006 - accuracy: 0.3083\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.1009 - accuracy: 0.3021\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.1005 - accuracy: 0.3000\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.1005 - accuracy: 0.3038\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.1002 - accuracy: 0.3179\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.1003 - accuracy: 0.3192\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.1002 - accuracy: 0.3167\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.1002 - accuracy: 0.3021\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.0997 - accuracy: 0.3196\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.1001 - accuracy: 0.3150\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.1001 - accuracy: 0.3154\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.0996 - accuracy: 0.3075\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 13s 1s/step - loss: 1.0981 - accuracy: 0.3492\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.0994 - accuracy: 0.3133\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.0994 - accuracy: 0.3021\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.0985 - accuracy: 0.3317\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.0986 - accuracy: 0.3333\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.0989 - accuracy: 0.3233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20487f23820>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = language_model(activation=\"tanh\", \n",
    "                   optimizer='adagrad', \n",
    "                   hidden_layer_sizes=(50,))\n",
    "\n",
    "model5.fit(X_train, y_train, epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24467e8a-3f01-459a-a198-4b6deaa3f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_model2(optimizer=\"adam\", hidden_layer_sizes=(100, 100)):\n",
    "    model = Sequential()\n",
    "    firstflag = True\n",
    "    for dim in hidden_layer_sizes:\n",
    "        if firstflag:\n",
    "            model.add(LSTM(n_mid, input_shape=(n_rnn, data_dim), return_sequences=True))\n",
    "            model.add(Dropout(0.2))\n",
    "            firstflag = False\n",
    "        else:\n",
    "            model.add(LSTM(n_mid, return_sequences=True))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(n_mid))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(output_dim, activation=\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2efdd614-1905-402b-a152-43859b9838f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation = [\"relu\", \"tanh\"]\n",
    "optimizer = [\"adam\", \"adagrad\", \"sgd\", \"RMSprop\", \"Adamax\"]\n",
    "hidden_layer_sizes = [(50, 50, 50, 50), (50, 50, 50), (50, 50), (50, ) ]\n",
    "nb_epoch = [20, 25]\n",
    "batch_size = [128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2aa68ee1-2b49-4ce3-b2f7-10847c2123ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fic2023150.FIC.009\\AppData\\Local\\Temp\\ipykernel_2724\\495326255.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model5 = KerasClassifier(build_fn=language_model2, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model5 = KerasClassifier(build_fn=language_model2, verbose=0)\n",
    "param_grid = dict(##activation=activation, \n",
    "                  optimizer=optimizer, \n",
    "                  hidden_layer_sizes=hidden_layer_sizes, \n",
    "                  nb_epoch=nb_epoch, \n",
    "                  batch_size=batch_size,)\n",
    "grid3 = GridSearchCV(estimator=model5, param_grid=param_grid, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12f1b04-b920-40a6-8c4e-41ba8e01786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid3_result = grid3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ac12b-2a14-4ec3-ad39-cd828009a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid_result.cv_results_['mean_test_score']\n",
    "## https://stackoverflow.com/questions/68844792/lstm-will-not-use-cudnn-kernels-since-it-doesnt-meet-the-criteria-it-will-use\n",
    "# Colab.research.google.com/drive/1VfGwo6Y8nkCMdiyyze6rPoJ0cmjE7ld3#scrollTo=cf9d0590-7607-4165-8ab9-7254250d7d16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
