{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13b60299-c959-479a-8d50-c3cb97e49d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学習者のID</th>\n",
       "      <th>学習者の性別</th>\n",
       "      <th>学習環境</th>\n",
       "      <th>作文テーマ</th>\n",
       "      <th>学習者の母語</th>\n",
       "      <th>日本語学習履歴</th>\n",
       "      <th>日本語レベル</th>\n",
       "      <th>テスト成績（文字語彙）</th>\n",
       "      <th>テスト成績（文法）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CG009</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CG011</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CG013</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CG015</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CG017</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>KN303</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>KN307</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>KN312</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>KN313</td>\n",
       "      <td>男</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>KN316</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    学習者のID 学習者の性別 学習環境            作文テーマ 学習者の母語   日本語学習履歴 日本語レベル テスト成績（文字語彙）  \\\n",
       "0    CG009      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "1    CG011      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "2    CG013      男   国外  外国語がうまくなる方法について    中国語      2年未満     上級           A   \n",
       "3    CG015      男   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "4    CG017      女   国外  外国語がうまくなる方法について    中国語      2年未満     中級           B   \n",
       "..     ...    ...  ...              ...    ...       ...    ...         ...   \n",
       "299  KN303      女   国内  外国語がうまくなる方法について    韓国語      2年未満     中級           X   \n",
       "300  KN307      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "301  KN312      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "302  KN313      男   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "303  KN316      女   国内  外国語がうまくなる方法について    韓国語      5年以上     上級           X   \n",
       "\n",
       "    テスト成績（文法）  \n",
       "0           C  \n",
       "1           B  \n",
       "2           A  \n",
       "3           B  \n",
       "4           A  \n",
       "..        ...  \n",
       "299         X  \n",
       "300         X  \n",
       "301         X  \n",
       "302         X  \n",
       "303         X  \n",
       "\n",
       "[304 rows x 9 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "path = \"data/register.xls\"\n",
    "labels = pd.read_excel(path)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98583a0b-403d-4212-8f28-f019e4a13f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学習者のID</th>\n",
       "      <th>学習者の性別</th>\n",
       "      <th>学習環境</th>\n",
       "      <th>作文テーマ</th>\n",
       "      <th>学習者の母語</th>\n",
       "      <th>日本語学習履歴</th>\n",
       "      <th>日本語レベル</th>\n",
       "      <th>テスト成績（文字語彙）</th>\n",
       "      <th>テスト成績（文法）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CG009</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CG011</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CG013</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CG015</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CG017</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>KN303</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>KN307</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>KN312</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>KN313</td>\n",
       "      <td>男</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>KN316</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    学習者のID 学習者の性別 学習環境            作文テーマ 学習者の母語   日本語学習履歴 日本語レベル テスト成績（文字語彙）  \\\n",
       "0    CG009      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "1    CG011      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "2    CG013      男   国外  外国語がうまくなる方法について    中国語      2年未満     上級           A   \n",
       "3    CG015      男   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "4    CG017      女   国外  外国語がうまくなる方法について    中国語      2年未満     中級           B   \n",
       "..     ...    ...  ...              ...    ...       ...    ...         ...   \n",
       "299  KN303      女   国内  外国語がうまくなる方法について    韓国語      2年未満     中級           X   \n",
       "300  KN307      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "301  KN312      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "302  KN313      男   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "303  KN316      女   国内  外国語がうまくなる方法について    韓国語      5年以上     上級           X   \n",
       "\n",
       "    テスト成績（文法）  \n",
       "0           C  \n",
       "1           B  \n",
       "2           A  \n",
       "3           B  \n",
       "4           A  \n",
       "..        ...  \n",
       "299         X  \n",
       "300         X  \n",
       "301         X  \n",
       "302         X  \n",
       "303         X  \n",
       "\n",
       "[192 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "label1 = labels.loc[labels.作文テーマ == \"外国語がうまくなる方法について\",:]\n",
    "label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "834e01d4-9aac-47c2-97bb-142ca7a152b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学習者のID</th>\n",
       "      <th>学習者の性別</th>\n",
       "      <th>学習環境</th>\n",
       "      <th>作文テーマ</th>\n",
       "      <th>学習者の母語</th>\n",
       "      <th>日本語学習履歴</th>\n",
       "      <th>日本語レベル</th>\n",
       "      <th>テスト成績（文字語彙）</th>\n",
       "      <th>テスト成績（文法）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>CG101</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>CG102</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>CG103</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CG104</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>CG105</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>KG151</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>KG152</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>KG153</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>KG154</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>KG155</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    学習者のID 学習者の性別 学習環境                作文テーマ 学習者の母語   日本語学習履歴 日本語レベル  \\\n",
       "76   CG101      男   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "77   CG102      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "78   CG103      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "79   CG104      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "80   CG105      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     上級   \n",
       "..     ...    ...  ...                  ...    ...       ...    ...   \n",
       "292  KG151      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語      5年以上     上級   \n",
       "293  KG152      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語  2年以上5年未満     上級   \n",
       "294  KG153      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語  2年以上5年未満     上級   \n",
       "295  KG154      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語      2年未満     中級   \n",
       "296  KG155      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語      5年以上     上級   \n",
       "\n",
       "    テスト成績（文字語彙） テスト成績（文法）  \n",
       "76            X         X  \n",
       "77            X         X  \n",
       "78            X         X  \n",
       "79            X         X  \n",
       "80            X         X  \n",
       "..          ...       ...  \n",
       "292           X         X  \n",
       "293           X         X  \n",
       "294           X         X  \n",
       "295           X         X  \n",
       "296           X         X  \n",
       "\n",
       "[112 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2 = labels.loc[labels.作文テーマ == \"インターネット時代に新聞や雑誌は必要か\",:]\n",
    "label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1ec06dd-dcd9-4ff8-be26-c2eb5e3feef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['初級', '初級', '上級', '初級', '中級', '中級', '中級', '上級', '中級', '中級', '中級',\n",
       "        '上級', '中級', '中級', '中級', '初級', '中級', '上級', '初級', '初級', '中級', '中級',\n",
       "        '初級', '中級', '中級', '上級', '中級', '中級', '初級', '上級', '上級', '初級', '中級',\n",
       "        '中級', '上級', '中級', '中級', '初級', '初級', '中級', '上級', '中級', '上級', '中級',\n",
       "        '上級', '中級', '初級', '中級', '中級', '初級', '上級', '初級', '中級', '中級', '上級',\n",
       "        '初級', '初級', '上級', '上級', '中級', '中級', '中級', '上級', '中級', '中級', '上級',\n",
       "        '中級', '中級', '中級', '初級', '中級', '初級', '中級', '中級', '上級', '上級', '初級',\n",
       "        '上級', '中級', '中級', '上級', '中級', '中級', '中級', '中級', '中級', '中級', '中級',\n",
       "        '中級', '中級', '上級', '中級', '中級', '初級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '中級', '中級', '中級', '中級', '初級', '中級', '中級', '初級', '中級', '中級', '中級',\n",
       "        '上級', '中級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '中級', '中級',\n",
       "        '上級', '中級', '上級', '上級', '中級', '上級', '上級', '中級', '中級', '初級', '中級',\n",
       "        '中級', '上級', '中級', '上級', '上級', '上級', '中級', '上級', '中級', '上級', '上級',\n",
       "        '上級', '中級', '初級', '中級', '中級', '上級', '上級', '中級', '中級', '上級', '上級',\n",
       "        '上級', '中級', '初級', '中級', '中級', '中級', '上級', '中級', '初級', '中級', '中級',\n",
       "        '中級', '上級', '初級', '上級', '中級', '中級', '中級', '初級', '中級', '中級', '中級',\n",
       "        '中級', '初級', '中級', '初級', '初級', '中級', '中級', '中級', '中級', '上級', '中級',\n",
       "        '中級', '上級', '上級', '上級', '上級'], dtype=object),\n",
       " 192)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level1 = np.array(label1.日本語レベル)\n",
    "level1, len(level1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c847ac2a-1c01-4872-b656-12ebc25ad33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中級', '中級', '中級', '中級', '上級', '中級', '中級', '中級', '上級', '中級', '中級',\n",
       "        '中級', '中級', '上級', '上級', '中級', '中級', '中級', '上級', '中級', '中級', '中級',\n",
       "        '中級', '上級', '中級', '中級', '中級', '中級', '中級', '上級', '中級', '中級', '中級',\n",
       "        '上級', '中級', '中級', '中級', '中級', '中級', '中級', '中級', '上級', '中級', '中級',\n",
       "        '中級', '中級', '上級', '中級', '中級', '上級', '中級', '中級', '中級', '上級', '中級',\n",
       "        '上級', '上級', '上級', '上級', '中級', '上級', '上級', '上級', '中級', '上級', '上級',\n",
       "        '中級', '上級', '上級', '上級', '中級', '上級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '上級', '上級', '上級', '上級', '上級', '上級', '中級', '上級', '上級', '上級', '上級',\n",
       "        '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '中級', '上級'], dtype=object),\n",
       " 112)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level2 = np.array(label2.日本語レベル)\n",
    "level2, len(level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dca6d9-408a-4711-a600-912f494fd62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8c86efb-bf58-4252-be6f-ca08ba4da7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "txt_path = \"data/txt/\"\n",
    "txt_topics = listdir(txt_path)\n",
    "\n",
    "txt_gaigo_path = txt_path + txt_topics[0]\n",
    "txt_internet_path = txt_path + txt_topics[1]\n",
    "\n",
    "txt_gaigo_files = listdir(txt_gaigo_path)\n",
    "txt_internet_files = listdir(txt_internet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e201e92-620e-46fe-a758-bb3787d99647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5889ef08-8537-4546-a485-ddfdd2aa65b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'私は大学日本語科の一年生です最初日本語が難しいと思いましたそれから先生が日本語がうまくなる方法を聞きました先生は毎日単語を覚えるとか日本語の文章を読むとかドラマをみますと言いました私は先生が教えたとおりにしていました毎朝単語を読んでいましたよるドラマを見ていました難しい内容をあった先生に聞きました重要な内容を整理しました日本語の口頭試験がよいためにたくさん練習しましたたくさんの日本の歌を聞きました歌を聞きながら歌の内容を書きましたいま私は日本語がやさしいと思います'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os.path as osp\n",
    "# import re\n",
    "# gaigo_files = [f for f in listdir(osp.join(txt_path, txt_topics[0])) if f.endswith('.txt')]\n",
    "# gaigo = []\n",
    "# for gaigo_file in gaigo_files:\n",
    "#     # print(gaigo_file)\n",
    "#     with open(osp.join(txt_path, txt_topics[0], gaigo_file), \"r\", encoding=\"utf-8\") as f:\n",
    "#         lines = f.read()\n",
    "#         # type(lines)\n",
    "#         lines = re.sub('\\n', '', lines)\n",
    "#         lines = re.sub('\\u3000', '', lines)\n",
    "#     gaigo.append(lines)\n",
    "# # type(gaigo[0])\n",
    "# # gaigo[0][0]\n",
    "\n",
    "import os.path as osp\n",
    "import re\n",
    "gaigo_files = [f for f in listdir(osp.join(txt_path, txt_topics[0])) if f.endswith('.txt')]\n",
    "gaigo = []\n",
    "for gaigo_file in gaigo_files:\n",
    "    # print(gaigo_file)\n",
    "    with open(osp.join(txt_path, txt_topics[0], gaigo_file), \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read()\n",
    "        # type(lines)\n",
    "        lines = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", lines)\n",
    "        lines = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", lines)\n",
    "\n",
    "    gaigo.append(lines)\n",
    "# type(gaigo[0])\n",
    "gaigo[0]\n",
    "\n",
    "# 注意。注釈は削除していない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec8cc9c2-1357-4ff9-90ce-b5585ec755b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'この数十年の間にテレビや携帯電話などの便利なものは世界的に使われていて私たち現代人の生活に大きな役に立っているのだその何種類の産品の中に一番の便利さが持っていて生活を影響するのはコンピューターだと思う今は何でもコンピューターでできるんでしょう例えばネットを使ってどの国にどんなことがあったかのがすぐ分かることとかネットで買い物したりホテルを予約したりすることとかいろいろなことがただ指で完成できるその一方でコンピューターの発達によってたくさん問題も次から次へと生じるずっとコンピューターで宿題やレポートをすると今の子たちはほとんど字がきたなくなったり書けない漢字も昔より増えてきたらしいだからうまくコンピューターを利用できるかどうかは私たちにとって重要な課題になるさっき言ったようにネットでどんなことでもできるもちろん毎日のニュースや雑誌の内容もほとんどネットにあるそのためコンビニに行って新聞と雑誌を買う必要がなくなりコンピューターの電源のボタンを押すと何でも見られる新聞代や雑誌代を使って他方面のことで使うことができるようになったからコンピューターがあれば他のものはもういらないと思っている人が多いかも知れないけれども私はそのようには思わないコンピューターの利点はたくさんあるのは確かだけれどその利点や便利さを頼りすぎると悪い結果も出て来る漢字が正しく書けなくなったり何でもネットからコピーして自分がどんどん考えられなくなったりするのは一番見られる現象であるですからいくらコンピューターが便利でも他のところから知識とか生活能力を学習するのは昔より重要だと思っているもちろん新聞や雑誌はそれらの方法の中に一番簡単に使える方法であるこれからも必要なものとして私たちの生活に存在しているのも違えない要するにこれからきっとたくさん生活に役に立つものが創造されるんだだけどいくら生活がどんなに快適便利になっても自分の目で見て手を使って自分らしく考えておいてそしてやることをするのが依然としてもっとも人間にとって大切なことであると私はそうだと思っている 携は右側の部分の上に山'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import re\n",
    "# internet_files = [f for f in listdir(osp.join(txt_path, txt_topics[1])) if f.endswith('.txt')]\n",
    "# internet = []\n",
    "# for internet_file in internet_files:\n",
    "#     with open(osp.join(txt_path, txt_topics[1], internet_file), \"r\", encoding=\"utf-8\") as f:\n",
    "#         lines = f.read()\n",
    "#         # print(lines)\n",
    "#         lines = lines.strip('\\ufeff□')\n",
    "#         lines = re.sub('■', '', lines)\n",
    "#         lines = re.sub('\\n', '', lines)\n",
    "#         lines = re.sub('□', '', lines)\n",
    "#         lines = re.sub('\\u3000', '', lines)\n",
    "        \n",
    "#     internet.append(lines)\n",
    "\n",
    "# internet[0]\n",
    "\n",
    "import re\n",
    "internet_files = [f for f in listdir(osp.join(txt_path, txt_topics[1])) if f.endswith('.txt')]\n",
    "internet = []\n",
    "for internet_file in internet_files:\n",
    "    with open(osp.join(txt_path, txt_topics[1], internet_file), \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read()\n",
    "        # print(lines)\n",
    "        lines = lines.strip('\\ufeff□')\n",
    "        lines = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", lines)\n",
    "        lines = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", lines)\n",
    "        \n",
    "    internet.append(lines)\n",
    "\n",
    "internet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d4b3c-3b3d-470c-9a2b-3841e092614a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6080253b-8225-4834-b212-f6da98da0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict as dd\n",
    "text_tagged = dd(list)\n",
    "for level, txt in zip(level1, internet):\n",
    "    text_tagged[level].append(txt)\n",
    "\n",
    "for level, txt in zip(level2, gaigo):\n",
    "    text_tagged[level].append(txt)\n",
    "\n",
    "text_tagged_dict = dict(text_tagged)\n",
    "# text_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0de867-5c50-4c98-b8d6-43dd0b155c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "# with open('text_tagged_dict2.pickle', 'wb') as f:\n",
    "#     pickle.dump(text_tagged_dict, f)\n",
    "    \n",
    "text_tagged_dict2 = pickle.load(open('text_tagged_dict2.pickle', 'rb'))\n",
    "text_tagged_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61b0dcbf-a602-4ff5-ae3f-950096e95542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9cd19413-0a78-491a-a043-5725826708be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "text_length_dist = [len(text) for level in text_tagged_dict2.keys() for text in text_tagged_dict2[level]]\n",
    "# [len(text) for text in text_tagged_dict2[\"初級\"]]\n",
    "# text_length_dist\n",
    "\n",
    "# np.max(text_length_dist) = 893\n",
    "# to determine how many paddings we should add \n",
    "plt.hist(text_length_dist, bins = np.arange(0, 900, 10))\n",
    "plt.show()\n",
    "# we can determine the max length of texts as 900 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f82bea-1fc6-459e-bdb8-d5a44e60c862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c7db81b-b016-4818-92ce-89912af7070c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:17<00:00,  5.94s/it]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.load('ja_ginza')\n",
    "\n",
    "a = text_tagged_dict2[\"初級\"][0]\n",
    "sents = nlp(a)\n",
    "for token in sents:\n",
    "    # print(token)\n",
    "    pass\n",
    "\n",
    "# word2index = {}\n",
    "vectors = {}\n",
    "for level in tqdm(text_tagged_dict2.keys()):\n",
    "    vectors[level] = []\n",
    "    for text in text_tagged_dict2[level]:\n",
    "        wakati = nlp(text)\n",
    "        for token in wakati:\n",
    "            # token = str(token)\n",
    "            # if token in word2index:  continue\n",
    "            # word2index[token] = len(word2index)\n",
    "            \n",
    "            vectors[level].append(token.vector)\n",
    "            \n",
    "        \n",
    "for level in vectors:\n",
    "    vectors[level] = np.array(vectors[level])\n",
    "# word2index\n",
    "# index2word = dict((i, w) for w, i in word2index.items())\n",
    "# index2word[4882], word2index[\"愉快\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a573aefc-587a-4430-9a71-6ddae32f13bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6436, 300), (1609, 300), (8045, 300))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "vectors_train = {}\n",
    "vectors_test = {}\n",
    "train_rate = 0.8\n",
    "for level in vectors:\n",
    "    length = int(len(vectors[level]) * train_rate) \n",
    "    # print(length)\n",
    "    vectors_train[level] = vectors[level][:length,:]\n",
    "    vectors_test[level] = vectors[level][length:,:]\n",
    "\n",
    "# vectors_train[\"初級\"].shape, vectors_test[\"初級\"].shape, vectors[\"初級\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b032e68d-08c7-4b28-a326-d4c115ac24c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8045, 300)\n",
      "(29070, 300)\n",
      "(36575, 300)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "keys, values = zip(*vectors.items())\n",
    "\n",
    "data = pd.DataFrame({'cat': keys, 'vectors': values})\n",
    "# data.head()\n",
    "\n",
    "for vector in data.vectors:\n",
    "    print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca2128f5-cad7-4643-8ab0-8d5005a3de29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 256)               1376256   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1087)              279359    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,655,615\n",
      "Trainable params: 1,655,615\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "n_rnn = 10  # 時系列の数\n",
    "batch_size = 128\n",
    "epochs = 20  #epochsは、多いほど、精密に学習するが、重くなるため今回は小さくしている\n",
    "n_mid = 256  # 中間層のニューロン数\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, np.max(char_length))))\n",
    "model_lstm.add(Dense(np.max(char_length), activation=\"softmax\"))\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f84449-8a82-4764-9067-35e6615e6f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffd476-c36e-404c-a107-c8a13a764c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36271f00-7a0d-4104-9866-a673191fb3b3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'この',\n",
       " 1: '数十',\n",
       " 2: '年',\n",
       " 3: 'の',\n",
       " 4: '間',\n",
       " 5: 'に',\n",
       " 6: 'テレビ',\n",
       " 7: 'や',\n",
       " 8: '携帯電話',\n",
       " 9: 'など',\n",
       " 10: '便利',\n",
       " 11: 'な',\n",
       " 12: 'もの',\n",
       " 13: 'は',\n",
       " 14: '世界的',\n",
       " 15: '使わ',\n",
       " 16: 'れ',\n",
       " 17: 'て',\n",
       " 18: 'い',\n",
       " 19: '私たち',\n",
       " 20: '現代人',\n",
       " 21: '生活',\n",
       " 22: '大きな',\n",
       " 23: '役',\n",
       " 24: '立っ',\n",
       " 25: 'いる',\n",
       " 26: 'だ',\n",
       " 27: 'その',\n",
       " 28: '何',\n",
       " 29: '種類',\n",
       " 30: '産品',\n",
       " 31: '中',\n",
       " 32: '一番',\n",
       " 33: 'さ',\n",
       " 34: 'が',\n",
       " 35: '持っ',\n",
       " 36: 'を',\n",
       " 37: '影響',\n",
       " 38: 'する',\n",
       " 39: 'コンピューター',\n",
       " 40: 'と',\n",
       " 41: '思う',\n",
       " 42: '今',\n",
       " 43: 'で',\n",
       " 44: 'も',\n",
       " 45: 'できる',\n",
       " 46: 'ん',\n",
       " 47: 'でしょう',\n",
       " 48: '例えば',\n",
       " 49: 'ネット',\n",
       " 50: '使っ',\n",
       " 51: 'どの',\n",
       " 52: '国',\n",
       " 53: 'どんな',\n",
       " 54: 'こと',\n",
       " 55: 'あっ',\n",
       " 56: 'た',\n",
       " 57: 'か',\n",
       " 58: 'すぐ',\n",
       " 59: '分かる',\n",
       " 60: '買い物',\n",
       " 61: 'し',\n",
       " 62: 'たり',\n",
       " 63: 'ホテル',\n",
       " 64: '予約',\n",
       " 65: 'いろいろ',\n",
       " 66: 'ただ',\n",
       " 67: '指',\n",
       " 68: '完成',\n",
       " 69: '一方',\n",
       " 70: '発達',\n",
       " 71: 'よっ',\n",
       " 72: 'たくさん',\n",
       " 73: '問題',\n",
       " 74: '次',\n",
       " 75: 'から',\n",
       " 76: 'へ',\n",
       " 77: '生じる',\n",
       " 78: 'ずっと',\n",
       " 79: '宿題',\n",
       " 80: 'レポート',\n",
       " 81: '子',\n",
       " 82: 'たち',\n",
       " 83: 'ほとんど',\n",
       " 84: '字',\n",
       " 85: 'きたなく',\n",
       " 86: 'なっ',\n",
       " 87: '書け',\n",
       " 88: 'ない',\n",
       " 89: '漢字',\n",
       " 90: '昔',\n",
       " 91: 'より',\n",
       " 92: '増え',\n",
       " 93: 'き',\n",
       " 94: 'らしい',\n",
       " 95: 'うまく',\n",
       " 96: '利用',\n",
       " 97: 'どう',\n",
       " 98: 'とっ',\n",
       " 99: '重要',\n",
       " 100: '課題',\n",
       " 101: 'なる',\n",
       " 102: 'さっき',\n",
       " 103: '言っ',\n",
       " 104: 'よう',\n",
       " 105: 'もちろん',\n",
       " 106: '毎日',\n",
       " 107: 'ニュース',\n",
       " 108: '雑誌',\n",
       " 109: '内容',\n",
       " 110: 'ある',\n",
       " 111: 'ため',\n",
       " 112: 'コンビニ',\n",
       " 113: '行っ',\n",
       " 114: '新聞',\n",
       " 115: '買う',\n",
       " 116: '必要',\n",
       " 117: 'なくなり',\n",
       " 118: '電源',\n",
       " 119: 'ボタン',\n",
       " 120: '押す',\n",
       " 121: '見',\n",
       " 122: 'られる',\n",
       " 123: '代',\n",
       " 124: '他',\n",
       " 125: '方面',\n",
       " 126: '使う',\n",
       " 127: 'あれ',\n",
       " 128: 'ば',\n",
       " 129: 'もう',\n",
       " 130: 'いら',\n",
       " 131: '思っ',\n",
       " 132: '人',\n",
       " 133: '多い',\n",
       " 134: '知れ',\n",
       " 135: 'けれど',\n",
       " 136: '私',\n",
       " 137: '思わ',\n",
       " 138: '利点',\n",
       " 139: '確か',\n",
       " 140: '頼り',\n",
       " 141: 'すぎる',\n",
       " 142: '悪い',\n",
       " 143: '結果',\n",
       " 144: '出',\n",
       " 145: '来る',\n",
       " 146: '正しく',\n",
       " 147: 'なく',\n",
       " 148: 'コピー',\n",
       " 149: '自分',\n",
       " 150: 'どんどん',\n",
       " 151: '考え',\n",
       " 152: 'られ',\n",
       " 153: '現象',\n",
       " 154: 'です',\n",
       " 155: 'いくら',\n",
       " 156: 'ところ',\n",
       " 157: '知識',\n",
       " 158: '能力',\n",
       " 159: '学習',\n",
       " 160: 'それ',\n",
       " 161: 'ら',\n",
       " 162: '方法',\n",
       " 163: '簡単',\n",
       " 164: '使える',\n",
       " 165: 'これ',\n",
       " 166: '存在',\n",
       " 167: '違え',\n",
       " 168: '要する',\n",
       " 169: 'きっと',\n",
       " 170: '立つ',\n",
       " 171: '創造',\n",
       " 172: 'れる',\n",
       " 173: 'けど',\n",
       " 174: '快適',\n",
       " 175: '目',\n",
       " 176: '手',\n",
       " 177: 'らしく',\n",
       " 178: 'おい',\n",
       " 179: 'そして',\n",
       " 180: 'やる',\n",
       " 181: '依然',\n",
       " 182: 'もっとも',\n",
       " 183: '人間',\n",
       " 184: '大切',\n",
       " 185: 'そう',\n",
       " 186: '携',\n",
       " 187: '右側',\n",
       " 188: '部分',\n",
       " 189: '上',\n",
       " 190: '山',\n",
       " 191: 'インターネット',\n",
       " 192: '見る',\n",
       " 193: 'いう',\n",
       " 194: '意見',\n",
       " 195: '思い',\n",
       " 196: 'ませ',\n",
       " 197: '多く',\n",
       " 198: '資料',\n",
       " 199: 'さがる',\n",
       " 200: '世界中',\n",
       " 201: '情報',\n",
       " 202: '知っ',\n",
       " 203: 'とても',\n",
       " 204: '実感',\n",
       " 205: '与え',\n",
       " 206: '感覚',\n",
       " 207: '物事',\n",
       " 208: '安全',\n",
       " 209: '感',\n",
       " 210: '真実',\n",
       " 211: '感じ',\n",
       " 212: 'ます',\n",
       " 213: '触れ',\n",
       " 214: '気持ち',\n",
       " 215: 'ゆえ',\n",
       " 216: '書物',\n",
       " 217: '集める',\n",
       " 218: '物',\n",
       " 219: 'だけ',\n",
       " 220: '一部分',\n",
       " 221: 'なり',\n",
       " 222: 'まし',\n",
       " 223: 'もし',\n",
       " 224: 'なくなっ',\n",
       " 225: 'たら',\n",
       " 226: 'どこ',\n",
       " 227: 'おかしく',\n",
       " 228: '感じる',\n",
       " 229: '可能性',\n",
       " 230: 'あり',\n",
       " 231: 'こう',\n",
       " 232: '単純',\n",
       " 233: '工具',\n",
       " 234: '習慣',\n",
       " 235: '感情',\n",
       " 236: '一',\n",
       " 237: 'つ',\n",
       " 238: 'また',\n",
       " 239: '収蔵',\n",
       " 240: '性',\n",
       " 241: '芸術性',\n",
       " 242: '紙',\n",
       " 243: '質',\n",
       " 244: '版面',\n",
       " 245: 'デザイン',\n",
       " 246: 'まで',\n",
       " 247: 'ちゃんと',\n",
       " 248: '読ん',\n",
       " 249: 'だら',\n",
       " 250: 'もた',\n",
       " 251: '視覚',\n",
       " 252: '生物',\n",
       " 253: '限',\n",
       " 254: '制',\n",
       " 255: 'におい',\n",
       " 256: '触感',\n",
       " 257: 'こそ',\n",
       " 258: '世界',\n",
       " 259: 'あらゆる',\n",
       " 260: '特質',\n",
       " 261: 'わけ',\n",
       " 262: '広い',\n",
       " 263: '使用',\n",
       " 264: '皆',\n",
       " 265: '図書館',\n",
       " 266: 'みたい',\n",
       " 267: '最近',\n",
       " 268: '見付ける',\n",
       " 269: '歴史',\n",
       " 270: 'さがし',\n",
       " 271: 'やすい',\n",
       " 272: '場所',\n",
       " 273: 'パソーコン',\n",
       " 274: '適当',\n",
       " 275: '的',\n",
       " 276: '検索',\n",
       " 277: 'いき',\n",
       " 278: 'たしか',\n",
       " 279: '取り',\n",
       " 280: '同時',\n",
       " 281: '価値',\n",
       " 282: 'つめたい',\n",
       " 283: 'メートル',\n",
       " 284: 'ちがっ',\n",
       " 285: '特別',\n",
       " 286: 'かかわら',\n",
       " 287: '物理',\n",
       " 288: '熱',\n",
       " 289: '伝導',\n",
       " 290: '証明',\n",
       " 291: 'あたたかい',\n",
       " 292: 'くる',\n",
       " 293: 'まちがい',\n",
       " 294: 'もっと',\n",
       " 295: 'じつ',\n",
       " 296: '信号',\n",
       " 297: '受ける',\n",
       " 298: '装置',\n",
       " 299: 'だんだん',\n",
       " 300: '小さく',\n",
       " 301: '絶対',\n",
       " 302: '勝つ',\n",
       " 303: '捨',\n",
       " 304: 'って',\n",
       " 305: 'いい',\n",
       " 306: 'インフォメーション',\n",
       " 307: '本当',\n",
       " 308: 'どちら',\n",
       " 309: '世の中',\n",
       " 310: 'メッセージー',\n",
       " 311: 'あなた',\n",
       " 312: '選ん',\n",
       " 313: '場合',\n",
       " 314: 'よる',\n",
       " 315: '媒介',\n",
       " 316: '歴',\n",
       " 317: '力',\n",
       " 318: '簡体字',\n",
       " 319: '値',\n",
       " 320: '下',\n",
       " 321: '直線',\n",
       " 322: '中国語',\n",
       " 323: '字体',\n",
       " 324: '置',\n",
       " 325: 'さがす',\n",
       " 326: '速さ',\n",
       " 327: '生まれ',\n",
       " 328: '人々',\n",
       " 329: 'こんな',\n",
       " 330: '需要',\n",
       " 331: '社会',\n",
       " 332: 'インフォメション',\n",
       " 333: 'しれ',\n",
       " 334: 'しかし',\n",
       " 335: 'みな',\n",
       " 336: '段々',\n",
       " 337: '行く',\n",
       " 338: '大丈夫',\n",
       " 339: 'いろんな',\n",
       " 340: '面白い',\n",
       " 341: '無料',\n",
       " 342: 'でき',\n",
       " 343: 'さかん',\n",
       " 344: '発展',\n",
       " 345: '伝統',\n",
       " 346: '紙本',\n",
       " 347: '比べ',\n",
       " 348: 'みる',\n",
       " 349: 'インタ',\n",
       " 350: 'ほう',\n",
       " 351: '速い',\n",
       " 352: '言い',\n",
       " 353: '前段',\n",
       " 354: '印刷',\n",
       " 355: 'そ',\n",
       " 356: '考え方',\n",
       " 357: '認め',\n",
       " 358: 'あるいは',\n",
       " 359: '二',\n",
       " 360: '別々',\n",
       " 361: '含め',\n",
       " 362: '特に',\n",
       " 363: '対し',\n",
       " 364: '文字',\n",
       " 365: '微妙',\n",
       " 366: '込',\n",
       " 367: '代り',\n",
       " 368: '無理',\n",
       " 369: '実',\n",
       " 370: '惡い',\n",
       " 371: '文化',\n",
       " 372: '接続',\n",
       " 373: 'ながら',\n",
       " 374: '新しい',\n",
       " 375: '対立',\n",
       " 376: '互い',\n",
       " 377: '尊敬',\n",
       " 378: 'す',\n",
       " 379: 'べき',\n",
       " 380: '多様',\n",
       " 381: '努力',\n",
       " 382: '点',\n",
       " 383: '占',\n",
       " 384: '大',\n",
       " 385: '自由',\n",
       " 386: 'よく',\n",
       " 387: '聞い',\n",
       " 388: '友達',\n",
       " 389: '話し',\n",
       " 390: '調べ',\n",
       " 391: '音楽',\n",
       " 392: '実物',\n",
       " 393: '方',\n",
       " 394: '好き',\n",
       " 395: '臭い',\n",
       " 396: 'すごい',\n",
       " 397: 'スピード',\n",
       " 398: '興味',\n",
       " 399: 'テーマ',\n",
       " 400: '捜す',\n",
       " 401: 'つまり',\n",
       " 402: '当日',\n",
       " 403: '読める',\n",
       " 404: 'かかる',\n",
       " 405: '時間',\n",
       " 406: '短かい',\n",
       " 407: '日',\n",
       " 408: 'パソコン',\n",
       " 409: '操作',\n",
       " 410: '時',\n",
       " 411: '遅い',\n",
       " 412: 'か月',\n",
       " 413: '前',\n",
       " 414: 'なかっ',\n",
       " 415: 'あの',\n",
       " 416: '全然',\n",
       " 417: '長い',\n",
       " 418: '傷',\n",
       " 419: 'すと',\n",
       " 420: '副',\n",
       " 421: '射',\n",
       " 422: '大きい',\n",
       " 423: '年上',\n",
       " 424: '難しく',\n",
       " 425: '使え',\n",
       " 426: '複雑',\n",
       " 427: '彼',\n",
       " 428: '閒',\n",
       " 429: '突然',\n",
       " 430: '起こる',\n",
       " 431: '事故',\n",
       " 432: '事件',\n",
       " 433: '知る',\n",
       " 434: '二方',\n",
       " 435: '行う',\n",
       " 436: '賛成',\n",
       " 437: '缺点',\n",
       " 438: '口',\n",
       " 439: '向',\n",
       " 440: '賛',\n",
       " 441: '夫',\n",
       " 442: '先',\n",
       " 443: '現在',\n",
       " 444: 'お蔭',\n",
       " 445: '分かり',\n",
       " 446: '毎朝',\n",
       " 447: 'コーヒー',\n",
       " 448: '飲み',\n",
       " 449: '読む',\n",
       " 450: '情報化',\n",
       " 451: '見える',\n",
       " 452: '場面',\n",
       " 453: 'じゃ',\n",
       " 454: '受け取ら',\n",
       " 455: '査証',\n",
       " 456: '噂',\n",
       " 457: '流れ',\n",
       " 458: 'ときどき',\n",
       " 459: '不必要',\n",
       " 460: '迷惑',\n",
       " 461: 'かけ',\n",
       " 462: '言え',\n",
       " 463: '編集',\n",
       " 464: '達',\n",
       " 465: '責任',\n",
       " 466: '少ない',\n",
       " 467: 'だろう',\n",
       " 468: '文章',\n",
       " 469: '実体',\n",
       " 470: '本',\n",
       " 471: '違う',\n",
       " 472: '読書',\n",
       " 473: 'なら',\n",
       " 474: 'やはり',\n",
       " 475: '環境',\n",
       " 476: '共同',\n",
       " 477: '頑張ろう',\n",
       " 478: 'メディア',\n",
       " 479: '成っ',\n",
       " 480: '数',\n",
       " 481: '万',\n",
       " 482: '流通',\n",
       " 483: 'スピート',\n",
       " 484: '非常',\n",
       " 485: '故',\n",
       " 486: '知',\n",
       " 487: 'のみ',\n",
       " 488: 'ず',\n",
       " 489: 'クリック',\n",
       " 490: '全て',\n",
       " 491: '可能',\n",
       " 492: 'そんな',\n",
       " 493: '代わり',\n",
       " 494: '好ま',\n",
       " 495: '傾向',\n",
       " 496: 'いつ',\n",
       " 497: '替わる',\n",
       " 498: '決まっ',\n",
       " 499: 'あろう',\n",
       " 500: '事実',\n",
       " 501: 'いっ',\n",
       " 502: 'まず',\n",
       " 503: '詳しく',\n",
       " 504: '反面',\n",
       " 505: '同じ',\n",
       " 506: '頭',\n",
       " 507: 'つい',\n",
       " 508: '考える',\n",
       " 509: '意識',\n",
       " 510: '生み出せる',\n",
       " 511: '成長',\n",
       " 512: 'いつも',\n",
       " 513: '読ま',\n",
       " 514: 'なけれ',\n",
       " 515: 'ばか',\n",
       " 516: '成る',\n",
       " 517: 'おそれ',\n",
       " 518: '全',\n",
       " 519: '六十億',\n",
       " 520: '以上',\n",
       " 521: '重要性',\n",
       " 522: '毎',\n",
       " 523: '母',\n",
       " 524: 'さん',\n",
       " 525: 'とおり',\n",
       " 526: '普及',\n",
       " 527: '見つから',\n",
       " 528: '関わる',\n",
       " 529: '映象',\n",
       " 530: '来',\n",
       " 531: '違い',\n",
       " 532: 'メリット',\n",
       " 533: 'サイト',\n",
       " 534: 'ほか',\n",
       " 535: '結び付か',\n",
       " 536: '読め',\n",
       " 537: '記事',\n",
       " 538: '図',\n",
       " 539: 'リンク',\n",
       " 540: '入れる',\n",
       " 541: '情報処理',\n",
       " 542: '多分',\n",
       " 543: '最も',\n",
       " 544: '優れ',\n",
       " 545: '言える',\n",
       " 546: '理由',\n",
       " 547: '古い',\n",
       " 548: '主張',\n",
       " 549: '決して',\n",
       " 550: '少なく',\n",
       " 551: '捨て',\n",
       " 552: 'いけ',\n",
       " 553: '反論',\n",
       " 554: 'ミス',\n",
       " 555: '言葉',\n",
       " 556: '混乱',\n",
       " 557: '欠点',\n",
       " 558: '評判',\n",
       " 559: '僕',\n",
       " 560: '立場',\n",
       " 561: '取ら',\n",
       " 562: '歴史的',\n",
       " 563: '面',\n",
       " 564: '主に',\n",
       " 565: '用い',\n",
       " 566: '記し',\n",
       " 567: '大衆',\n",
       " 568: '提供',\n",
       " 569: '義務教育',\n",
       " 570: '従う',\n",
       " 571: '言い換えれ',\n",
       " 572: ' ',\n",
       " 573: '世紀',\n",
       " 574: '各国',\n",
       " 575: '次々',\n",
       " 576: '始まり',\n",
       " 577: '従っ',\n",
       " 578: '文学',\n",
       " 579: '小説',\n",
       " 580: '作品',\n",
       " 581: '異彩',\n",
       " 582: '放っ',\n",
       " 583: '時代',\n",
       " 584: '映画',\n",
       " 585: '発明',\n",
       " 586: '幅広く',\n",
       " 587: '必ず',\n",
       " 588: '唯一',\n",
       " 589: '手段',\n",
       " 590: '美し',\n",
       " 591: '独自',\n",
       " 592: '美学',\n",
       " 593: '残念',\n",
       " 594: '様々',\n",
       " 595: '色々',\n",
       " 596: '選ば',\n",
       " 597: '媒体',\n",
       " 598: 'よろしい',\n",
       " 599: '追い',\n",
       " 600: '残さ',\n",
       " 601: '自然',\n",
       " 602: '林',\n",
       " 603: '禾',\n",
       " 604: 'たぶん',\n",
       " 605: '繁体字',\n",
       " 606: 'つれ',\n",
       " 607: '声',\n",
       " 608: '新し',\n",
       " 609: 'いえ',\n",
       " 610: '調べる',\n",
       " 611: '当然',\n",
       " 612: '以下',\n",
       " 613: '三',\n",
       " 614: '第',\n",
       " 615: '正確性',\n",
       " 616: '権威',\n",
       " 617: 'はるか',\n",
       " 618: '重視',\n",
       " 619: 'だれ',\n",
       " 620: '発表',\n",
       " 621: '判明',\n",
       " 622: 'にくい',\n",
       " 623: '作者',\n",
       " 624: '名前',\n",
       " 625: '書い',\n",
       " 626: '持つ',\n",
       " 627: '読者',\n",
       " 628: '信頼',\n",
       " 629: '保存',\n",
       " 630: '短く',\n",
       " 631: '確保',\n",
       " 632: '作ら',\n",
       " 633: '年月',\n",
       " 634: '経っ',\n",
       " 635: '適切',\n",
       " 636: 'すれ',\n",
       " 637: '何百',\n",
       " 638: '後',\n",
       " 639: '携帯性',\n",
       " 640: 'きまず',\n",
       " 641: '重く',\n",
       " 642: '持て',\n",
       " 643: '面倒',\n",
       " 644: '不便',\n",
       " 645: '軽く',\n",
       " 646: '電車',\n",
       " 647: 'バス',\n",
       " 648: '気軽',\n",
       " 649: 'とも',\n",
       " 650: '長く',\n",
       " 651: '続く',\n",
       " 652: '新',\n",
       " 653: 'つくり',\n",
       " 654: '通信',\n",
       " 655: '技術',\n",
       " 656: '伝え',\n",
       " 657: '繋げ',\n",
       " 658: '大量',\n",
       " 659: '一気',\n",
       " 660: '取れる',\n",
       " 661: 'まま',\n",
       " 662: '機能',\n",
       " 663: '代わら',\n",
       " 664: 'ケイタイ',\n",
       " 665: '電子',\n",
       " 666: '用品',\n",
       " 667: '以外',\n",
       " 668: 'ぬ',\n",
       " 669: '年寄り',\n",
       " 670: '使い',\n",
       " 671: '飛行',\n",
       " 672: '器',\n",
       " 673: '病院',\n",
       " 674: '取れ',\n",
       " 675: '品',\n",
       " 676: '楽しむ',\n",
       " 677: '触っ',\n",
       " 678: 'ページ',\n",
       " 679: 'めくり',\n",
       " 680: '気',\n",
       " 681: '入る',\n",
       " 682: 'イメージ',\n",
       " 683: 'はさみ',\n",
       " 684: '切り取っ',\n",
       " 685: 'メーモー',\n",
       " 686: '貼る',\n",
       " 687: 'ふう',\n",
       " 688: '楽し',\n",
       " 689: '藝能',\n",
       " 690: 'スポーツ',\n",
       " 691: '選手',\n",
       " 692: '思い出',\n",
       " 693: '作り',\n",
       " 694: '載っ',\n",
       " 695: '各種',\n",
       " 696: '割引券',\n",
       " 697: '主婦',\n",
       " 698: '原因',\n",
       " 699: '一般',\n",
       " 700: 'ウェブ',\n",
       " 701: 'いっぱい',\n",
       " 702: '何日',\n",
       " 703: 'わたっ',\n",
       " 704: '一回',\n",
       " 705: 'たい',\n",
       " 706: 'とき',\n",
       " 707: '削除',\n",
       " 708: '出版',\n",
       " 709: 'されば',\n",
       " 710: '消え',\n",
       " 711: '合わせ',\n",
       " 712: 'しんにょう',\n",
       " 713: '選',\n",
       " 714: 'おかげ',\n",
       " 715: '国際化',\n",
       " 716: '入り',\n",
       " 717: 'つつ',\n",
       " 718: 'かわり',\n",
       " 719: 'あいかわらず',\n",
       " 720: '木',\n",
       " 721: '生命力',\n",
       " 722: '比較',\n",
       " 723: 'ノート',\n",
       " 724: '書く',\n",
       " 725: '直接',\n",
       " 726: '書きこま',\n",
       " 727: '違っ',\n",
       " 728: '編集者',\n",
       " 729: '信憑性',\n",
       " 730: '比較的',\n",
       " 731: '高い',\n",
       " 732: '有名',\n",
       " 733: '多',\n",
       " 734: 'せい',\n",
       " 735: '採用',\n",
       " 736: 'あらためて',\n",
       " 737: '確認',\n",
       " 738: '写真',\n",
       " 739: '当事者',\n",
       " 740: 'わくわく',\n",
       " 741: '紀念',\n",
       " 742: 'からだ',\n",
       " 743: '興奮',\n",
       " 744: 'なかなか',\n",
       " 745: 'こ',\n",
       " 746: '欧米',\n",
       " 747: '先進国',\n",
       " 748: '除い',\n",
       " 749: '人口',\n",
       " 750: 'まだ',\n",
       " 751: 'わずか',\n",
       " 752: '占め',\n",
       " 753: '言う',\n",
       " 754: '捨てよう',\n",
       " 755: '将来',\n",
       " 756: '消える',\n",
       " 757: 'はず',\n",
       " 758: '温度',\n",
       " 759: '合う',\n",
       " 760: 'あかし',\n",
       " 761: '読み',\n",
       " 762: '出来事',\n",
       " 763: 'ふんいき',\n",
       " 764: 'なつかしい',\n",
       " 765: '命',\n",
       " 766: '発行',\n",
       " 767: '量',\n",
       " 768: '減る',\n",
       " 769: '保つ',\n",
       " 770: 'むだ',\n",
       " 771: 'それぞれ',\n",
       " 772: '進み',\n",
       " 773: 'ハイテイク',\n",
       " 774: '産物',\n",
       " 775: '大層',\n",
       " 776: '変え',\n",
       " 777: '方々',\n",
       " 778: '発生',\n",
       " 779: 'ばかり',\n",
       " 780: '事',\n",
       " 781: '入ら',\n",
       " 782: '必要性',\n",
       " 783: '所々',\n",
       " 784: '常',\n",
       " 785: '調査',\n",
       " 786: '間違っ',\n",
       " 787: 'しまっ',\n",
       " 788: '立た',\n",
       " 789: 'むしろ',\n",
       " 790: 'ちんと',\n",
       " 791: '整い',\n",
       " 792: 'よい',\n",
       " 793: '更に',\n",
       " 794: '疲れ',\n",
       " 795: '記さ',\n",
       " 796: 'コンピュータ',\n",
       " 797: 'メイディアー',\n",
       " 798: '器材',\n",
       " 799: '不',\n",
       " 800: '公平性',\n",
       " 801: '公平',\n",
       " 802: '換え',\n",
       " 803: 'り',\n",
       " 804: '難い',\n",
       " 805: '正しい',\n",
       " 806: '最後',\n",
       " 807: '接',\n",
       " 808: '明か',\n",
       " 809: 'つながっ',\n",
       " 810: '村',\n",
       " 811: 'いえる',\n",
       " 812: '知り',\n",
       " 813: '出す',\n",
       " 814: '向き',\n",
       " 815: '時点',\n",
       " 816: '間違い',\n",
       " 817: '比べる',\n",
       " 818: '中二',\n",
       " 819: '十四',\n",
       " 820: '各地',\n",
       " 821: '読み切り',\n",
       " 822: '密',\n",
       " 823: '切',\n",
       " 824: '関連',\n",
       " 825: 'すぎ',\n",
       " 826: '混雑',\n",
       " 827: '経',\n",
       " 828: '選択',\n",
       " 829: '大体',\n",
       " 830: '状態',\n",
       " 831: 'わかる',\n",
       " 832: '通勤',\n",
       " 833: '通学',\n",
       " 834: '持た',\n",
       " 835: 'つなげる',\n",
       " 836: 'すごく',\n",
       " 837: '減量',\n",
       " 838: '森',\n",
       " 839: '守る',\n",
       " 840: '上述',\n",
       " 841: '解決',\n",
       " 842: '限り',\n",
       " 843: 'どのような',\n",
       " 844: 'みんな',\n",
       " 845: 'もたらす',\n",
       " 846: 'バランス',\n",
       " 847: '地球',\n",
       " 848: '生き',\n",
       " 849: 'われわれ',\n",
       " 850: '今日',\n",
       " 851: '大事',\n",
       " 852: '起き',\n",
       " 853: '関する',\n",
       " 854: 'すべて',\n",
       " 855: 'インフォーメーション',\n",
       " 856: 'マウス',\n",
       " 857: '映る',\n",
       " 858: '火山',\n",
       " 859: '爆発',\n",
       " 860: '如き',\n",
       " 861: '提出',\n",
       " 862: 'お',\n",
       " 863: '分かれ',\n",
       " 864: '出現',\n",
       " 865: '促成',\n",
       " 866: '肝心',\n",
       " 867: '要因',\n",
       " 868: '送っ',\n",
       " 869: '電気',\n",
       " 870: '製品',\n",
       " 871: '交流',\n",
       " 872: '関係',\n",
       " 873: 'なん',\n",
       " 874: '違',\n",
       " 875: 'させる',\n",
       " 876: '忘れ',\n",
       " 877: '収集',\n",
       " 878: 'つけ',\n",
       " 879: 'かかわっ',\n",
       " 880: '陥',\n",
       " 881: '一筋',\n",
       " 882: '唱え',\n",
       " 883: '崇拝',\n",
       " 884: '行為',\n",
       " 885: '即ち',\n",
       " 886: '科学',\n",
       " 887: '勢い',\n",
       " 888: '広く',\n",
       " 889: 'エンターテーメント',\n",
       " 890: '分野',\n",
       " 891: '我々',\n",
       " 892: '一般的',\n",
       " 893: '言えよう',\n",
       " 894: 'つける',\n",
       " 895: 'メール',\n",
       " 896: 'チェック',\n",
       " 897: 'ブログ',\n",
       " 898: '欠く',\n",
       " 899: '新聞紙',\n",
       " 900: 'くらい',\n",
       " 901: '大きさ',\n",
       " 902: '通勤時間',\n",
       " 903: 'つらい',\n",
       " 904: 'でる',\n",
       " 905: '墨',\n",
       " 906: '汚れる',\n",
       " 907: '資源',\n",
       " 908: '減り',\n",
       " 909: '作る',\n",
       " 910: '切る',\n",
       " 911: 'やさしい',\n",
       " 912: '良い',\n",
       " 913: '携帯',\n",
       " 914: 'つなげ',\n",
       " 915: 'さえ',\n",
       " 916: 'いれ',\n",
       " 917: 'ありがたい',\n",
       " 918: '国際',\n",
       " 919: '一員',\n",
       " 920: '他人',\n",
       " 921: '交換',\n",
       " 922: '全面的',\n",
       " 923: '取っ',\n",
       " 924: 'わ',\n",
       " 925: 'える',\n",
       " 926: '第一',\n",
       " 927: 'しも',\n",
       " 928: '限ら',\n",
       " 929: 'すでに',\n",
       " 930: '慣れ',\n",
       " 931: '激しく',\n",
       " 932: '行わ',\n",
       " 933: '正確',\n",
       " 934: '疑わ',\n",
       " 935: 'つの',\n",
       " 936: 'できれ',\n",
       " 937: '見い出せる',\n",
       " 938: 'タイトル',\n",
       " 939: '反対',\n",
       " 940: 'いくつ',\n",
       " 941: '方便',\n",
       " 942: 'ボッタ',\n",
       " 943: '遙か',\n",
       " 944: '重さ',\n",
       " 945: '条件',\n",
       " 946: 'けいたい',\n",
       " 947: '亭',\n",
       " 948: '重い',\n",
       " 949: '開け',\n",
       " 950: '報',\n",
       " 951: '導',\n",
       " 952: '空白',\n",
       " 953: '所',\n",
       " 954: '若者',\n",
       " 955: 'ね',\n",
       " 956: '苦手',\n",
       " 957: '一部',\n",
       " 958: '一度',\n",
       " 959: 'っ',\n",
       " 960: 'たこ',\n",
       " 961: '取る',\n",
       " 962: '嫌',\n",
       " 963: 'あまり',\n",
       " 964: '依頼',\n",
       " 965: '動け',\n",
       " 966: '困る',\n",
       " 967: 'よ',\n",
       " 968: '減',\n",
       " 969: 'いく',\n",
       " 970: '使',\n",
       " 971: 'ったら',\n",
       " 972: 'なくなる',\n",
       " 973: '語',\n",
       " 974: '住ん',\n",
       " 975: 'とくに',\n",
       " 976: 'じょうほう',\n",
       " 977: 'えら',\n",
       " 978: '本屋',\n",
       " 979: 'そんざい',\n",
       " 980: 'ちがう',\n",
       " 981: '要ら',\n",
       " 982: 'なくし',\n",
       " 983: 'かまわ',\n",
       " 984: 'へんじ',\n",
       " 985: 'いいえ',\n",
       " 986: '思ん',\n",
       " 987: 'ぜひ',\n",
       " 988: 'てんき',\n",
       " 989: 'きぐ',\n",
       " 990: 'ばあい',\n",
       " 991: 'ないよう',\n",
       " 992: 'かくにん',\n",
       " 993: 'こども',\n",
       " 994: 'ばあ',\n",
       " 995: 'くらべる',\n",
       " 996: 'かぎ',\n",
       " 997: 'えぎ',\n",
       " 998: 'ほん',\n",
       " 999: 'てき',\n",
       " ...}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "# with open('index2word.pickle', 'wb') as f:\n",
    "#     pickle.dump(index2word, f)\n",
    "    \n",
    "index2word = pickle.load(open('index2word.pickle', 'rb'))\n",
    "word2index = dict((i, w) for w, i in index2word.items())\n",
    "# index2word[4882], word2index[\"愉快\"]\n",
    "index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f495f511-d7dd-47b2-a933-244d196ac6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma size: 4883\n"
     ]
    }
   ],
   "source": [
    "print(\"vocab size: {}\".format(len(word2index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a688b5e-5b92-48ae-9059-861739788c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8559e3f-afd9-4060-9d49-c8122f559d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# nlp = spacy.load('ja_ginza_electra')\n",
    "nlp = spacy.load('ja_ginza')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "category_vectors = []\n",
    "\n",
    "for cat, text in text_tagged_dict.items():\n",
    "    for sents in tqdm(text):\n",
    "        sents = nlp(sents)\n",
    "        word_vector = np.array([tok.vector for tok in sents])\n",
    "        # sent_vecs = []\n",
    "        # for sent in sents:\n",
    "        #     sent = nlp(sent)\n",
    "        #     word_vector = np.array([tok.vector for tok in sent])\n",
    "        #     sent_vecs.append(word_vector)\n",
    "        category_vectors.append((cat, np.array(sent_vecs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ce7a9-e3ef-48af-9262-f1ab38fe2749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45aa3438-937f-4e39-86c7-b2a893cbec7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fbcfea0-b594-4021-9888-a895d2d8736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "# an Embedding module containing 10 tensors of size 3\n",
    "embedding = nn.Embedding(10, 3)\n",
    "\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "embedding(input).size()\n",
    "\n",
    "\n",
    "# # example with padding_idx\n",
    "# embedding = nn.Embedding(10, 3, padding_idx=0)\n",
    "# input = torch.LongTensor([[0,2,0,5]])\n",
    "# embedding(input)\n",
    "\n",
    "# # example of changing `pad` vector\n",
    "# padding_idx = 0\n",
    "# embedding = nn.Embedding(3, 3, padding_idx=padding_idx)\n",
    "# embedding.weight\n",
    "# with torch.no_grad():\n",
    "#     embedding.weight[padding_idx] = torch.ones(3)\n",
    "# embedding.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff61908-e9b1-440b-a51c-71de6ea04740",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "- num_embeddings (int) – size of the dictionary of embeddings\n",
    "\n",
    "- embedding_dim (int) – the size of each embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e4779e-7851-494a-af4e-d70fac6cd738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a5a2e0c6-653d-4a26-aba1-dce1efed112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2 = {}\n",
    "for level in text_tagged_dict2.keys():\n",
    "    dict2[level] = (\"\").join(text_tagged_dict2[level])\n",
    "    \n",
    "# dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a4456843-cd83-4ab7-a83c-326d39fab55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length: [14443, 50572, 64466]\n",
      "vocab: [625, 966, 1087]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "length = [len(dict2[level]) for level in dict2.keys()]\n",
    "chars = [sorted(list(set(dict2[level]))) for level in dict2.keys()]\n",
    "char_length = [len(char) for char in chars]\n",
    "\n",
    "print(\"text length: {}\".format(length))\n",
    "print(\"vocab: {}\".format(char_length))\n",
    "# len(chars[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf423b-fb2c-4f35-b1f3-ecf5a80046fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ee05734-697e-4910-b08b-cce7b1f68b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# a = [1, 2, 3]\n",
    "# a_string = map(str, a)\n",
    "# print(list(a_string))\n",
    "# b = (\"\").join(a_string)\n",
    "# print(list(a_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646407a1-f75e-4df5-a43d-51f519484096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cfb293-32e1-4ce6-a3be-e947c031df4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "996ee578-8744-4c7d-80ef-e204761e5a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:01<00:00, 11.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [00:07<00:00, 12.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:08<00:00, 12.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# nlp = spacy.load('ja_ginza_electra')\n",
    "nlp = spacy.load('ja_ginza')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "category_vectors = []\n",
    "\n",
    "for cat, text in text_tagged_dict.items():\n",
    "    for sents in tqdm(text):\n",
    "        sents = nlp(sents)\n",
    "        word_vector = np.array([tok.vector for tok in sents])\n",
    "        # sent_vecs = []\n",
    "        # for sent in sents:\n",
    "        #     sent = nlp(sent)\n",
    "        #     word_vector = np.array([tok.vector for tok in sent])\n",
    "        #     sent_vecs.append(word_vector)\n",
    "        category_vectors.append((cat, np.array(sent_vecs)))\n",
    "    \n",
    "# 一つの長文の形に変形したのでspacyでうまくいくかわからない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "42697ce7-bc9e-48f9-8908-d9064e309df2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('初級',\n",
       " array([[[-0.0063053 , -0.04985307, -0.22556107, ...,  0.06186676,\n",
       "          -0.05566797, -0.00957808]],\n",
       " \n",
       "        [[-0.08274004, -0.09103364, -0.08744463, ..., -0.06126847,\n",
       "          -0.00597147, -0.00478465]],\n",
       " \n",
       "        [[ 0.17216177,  0.09944343,  0.38480812, ...,  0.17196812,\n",
       "           0.02225779,  0.12094363]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.09195102, -0.10327693, -0.11661331, ..., -0.12604538,\n",
       "          -0.07508431,  0.0575574 ]],\n",
       " \n",
       "        [[ 0.30234763,  0.10496894,  0.24105701, ..., -0.06826453,\n",
       "          -0.29353613,  0.07642345]],\n",
       " \n",
       "        [[-0.10983511, -0.1689055 , -0.12226205, ..., -0.07010163,\n",
       "           0.05129355, -0.01890929]]], dtype=float32))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e3584d5f-9a28-42e7-95f1-4fe13e09d5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 300)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(category_vectors[0][1]).reshape((174, 300)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4ddfa-5263-4c31-b8e8-fd62ff964fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# # nlp = spacy.load('ja_ginza_electra')\n",
    "# nlp = spacy.load('ja_ginza')\n",
    "\n",
    "# import tqdm\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# category_vectors = []\n",
    "\n",
    "# for cat, text in text_tagged_dict2.items():\n",
    "#     for sents in tqdm(text):\n",
    "#         sent_vecs = []\n",
    "#         for sent in sents:\n",
    "#             sent = nlp(sent)\n",
    "#             word_sum = np.sum([tok.vector for tok in sent], axis=0)\n",
    "#             sent_vecs.append(word_sum)\n",
    "#         category_vectors.append((cat, np.sum(sent_vecs, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "69589f43-9229-4f42-8448-a473d3de18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "# with open('category_vectors.pickle', 'wb') as f:\n",
    "#     pickle.dump(category_vectors, f)\n",
    "    \n",
    "category_vectors2 = pickle.load(open('category_vectors.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "01150048-aa9c-496b-8136-a7ee459a971d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>中級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>中級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>中級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>中級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>中級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat                                            vectors\n",
       "0    初級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "1    初級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "2    初級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "3    初級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "4    初級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "..   ..                                                ...\n",
       "219  中級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "220  中級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "221  中級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "222  中級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "223  中級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "\n",
       "[224 rows x 2 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "keys, values = zip(*category_vectors)\n",
    "\n",
    "values = [np.squeeze(value, axis=1) for value in values]\n",
    "\n",
    "# values = np.array(values).reshape((174, 300))\n",
    "\n",
    "data = pd.DataFrame({'cat': keys, 'vectors': values})\n",
    "# data2 = Counter(data.cat)\n",
    "# data2\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "09188006-291a-4072-b179-8935cdf5c3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 300)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e7d46bcd-74c9-4900-96d6-7f79cf3530ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 1, 300)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d6d4561-8ed6-4ca5-a106-4f607181fd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 1, 300)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vectors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "854dfd53-ba0d-40b3-b908-a9f6416cc3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f6fbecde-b9c1-4d06-8571-15f763c58b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 2), (179, 2))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.sample(frac=0.2, random_state=200)\n",
    "train = data.drop(test.index)\n",
    "\n",
    "test.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5738acb-f0ae-4ad9-8c77-cd75b56c98f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cbfa9c34-0f23-4c08-8805-6777edc953e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data.cat)\n",
    "X = [x for x in train.vectors]\n",
    "y = le.transform(train.cat)\n",
    "\n",
    "# [x.shape for x in X]\n",
    "# len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9a11217b-6769-4975-9777-c2301be137dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179,)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "50c237a9-33c4-4be8-8b21-6f5089ba7c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 2), (179, 2))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.sample(frac=0.2, random_state=200)\n",
    "train = data.drop(test.index)\n",
    "\n",
    "test.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cea012-7672-4554-9fae-d05593fc7bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8743db7a-cfc7-4e68-a622-abfbe681ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rnn = 10  # 時系列の数\n",
    "batch_size = 128\n",
    "epochs = 20  #epochsは、多いほど、精密に学習するが、重くなるため今回は小さくしている\n",
    "n_mid = 256  # 中間層のニューロン数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b8441508-6ce0-4245-b039-d7e9a98b8bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 256)               570368    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10000)             2570000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,140,368\n",
      "Trainable params: 3,140,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, 300)))\n",
    "model_lstm.add(Dense(10000, activation=\"softmax\"))\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0614054f-c73b-4344-b00b-05c0093d3e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 10, 300), found shape=(None, 174, 300)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [128]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model_lstm\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel_lstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\FIC202~1.002\\AppData\\Local\\Temp\\__autograph_generated_file6fa0mjai.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 10, 300), found shape=(None, 174, 300)\n"
     ]
    }
   ],
   "source": [
    "model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model_lstm.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "02e1dbef-d8d1-4da1-876a-bbfa5579ce8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((179, 174, 300), (179, 3))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "le.fit(data.cat)\n",
    "y_train = le.transform(train.cat).reshape(-1, 1)\n",
    "ohe.fit(y_train)\n",
    "y_train = ohe.transform(y_train).todense()\n",
    "\n",
    "X_train = np.array([x for x in train.vectors])\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd283618-567b-4b7d-b24c-2b1febd08729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13fc15ed-6bda-493d-abf2-51ad6b4ab2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c6f840e-7656-49bc-9fac-94487c6c95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data.cat)\n",
    "X = [x for x in train.vectors]\n",
    "y = le.transform(train.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d5c60ac-01c5-4102-b201-f7e75e9d5e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((179, 300), (179, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "le.fit(data.cat)\n",
    "y_train = le.transform(train.cat).reshape(-1, 1)\n",
    "ohe.fit(y_train)\n",
    "y_train = ohe.transform(y_train).todense()\n",
    "\n",
    "X_train = np.array([x for x in train.vectors])\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27a9ed1-3674-4939-94fd-d87d1dbf08fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35.72873  , -75.88274  ,   1.2493681, ..., -46.46502  ,\n",
       "        -22.483027 , -23.89953  ],\n",
       "       [ 28.799707 , -52.42878  ,   4.982424 , ..., -28.353933 ,\n",
       "        -15.14752  , -12.70157  ],\n",
       "       [ 24.782848 , -50.567856 ,   3.9012423, ..., -28.780779 ,\n",
       "        -13.119149 , -10.998436 ],\n",
       "       ...,\n",
       "       [ 13.380746 , -38.492195 ,   1.7690995, ..., -25.462816 ,\n",
       "         -5.160268 ,  -7.710597 ],\n",
       "       [ 30.981627 , -44.044937 ,   6.382059 , ..., -31.046907 ,\n",
       "        -15.398306 ,  -6.9955473],\n",
       "       [ 33.65297  , -54.06166  ,   4.3123937, ..., -28.694584 ,\n",
       "        -19.503485 ,  -9.43222  ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00abde5f-60f0-4ee6-8c91-ca9273b1e7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 300), (45, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "le.fit(data.cat)\n",
    "y_test = le.transform(test.cat).reshape(-1, 1)\n",
    "ohe.fit(y_test)\n",
    "y_test = ohe.transform(y_test).todense()\n",
    "\n",
    "X_test = np.array([x for x in test.vectors])\n",
    "\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e194a5eb-8389-45eb-b808-a4d9a722b4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         6400000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 128)        98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,598,019\n",
      "Trainable params: 6,598,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Bidirectional, Dense, LSTM\n",
    "import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "model.add(inputs)\n",
    "model.add(Embedding(50000, 128))\n",
    "# Add 2 bidirectional LSTMs\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "# Add a classifier\n",
    "model.add(Dense(3, activation=\"sigmoid\"))\n",
    "#model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cb892916-003d-433e-8135-ab65d837805d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [125]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d422c-0115-4f6f-88fe-0017a3f17ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qiita.com/KojiOhki/items/89cd7b69a8a6239d67ca#lstm%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF\n",
    "# https://own-search-and-study.xyz/2018/09/17/keras%E3%81%A7lstm%E3%82%92%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%89%8B%E9%A0%86%E3%82%92%E6%95%B4%E7%90%86%E3%81%97%E3%81%A6%E3%81%BF%E3%81%9F/\n",
    "# https://qiita.com/sasayabaku/items/b7872a3b8acc7d6261bf\n",
    "# https://shiva-verma.medium.com/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e\n",
    "# https://www.kaggle.com/code/ranxi169/sentiment-classification-using-lstm/notebook\n",
    "# https://qiita.com/hara_tatsu/items/d1ddb5f1e0dee55dcdfa\n",
    "# https://qiita.com/hara_tatsu/items/c3ba100e95e600846125\n",
    "# https://keras.io/api/layers/recurrent_layers/lstm/\n",
    "\n",
    "\n",
    "\n",
    "# https://gist.github.com/jshirius/a38ed0824e9adaea66e87811514b0b9f#file-lstm_ginga-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "676cd8e5-50c6-4728-98aa-57fe97992d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = tf.constant(a)\n",
    "a[0] = 4\n",
    "print(b)  # tf.Tensor([4 2 3], shape=(3,), dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffddb98-48b5-4aca-ba0f-9ed21a38672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://propen.dream-target.jp/blog/keras_lstm\n",
    "# https://qiita.com/m__k/items/841950a57a0d7ff05506\n",
    "# https://kagglenote.com/kaggle/keras-lstm-textclassifier/\n",
    "# https://gist.github.com/jshirius/a38ed0824e9adaea66e87811514b0b9f#file-lstm_ginga-ipynb\n",
    "# https://own-search-and-study.xyz/2018/09/17/keras%E3%81%A7lstm%E3%82%92%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%89%8B%E9%A0%86%E3%82%92%E6%95%B4%E7%90%86%E3%81%97%E3%81%A6%E3%81%BF%E3%81%9F/\n",
    "# https://toge510.com/2020/01/11/makesentencesbylstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c345b4-0a66-44b3-a848-7160e3f8174b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbc9942-17a8-481a-a2d8-4d39b5e98c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d01e3-41a5-4369-84e2-6dc3f5b1976e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e1f12-84e4-46fa-a483-7b7052858bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
