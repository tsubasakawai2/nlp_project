{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13b60299-c959-479a-8d50-c3cb97e49d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学習者のID</th>\n",
       "      <th>学習者の性別</th>\n",
       "      <th>学習環境</th>\n",
       "      <th>作文テーマ</th>\n",
       "      <th>学習者の母語</th>\n",
       "      <th>日本語学習履歴</th>\n",
       "      <th>日本語レベル</th>\n",
       "      <th>テスト成績（文字語彙）</th>\n",
       "      <th>テスト成績（文法）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CG009</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CG011</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CG013</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CG015</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CG017</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>KN303</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>KN307</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>KN312</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>KN313</td>\n",
       "      <td>男</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>KN316</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    学習者のID 学習者の性別 学習環境            作文テーマ 学習者の母語   日本語学習履歴 日本語レベル テスト成績（文字語彙）  \\\n",
       "0    CG009      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "1    CG011      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "2    CG013      男   国外  外国語がうまくなる方法について    中国語      2年未満     上級           A   \n",
       "3    CG015      男   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "4    CG017      女   国外  外国語がうまくなる方法について    中国語      2年未満     中級           B   \n",
       "..     ...    ...  ...              ...    ...       ...    ...         ...   \n",
       "299  KN303      女   国内  外国語がうまくなる方法について    韓国語      2年未満     中級           X   \n",
       "300  KN307      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "301  KN312      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "302  KN313      男   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "303  KN316      女   国内  外国語がうまくなる方法について    韓国語      5年以上     上級           X   \n",
       "\n",
       "    テスト成績（文法）  \n",
       "0           C  \n",
       "1           B  \n",
       "2           A  \n",
       "3           B  \n",
       "4           A  \n",
       "..        ...  \n",
       "299         X  \n",
       "300         X  \n",
       "301         X  \n",
       "302         X  \n",
       "303         X  \n",
       "\n",
       "[304 rows x 9 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "path = \"data/register.xls\"\n",
    "labels = pd.read_excel(path)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98583a0b-403d-4212-8f28-f019e4a13f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学習者のID</th>\n",
       "      <th>学習者の性別</th>\n",
       "      <th>学習環境</th>\n",
       "      <th>作文テーマ</th>\n",
       "      <th>学習者の母語</th>\n",
       "      <th>日本語学習履歴</th>\n",
       "      <th>日本語レベル</th>\n",
       "      <th>テスト成績（文字語彙）</th>\n",
       "      <th>テスト成績（文法）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CG009</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CG011</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CG013</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CG015</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>初級</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CG017</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>KN303</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>KN307</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>KN312</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>KN313</td>\n",
       "      <td>男</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>KN316</td>\n",
       "      <td>女</td>\n",
       "      <td>国内</td>\n",
       "      <td>外国語がうまくなる方法について</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    学習者のID 学習者の性別 学習環境            作文テーマ 学習者の母語   日本語学習履歴 日本語レベル テスト成績（文字語彙）  \\\n",
       "0    CG009      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "1    CG011      女   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "2    CG013      男   国外  外国語がうまくなる方法について    中国語      2年未満     上級           A   \n",
       "3    CG015      男   国外  外国語がうまくなる方法について    中国語      2年未満     初級           B   \n",
       "4    CG017      女   国外  外国語がうまくなる方法について    中国語      2年未満     中級           B   \n",
       "..     ...    ...  ...              ...    ...       ...    ...         ...   \n",
       "299  KN303      女   国内  外国語がうまくなる方法について    韓国語      2年未満     中級           X   \n",
       "300  KN307      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "301  KN312      女   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "302  KN313      男   国内  外国語がうまくなる方法について    韓国語  2年以上5年未満     上級           X   \n",
       "303  KN316      女   国内  外国語がうまくなる方法について    韓国語      5年以上     上級           X   \n",
       "\n",
       "    テスト成績（文法）  \n",
       "0           C  \n",
       "1           B  \n",
       "2           A  \n",
       "3           B  \n",
       "4           A  \n",
       "..        ...  \n",
       "299         X  \n",
       "300         X  \n",
       "301         X  \n",
       "302         X  \n",
       "303         X  \n",
       "\n",
       "[192 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "label1 = labels.loc[labels.作文テーマ == \"外国語がうまくなる方法について\",:]\n",
    "label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "834e01d4-9aac-47c2-97bb-142ca7a152b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学習者のID</th>\n",
       "      <th>学習者の性別</th>\n",
       "      <th>学習環境</th>\n",
       "      <th>作文テーマ</th>\n",
       "      <th>学習者の母語</th>\n",
       "      <th>日本語学習履歴</th>\n",
       "      <th>日本語レベル</th>\n",
       "      <th>テスト成績（文字語彙）</th>\n",
       "      <th>テスト成績（文法）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>CG101</td>\n",
       "      <td>男</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>CG102</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>CG103</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CG104</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>CG105</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>中国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>KG151</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>KG152</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>KG153</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年以上5年未満</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>KG154</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>2年未満</td>\n",
       "      <td>中級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>KG155</td>\n",
       "      <td>女</td>\n",
       "      <td>国外</td>\n",
       "      <td>インターネット時代に新聞や雑誌は必要か</td>\n",
       "      <td>韓国語</td>\n",
       "      <td>5年以上</td>\n",
       "      <td>上級</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    学習者のID 学習者の性別 学習環境                作文テーマ 学習者の母語   日本語学習履歴 日本語レベル  \\\n",
       "76   CG101      男   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "77   CG102      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "78   CG103      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "79   CG104      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     中級   \n",
       "80   CG105      女   国外  インターネット時代に新聞や雑誌は必要か    中国語  2年以上5年未満     上級   \n",
       "..     ...    ...  ...                  ...    ...       ...    ...   \n",
       "292  KG151      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語      5年以上     上級   \n",
       "293  KG152      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語  2年以上5年未満     上級   \n",
       "294  KG153      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語  2年以上5年未満     上級   \n",
       "295  KG154      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語      2年未満     中級   \n",
       "296  KG155      女   国外  インターネット時代に新聞や雑誌は必要か    韓国語      5年以上     上級   \n",
       "\n",
       "    テスト成績（文字語彙） テスト成績（文法）  \n",
       "76            X         X  \n",
       "77            X         X  \n",
       "78            X         X  \n",
       "79            X         X  \n",
       "80            X         X  \n",
       "..          ...       ...  \n",
       "292           X         X  \n",
       "293           X         X  \n",
       "294           X         X  \n",
       "295           X         X  \n",
       "296           X         X  \n",
       "\n",
       "[112 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2 = labels.loc[labels.作文テーマ == \"インターネット時代に新聞や雑誌は必要か\",:]\n",
    "label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1ec06dd-dcd9-4ff8-be26-c2eb5e3feef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['初級', '初級', '上級', '初級', '中級', '中級', '中級', '上級', '中級', '中級', '中級',\n",
       "        '上級', '中級', '中級', '中級', '初級', '中級', '上級', '初級', '初級', '中級', '中級',\n",
       "        '初級', '中級', '中級', '上級', '中級', '中級', '初級', '上級', '上級', '初級', '中級',\n",
       "        '中級', '上級', '中級', '中級', '初級', '初級', '中級', '上級', '中級', '上級', '中級',\n",
       "        '上級', '中級', '初級', '中級', '中級', '初級', '上級', '初級', '中級', '中級', '上級',\n",
       "        '初級', '初級', '上級', '上級', '中級', '中級', '中級', '上級', '中級', '中級', '上級',\n",
       "        '中級', '中級', '中級', '初級', '中級', '初級', '中級', '中級', '上級', '上級', '初級',\n",
       "        '上級', '中級', '中級', '上級', '中級', '中級', '中級', '中級', '中級', '中級', '中級',\n",
       "        '中級', '中級', '上級', '中級', '中級', '初級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '中級', '中級', '中級', '中級', '初級', '中級', '中級', '初級', '中級', '中級', '中級',\n",
       "        '上級', '中級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '中級', '中級',\n",
       "        '上級', '中級', '上級', '上級', '中級', '上級', '上級', '中級', '中級', '初級', '中級',\n",
       "        '中級', '上級', '中級', '上級', '上級', '上級', '中級', '上級', '中級', '上級', '上級',\n",
       "        '上級', '中級', '初級', '中級', '中級', '上級', '上級', '中級', '中級', '上級', '上級',\n",
       "        '上級', '中級', '初級', '中級', '中級', '中級', '上級', '中級', '初級', '中級', '中級',\n",
       "        '中級', '上級', '初級', '上級', '中級', '中級', '中級', '初級', '中級', '中級', '中級',\n",
       "        '中級', '初級', '中級', '初級', '初級', '中級', '中級', '中級', '中級', '上級', '中級',\n",
       "        '中級', '上級', '上級', '上級', '上級'], dtype=object),\n",
       " 192)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level1 = np.array(label1.日本語レベル)\n",
    "level1, len(level1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c847ac2a-1c01-4872-b656-12ebc25ad33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中級', '中級', '中級', '中級', '上級', '中級', '中級', '中級', '上級', '中級', '中級',\n",
       "        '中級', '中級', '上級', '上級', '中級', '中級', '中級', '上級', '中級', '中級', '中級',\n",
       "        '中級', '上級', '中級', '中級', '中級', '中級', '中級', '上級', '中級', '中級', '中級',\n",
       "        '上級', '中級', '中級', '中級', '中級', '中級', '中級', '中級', '上級', '中級', '中級',\n",
       "        '中級', '中級', '上級', '中級', '中級', '上級', '中級', '中級', '中級', '上級', '中級',\n",
       "        '上級', '上級', '上級', '上級', '中級', '上級', '上級', '上級', '中級', '上級', '上級',\n",
       "        '中級', '上級', '上級', '上級', '中級', '上級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '上級', '上級', '上級', '上級', '上級', '上級', '中級', '上級', '上級', '上級', '上級',\n",
       "        '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級', '上級',\n",
       "        '中級', '上級'], dtype=object),\n",
       " 112)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level2 = np.array(label2.日本語レベル)\n",
    "level2, len(level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dca6d9-408a-4711-a600-912f494fd62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8c86efb-bf58-4252-be6f-ca08ba4da7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "txt_path = \"data/txt/\"\n",
    "txt_topics = listdir(txt_path)\n",
    "\n",
    "txt_gaigo_path = txt_path + txt_topics[0]\n",
    "txt_internet_path = txt_path + txt_topics[1]\n",
    "\n",
    "txt_gaigo_files = listdir(txt_gaigo_path)\n",
    "txt_internet_files = listdir(txt_internet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e201e92-620e-46fe-a758-bb3787d99647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5889ef08-8537-4546-a485-ddfdd2aa65b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'私は大学日本語科の一年生です最初日本語が難しいと思いましたそれから先生が日本語がうまくなる方法を聞きました先生は毎日単語を覚えるとか日本語の文章を読むとかドラマをみますと言いました私は先生が教えたとおりにしていました毎朝単語を読んでいましたよるドラマを見ていました難しい内容をあった先生に聞きました重要な内容を整理しました日本語の口頭試験がよいためにたくさん練習しましたたくさんの日本の歌を聞きました歌を聞きながら歌の内容を書きましたいま私は日本語がやさしいと思います'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os.path as osp\n",
    "# import re\n",
    "# gaigo_files = [f for f in listdir(osp.join(txt_path, txt_topics[0])) if f.endswith('.txt')]\n",
    "# gaigo = []\n",
    "# for gaigo_file in gaigo_files:\n",
    "#     # print(gaigo_file)\n",
    "#     with open(osp.join(txt_path, txt_topics[0], gaigo_file), \"r\", encoding=\"utf-8\") as f:\n",
    "#         lines = f.read()\n",
    "#         # type(lines)\n",
    "#         lines = re.sub('\\n', '', lines)\n",
    "#         lines = re.sub('\\u3000', '', lines)\n",
    "#     gaigo.append(lines)\n",
    "# # type(gaigo[0])\n",
    "# # gaigo[0][0]\n",
    "\n",
    "import os.path as osp\n",
    "import re\n",
    "gaigo_files = [f for f in listdir(osp.join(txt_path, txt_topics[0])) if f.endswith('.txt')]\n",
    "gaigo = []\n",
    "for gaigo_file in gaigo_files:\n",
    "    # print(gaigo_file)\n",
    "    with open(osp.join(txt_path, txt_topics[0], gaigo_file), \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read()\n",
    "        # type(lines)\n",
    "        lines = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", lines)\n",
    "        lines = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", lines)\n",
    "\n",
    "    gaigo.append(lines)\n",
    "# type(gaigo[0])\n",
    "gaigo[0]\n",
    "\n",
    "# 注意。注釈は削除していない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec8cc9c2-1357-4ff9-90ce-b5585ec755b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'この数十年の間にテレビや携帯電話などの便利なものは世界的に使われていて私たち現代人の生活に大きな役に立っているのだその何種類の産品の中に一番の便利さが持っていて生活を影響するのはコンピューターだと思う今は何でもコンピューターでできるんでしょう例えばネットを使ってどの国にどんなことがあったかのがすぐ分かることとかネットで買い物したりホテルを予約したりすることとかいろいろなことがただ指で完成できるその一方でコンピューターの発達によってたくさん問題も次から次へと生じるずっとコンピューターで宿題やレポートをすると今の子たちはほとんど字がきたなくなったり書けない漢字も昔より増えてきたらしいだからうまくコンピューターを利用できるかどうかは私たちにとって重要な課題になるさっき言ったようにネットでどんなことでもできるもちろん毎日のニュースや雑誌の内容もほとんどネットにあるそのためコンビニに行って新聞と雑誌を買う必要がなくなりコンピューターの電源のボタンを押すと何でも見られる新聞代や雑誌代を使って他方面のことで使うことができるようになったからコンピューターがあれば他のものはもういらないと思っている人が多いかも知れないけれども私はそのようには思わないコンピューターの利点はたくさんあるのは確かだけれどその利点や便利さを頼りすぎると悪い結果も出て来る漢字が正しく書けなくなったり何でもネットからコピーして自分がどんどん考えられなくなったりするのは一番見られる現象であるですからいくらコンピューターが便利でも他のところから知識とか生活能力を学習するのは昔より重要だと思っているもちろん新聞や雑誌はそれらの方法の中に一番簡単に使える方法であるこれからも必要なものとして私たちの生活に存在しているのも違えない要するにこれからきっとたくさん生活に役に立つものが創造されるんだだけどいくら生活がどんなに快適便利になっても自分の目で見て手を使って自分らしく考えておいてそしてやることをするのが依然としてもっとも人間にとって大切なことであると私はそうだと思っている 携は右側の部分の上に山'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import re\n",
    "# internet_files = [f for f in listdir(osp.join(txt_path, txt_topics[1])) if f.endswith('.txt')]\n",
    "# internet = []\n",
    "# for internet_file in internet_files:\n",
    "#     with open(osp.join(txt_path, txt_topics[1], internet_file), \"r\", encoding=\"utf-8\") as f:\n",
    "#         lines = f.read()\n",
    "#         # print(lines)\n",
    "#         lines = lines.strip('\\ufeff□')\n",
    "#         lines = re.sub('■', '', lines)\n",
    "#         lines = re.sub('\\n', '', lines)\n",
    "#         lines = re.sub('□', '', lines)\n",
    "#         lines = re.sub('\\u3000', '', lines)\n",
    "        \n",
    "#     internet.append(lines)\n",
    "\n",
    "# internet[0]\n",
    "\n",
    "import re\n",
    "internet_files = [f for f in listdir(osp.join(txt_path, txt_topics[1])) if f.endswith('.txt')]\n",
    "internet = []\n",
    "for internet_file in internet_files:\n",
    "    with open(osp.join(txt_path, txt_topics[1], internet_file), \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read()\n",
    "        # print(lines)\n",
    "        lines = lines.strip('\\ufeff□')\n",
    "        lines = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", lines)\n",
    "        lines = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", lines)\n",
    "        \n",
    "    internet.append(lines)\n",
    "\n",
    "internet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d4b3c-3b3d-470c-9a2b-3841e092614a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6080253b-8225-4834-b212-f6da98da0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict as dd\n",
    "text_tagged = dd(list)\n",
    "for level, txt in zip(level1, internet):\n",
    "    text_tagged[level].append(txt)\n",
    "\n",
    "for level, txt in zip(level2, gaigo):\n",
    "    text_tagged[level].append(txt)\n",
    "\n",
    "text_tagged_dict = dict(text_tagged)\n",
    "# text_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec0de867-5c50-4c98-b8d6-43dd0b155c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('text_tagged_dict2.pickle', 'wb') as f:\n",
    "    pickle.dump(text_tagged_dict, f)\n",
    "    \n",
    "text_tagged_dict2 = pickle.load(open('text_tagged_dict2.pickle', 'rb'))\n",
    "# text_tagged_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "996ee578-8744-4c7d-80ef-e204761e5a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:01<00:00, 11.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [00:07<00:00, 12.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:08<00:00, 12.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# nlp = spacy.load('ja_ginza_electra')\n",
    "nlp = spacy.load('ja_ginza')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "category_vectors = []\n",
    "\n",
    "for cat, text in text_tagged_dict.items():\n",
    "    for sents in tqdm(text):\n",
    "        sents = nlp(sents)\n",
    "        word_vector = np.array([tok.vector for tok in sents])\n",
    "        # sent_vecs = []\n",
    "        # for sent in sents:\n",
    "        #     sent = nlp(sent)\n",
    "        #     word_vector = np.array([tok.vector for tok in sent])\n",
    "        #     sent_vecs.append(word_vector)\n",
    "        category_vectors.append((cat, np.array(sent_vecs)))\n",
    "    \n",
    "# 一つの長文の形に変形したのでspacyでうまくいくかわからない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "42697ce7-bc9e-48f9-8908-d9064e309df2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('初級',\n",
       " array([[[-0.0063053 , -0.04985307, -0.22556107, ...,  0.06186676,\n",
       "          -0.05566797, -0.00957808]],\n",
       " \n",
       "        [[-0.08274004, -0.09103364, -0.08744463, ..., -0.06126847,\n",
       "          -0.00597147, -0.00478465]],\n",
       " \n",
       "        [[ 0.17216177,  0.09944343,  0.38480812, ...,  0.17196812,\n",
       "           0.02225779,  0.12094363]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.09195102, -0.10327693, -0.11661331, ..., -0.12604538,\n",
       "          -0.07508431,  0.0575574 ]],\n",
       " \n",
       "        [[ 0.30234763,  0.10496894,  0.24105701, ..., -0.06826453,\n",
       "          -0.29353613,  0.07642345]],\n",
       " \n",
       "        [[-0.10983511, -0.1689055 , -0.12226205, ..., -0.07010163,\n",
       "           0.05129355, -0.01890929]]], dtype=float32))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e3584d5f-9a28-42e7-95f1-4fe13e09d5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 300)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(category_vectors[0][1]).reshape((174, 300)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4ddfa-5263-4c31-b8e8-fd62ff964fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# # nlp = spacy.load('ja_ginza_electra')\n",
    "# nlp = spacy.load('ja_ginza')\n",
    "\n",
    "# import tqdm\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# category_vectors = []\n",
    "\n",
    "# for cat, text in text_tagged_dict2.items():\n",
    "#     for sents in tqdm(text):\n",
    "#         sent_vecs = []\n",
    "#         for sent in sents:\n",
    "#             sent = nlp(sent)\n",
    "#             word_sum = np.sum([tok.vector for tok in sent], axis=0)\n",
    "#             sent_vecs.append(word_sum)\n",
    "#         category_vectors.append((cat, np.sum(sent_vecs, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "69589f43-9229-4f42-8448-a473d3de18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "# with open('category_vectors.pickle', 'wb') as f:\n",
    "#     pickle.dump(category_vectors, f)\n",
    "    \n",
    "category_vectors2 = pickle.load(open('category_vectors.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "01150048-aa9c-496b-8136-a7ee459a971d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>初級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>中級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>中級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>中級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>中級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>中級</td>\n",
       "      <td>[[-0.006305301, -0.049853068, -0.22556107, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat                                            vectors\n",
       "0    初級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "1    初級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "2    初級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "3    初級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "4    初級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "..   ..                                                ...\n",
       "219  中級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "220  中級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "221  中級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "222  中級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "223  中級  [[-0.006305301, -0.049853068, -0.22556107, -0....\n",
       "\n",
       "[224 rows x 2 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "keys, values = zip(*category_vectors)\n",
    "\n",
    "values = [np.squeeze(value, axis=1) for value in values]\n",
    "\n",
    "# values = np.array(values).reshape((174, 300))\n",
    "\n",
    "data = pd.DataFrame({'cat': keys, 'vectors': values})\n",
    "# data2 = Counter(data.cat)\n",
    "# data2\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "09188006-291a-4072-b179-8935cdf5c3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 300)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e7d46bcd-74c9-4900-96d6-7f79cf3530ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 1, 300)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d6d4561-8ed6-4ca5-a106-4f607181fd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 1, 300)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vectors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "854dfd53-ba0d-40b3-b908-a9f6416cc3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f6fbecde-b9c1-4d06-8571-15f763c58b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 2), (179, 2))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.sample(frac=0.2, random_state=200)\n",
    "train = data.drop(test.index)\n",
    "\n",
    "test.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5738acb-f0ae-4ad9-8c77-cd75b56c98f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cbfa9c34-0f23-4c08-8805-6777edc953e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data.cat)\n",
    "X = [x for x in train.vectors]\n",
    "y = le.transform(train.cat)\n",
    "\n",
    "# [x.shape for x in X]\n",
    "# len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9a11217b-6769-4975-9777-c2301be137dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179,)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "50c237a9-33c4-4be8-8b21-6f5089ba7c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 2), (179, 2))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.sample(frac=0.2, random_state=200)\n",
    "train = data.drop(test.index)\n",
    "\n",
    "test.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cea012-7672-4554-9fae-d05593fc7bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8743db7a-cfc7-4e68-a622-abfbe681ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rnn = 10  # 時系列の数\n",
    "batch_size = 128\n",
    "epochs = 20  #epochsは、多いほど、精密に学習するが、重くなるため今回は小さくしている\n",
    "n_mid = 256  # 中間層のニューロン数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b8441508-6ce0-4245-b039-d7e9a98b8bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 256)               570368    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10000)             2570000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,140,368\n",
      "Trainable params: 3,140,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, 300)))\n",
    "model_lstm.add(Dense(10000, activation=\"softmax\"))\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0614054f-c73b-4344-b00b-05c0093d3e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 10, 300), found shape=(None, 174, 300)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [128]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model_lstm\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel_lstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\FIC202~1.002\\AppData\\Local\\Temp\\__autograph_generated_file6fa0mjai.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fic2023150.FIC.002\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 10, 300), found shape=(None, 174, 300)\n"
     ]
    }
   ],
   "source": [
    "model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model_lstm.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "02e1dbef-d8d1-4da1-876a-bbfa5579ce8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((179, 174, 300), (179, 3))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "le.fit(data.cat)\n",
    "y_train = le.transform(train.cat).reshape(-1, 1)\n",
    "ohe.fit(y_train)\n",
    "y_train = ohe.transform(y_train).todense()\n",
    "\n",
    "X_train = np.array([x for x in train.vectors])\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd283618-567b-4b7d-b24c-2b1febd08729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13fc15ed-6bda-493d-abf2-51ad6b4ab2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c6f840e-7656-49bc-9fac-94487c6c95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data.cat)\n",
    "X = [x for x in train.vectors]\n",
    "y = le.transform(train.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d5c60ac-01c5-4102-b201-f7e75e9d5e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((179, 300), (179, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "le.fit(data.cat)\n",
    "y_train = le.transform(train.cat).reshape(-1, 1)\n",
    "ohe.fit(y_train)\n",
    "y_train = ohe.transform(y_train).todense()\n",
    "\n",
    "X_train = np.array([x for x in train.vectors])\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27a9ed1-3674-4939-94fd-d87d1dbf08fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35.72873  , -75.88274  ,   1.2493681, ..., -46.46502  ,\n",
       "        -22.483027 , -23.89953  ],\n",
       "       [ 28.799707 , -52.42878  ,   4.982424 , ..., -28.353933 ,\n",
       "        -15.14752  , -12.70157  ],\n",
       "       [ 24.782848 , -50.567856 ,   3.9012423, ..., -28.780779 ,\n",
       "        -13.119149 , -10.998436 ],\n",
       "       ...,\n",
       "       [ 13.380746 , -38.492195 ,   1.7690995, ..., -25.462816 ,\n",
       "         -5.160268 ,  -7.710597 ],\n",
       "       [ 30.981627 , -44.044937 ,   6.382059 , ..., -31.046907 ,\n",
       "        -15.398306 ,  -6.9955473],\n",
       "       [ 33.65297  , -54.06166  ,   4.3123937, ..., -28.694584 ,\n",
       "        -19.503485 ,  -9.43222  ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00abde5f-60f0-4ee6-8c91-ca9273b1e7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 300), (45, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "le.fit(data.cat)\n",
    "y_test = le.transform(test.cat).reshape(-1, 1)\n",
    "ohe.fit(y_test)\n",
    "y_test = ohe.transform(y_test).todense()\n",
    "\n",
    "X_test = np.array([x for x in test.vectors])\n",
    "\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e194a5eb-8389-45eb-b808-a4d9a722b4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         6400000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 128)        98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,598,019\n",
      "Trainable params: 6,598,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Bidirectional, Dense, LSTM\n",
    "import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "model.add(inputs)\n",
    "model.add(Embedding(50000, 128))\n",
    "# Add 2 bidirectional LSTMs\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "# Add a classifier\n",
    "model.add(Dense(3, activation=\"sigmoid\"))\n",
    "#model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cb892916-003d-433e-8135-ab65d837805d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [125]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d422c-0115-4f6f-88fe-0017a3f17ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qiita.com/KojiOhki/items/89cd7b69a8a6239d67ca#lstm%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF\n",
    "# https://own-search-and-study.xyz/2018/09/17/keras%E3%81%A7lstm%E3%82%92%E5%AD%A6%E7%BF%92%E3%81%99%E3%82%8B%E6%89%8B%E9%A0%86%E3%82%92%E6%95%B4%E7%90%86%E3%81%97%E3%81%A6%E3%81%BF%E3%81%9F/\n",
    "# https://qiita.com/sasayabaku/items/b7872a3b8acc7d6261bf\n",
    "# https://shiva-verma.medium.com/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e\n",
    "# https://www.kaggle.com/code/ranxi169/sentiment-classification-using-lstm/notebook\n",
    "# https://qiita.com/hara_tatsu/items/d1ddb5f1e0dee55dcdfa\n",
    "# https://qiita.com/hara_tatsu/items/c3ba100e95e600846125\n",
    "# https://keras.io/api/layers/recurrent_layers/lstm/\n",
    "\n",
    "\n",
    "\n",
    "# https://gist.github.com/jshirius/a38ed0824e9adaea66e87811514b0b9f#file-lstm_ginga-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "676cd8e5-50c6-4728-98aa-57fe97992d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = tf.constant(a)\n",
    "a[0] = 4\n",
    "print(b)  # tf.Tensor([4 2 3], shape=(3,), dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffddb98-48b5-4aca-ba0f-9ed21a38672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://propen.dream-target.jp/blog/keras_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c345b4-0a66-44b3-a848-7160e3f8174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qiita.com/m__k/items/841950a57a0d7ff05506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbc9942-17a8-481a-a2d8-4d39b5e98c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d01e3-41a5-4369-84e2-6dc3f5b1976e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e1f12-84e4-46fa-a483-7b7052858bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
